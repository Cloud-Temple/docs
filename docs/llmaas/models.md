---
title: Catalogue des Mod√®les LLMaaS
sidebar_position: 2
---

# Catalogue des Mod√®les LLM as a Service

## Vue d'ensemble

Cloud Temple LLMaaS propose **41 mod√®les de langage large** soigneusement s√©lectionn√©s et optimis√©s pour r√©pondre aux exigences **SecNumCloud** les plus strictes. Notre catalogue couvre l'ensemble du spectre, des micro-mod√®les ultra-efficaces aux mod√®les extr√™mement volumineux.

### Statistiques Globales

| M√©trique | Valeur |
|----------|--------|
| **Nombre total de mod√®les** | 41 mod√®les |
| **Contexte minimum** | 8 192 tokens |
| **Contexte maximum** | 262 144 tokens |
| **Conformit√©** | SecNumCloud ‚úÖ HDS ‚úÖ Souverainet√© ‚úÖ C5 ‚ùå |
| **Localisation** | 100% France üá´üá∑ |

### Tarification

| Type d'utilisation | Prix |
|-------------------|------|
| **Tokens d'entr√©e** | 0.9‚Ç¨ / million de tokens |
| **Tokens de sortie** | 4‚Ç¨ / million de tokens |
| **Raisonnement avanc√©** | 21‚Ç¨ / million de tokens |

## Mod√®les de Grande Taille

### gpt-oss:120b
**OpenAI ‚Ä¢ 120B param√®tres ‚Ä¢ Contexte : 120 000 tokens**

Mod√®le de langage open-weight de pointe d'OpenAI, offrant de solides performances avec une licence flexible Apache 2.0.

**Sp√©cifications techniques :**
- **Vitesse** : 140 tokens/seconde tokens/seconde
- **Consommation** : 1.69 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `MoE` `Agent` `Raisonnement` `Open-Source` `Tr√®s Large`

**Cas d'usage :**
- Agents conversationnels avanc√©s avec raisonnement complexe et int√©gration d'outils.
- Applications n√©cessitant une transparence totale du processus de raisonnement (chain-of-thought).
- Sc√©narios commerciaux n√©cessitant une licence permissive (Apache 2.0).
- Fine-tuning pour des t√¢ches sp√©cialis√©es n√©cessitant un mod√®le de base puissant.

---

### llama3.3:70b
**Meta ‚Ä¢ 70B param√®tres ‚Ä¢ Contexte : 132 000 tokens**

Mod√®le multilingue de pointe d√©velopp√© par Meta, con√ßu pour exceller dans le dialogue naturel, le raisonnement complexe et la compr√©hension nuanc√©e des instructions.

**Sp√©cifications techniques :**
- **Vitesse** : 31 tokens/seconde tokens/seconde
- **Consommation** : 8.58 kWh/million tokens
- **Licence** : LLAMA 3.3 Community Licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Dialogue` `Multilingue`

**Cas d'usage :**
- Chatbots multilingues prenant en charge 8 langues simultan√©ment
- Ex√©cution d'instructions complexes encha√Æn√©es (prompt chaining)
- Traitement d'une fen√™tre de dialogue de 60K tokens pour historique conversationnel
- Analyse de documents juridiques ou techniques volumineux (>100 pages)
- G√©n√©ration de textes structur√©s avec fid√©lit√© aux consignes stylistiques

---

### gemma3:27b
**Google ‚Ä¢ 27B param√®tres ‚Ä¢ Contexte : 120 000 tokens**

Mod√®le r√©volutionnaire de Google offrant un √©quilibre optimal entre puissance et efficacit√©, avec un rapport performance/co√ªt exceptionnel pour les applications professionnelles exigeantes.

**Sp√©cifications techniques :**
- **Vitesse** : 24 tokens/seconde tokens/seconde
- **Consommation** : 5.56 kWh/million tokens
- **Licence** : Google Gemma Terms of Use
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `Agent` `Grand contexte`

**Cas d'usage :**
- Analyse de documents avec contexte √©tendu jusqu'√† 120K tokens (environ 400 pages)
- Indexation et recherche s√©mantique dans des bases documentaires volumineuses
- Traitement d'images et texte en simultan√© gr√¢ce aux capacit√©s multimodales
- Extraction structur√©e de donn√©es √† partir de PDF et documents scann√©s
- Int√©gration avec des outils externes via l'API function calling

---

### qwen3-coder:30b
**Qwen Team ‚Ä¢ 30B param√®tres ‚Ä¢ Contexte : 250 000 tokens**

Mod√®le MoE optimis√© pour les t√¢ches d'ing√©nierie logicielle, avec un contexte tr√®s long.

**Sp√©cifications techniques :**
- **Vitesse** : 84 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 3.14 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Programmation` `Grand Contexte` `MoE`

**Cas d'usage :**
- Agents d'ing√©nierie logicielle pour explorer et modifier des bases de code
- G√©n√©ration de code complexe avec compr√©hension √† l'√©chelle du d√©p√¥t (repository-scale)
- T√¢ches de raisonnement sur des contextes √©tendus
- Am√©lioration de code via apprentissage par renforcement

---

### qwen3-2507:30b-a3b
**Qwen Team ‚Ä¢ 30B param√®tres ‚Ä¢ Contexte : 250 000 tokens**

Version am√©lior√©e du mode non-pens√©e de Qwen3-30B, avec des capacit√©s g√©n√©rales, une couverture de connaissances et un alignement utilisateur am√©lior√©s.

**Sp√©cifications techniques :**
- **Vitesse** : 118 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 1.65 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Grand Contexte` `MoE` `Multilingue`

**Cas d'usage :**
- T√¢ches complexes n√©cessitant un suivi d'instructions pr√©cis et un raisonnement logique.
- Applications multilingues avec une large couverture de connaissances.
- G√©n√©ration de texte de haute qualit√© pour des t√¢ches ouvertes et subjectives.
- Analyse de documents tr√®s volumineux gr√¢ce au contexte de 250k tokens.

---

### qwen3:30b-a3b
**Qwen Team ‚Ä¢ 30B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Derni√®re g√©n√©ration des mod√®les Qwen, offrant des am√©liorations significatives en termes de donn√©es d'entra√Ænement, d'architecture et d'optimisation.

**Sp√©cifications techniques :**
- **Vitesse** : 118 tokens/seconde tokens/seconde
- **Consommation** : 1.65 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Programmation` `Multilingue` `MoE`

**Cas d'usage :**
- T√¢ches de raisonnement complexes et g√©n√©ration de code.
- Applications multilingues n√©cessitant une large couverture linguistique.
- Sc√©narios n√©cessitant un bon √©quilibre entre performance et efficacit√© des ressources gr√¢ce √† l'architecture MoE.

---

### qwen2.5vl:32b
**Qwen Team ‚Ä¢ 32B param√®tres ‚Ä¢ Contexte : 120 000 tokens**

Version la plus puissante de la s√©rie Qwen2.5-VL, offrant des capacit√©s de compr√©hension visuelle et d'agentique de pointe.

**Sp√©cifications techniques :**
- **Vitesse** : 22 tokens/seconde tokens/seconde
- **Consommation** : 6.06 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `Agent` `Raisonnement` `OCR` `Localisation Visuelle` `Large`

**Cas d'usage :**
- Analyse de documents et de diagrammes tr√®s complexes
- Agents visuels autonomes pour la navigation et l'interaction avec des GUI
- T√¢ches de localisation d'objets et de reconnaissance de texte de haute pr√©cision
- G√©n√©ration de descriptions riches et d√©taill√©es √† partir d'images complexes

---

### qwen2.5vl:72b
**Qwen Team ‚Ä¢ 72B param√®tres ‚Ä¢ Contexte : 128 000 tokens**

Version la plus puissante de la s√©rie Qwen2.5-VL, offrant des capacit√©s de compr√©hension visuelle et d'agentique de pointe pour les t√¢ches les plus exigeantes.

**Sp√©cifications techniques :**
- **Vitesse** : 13 tokens/seconde tokens/seconde
- **Consommation** : 10.26 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `Agent` `Raisonnement` `OCR` `Localisation Visuelle` `Tr√®s Large`

**Cas d'usage :**
- Analyse de documents et de diagrammes tr√®s complexes
- Agents visuels autonomes pour la navigation et l'interaction avec des GUI
- T√¢ches de localisation d'objets et de reconnaissance de texte de tr√®s haute pr√©cision
- G√©n√©ration de descriptions riches et d√©taill√©es √† partir d'images tr√®s complexes

---

### qwen3-next:80b
**Qwen Team ‚Ä¢ 80B param√®tres ‚Ä¢ Contexte : 262 144 tokens**

Mod√®le Next 80B FP8 de Qwen, optimis√© pour les grands contextes et le raisonnement, servi via vLLM (A100).

**Sp√©cifications techniques :**
- **Vitesse** : 59 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 3.3 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Grand Contexte` `MoE`

**Cas d'usage :**
- Agents conversationnels avanc√©s avec int√©gration d'outils
- Analyse de documents tr√®s volumineux (jusqu'√† 260k tokens)
- G√©n√©ration de code et t√¢ches complexes n√©cessitant raisonnement structur√©

---

## Mod√®les Sp√©cialis√©s

### embeddinggemma:300m
**Google ‚Ä¢ 300M param√®tres ‚Ä¢ Contexte : 2 048 tokens**

Mod√®le d'embedding de pointe de Google, optimis√© pour sa taille, id√©al pour les t√¢ches de recherche et de r√©cup√©ration s√©mantique.

**Sp√©cifications techniques :**
- **Licence** : Google Gemma Terms of Use
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Embedding` `Compact` `S√©mantique` `Efficient` `Multilingue`

**Cas d'usage :**
- Recherche et r√©cup√©ration d'informations (Retrieval)
- Classification et clustering de documents
- Recherche de similarit√© s√©mantique
- D√©ploiement sur des appareils √† ressources limit√©es (mobile, laptop)

---

### gpt-oss:20b
**OpenAI ‚Ä¢ 20B param√®tres ‚Ä¢ Contexte : 120 000 tokens**

Mod√®le de langage open-weight d'OpenAI, optimis√© pour l'efficacit√© et le d√©ploiement sur du mat√©riel grand public.

**Sp√©cifications techniques :**
- **Vitesse** : 85 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 1.57 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `MoE` `Agent` `Raisonnement` `Open-Source` `Compact` `Rapide`

**Cas d'usage :**
- D√©ploiements sur des appareils √† ressources limit√©es (edge devices) ou des serveurs √† faible co√ªt.
- Applications n√©cessitant une inf√©rence rapide avec de bonnes capacit√©s de raisonnement.
- Cas d'usage agentiques avec appel de fonctions, navigation web et ex√©cution de code.
- Fine-tuning pour des t√¢ches sp√©cialis√©es sur du mat√©riel grand public.

---

### qwen3:14b
**Qwen Team ‚Ä¢ 14B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le dense nouvelle g√©n√©ration Qwen3 (14B), offrant des performances √©quivalentes √† Qwen2.5 32B avec une meilleure efficacit√©.

**Sp√©cifications techniques :**
- **Vitesse** : 44 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 3.03 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Rapide` `Multilingue`

**Cas d'usage :**
- T√¢ches g√©n√©rales n√©cessitant performance et grand contexte
- G√©n√©ration de contenu cr√©atif et technique
- Analyse de donn√©es et raisonnement complexe
- Int√©gration avec des outils externes via function calling

---

### gemma3:4b
**Google ‚Ä¢ 4B param√®tres ‚Ä¢ Contexte : 120 000 tokens**

Mod√®le compact de Google offrant d'excellentes performances dans un format l√©ger et √©conomique.

**Sp√©cifications techniques :**
- **Vitesse** : 60 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 0.55 kWh/million tokens üå±
- **Licence** : Google Gemma Terms of Use
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `Rapide` `Compact` `Grand Contexte` `Efficient`

**Cas d'usage :**
- Applications embarqu√©es et edge computing avec traitement d'images
- Chatbots multimodaux r√©actifs n√©cessitant une faible latence
- D√©ploiements √† grande √©chelle avec capacit√©s visuelles et textuelles
- Applications mobiles avec analyse d'images et textes
- Traitement de requ√™tes visuelles simples √† moyenne complexit√© avec haute performance

---

### gemma3:1b
**Google ‚Ä¢ 1B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Micro-mod√®le ultra-l√©ger con√ßu pour les d√©ploiements sur appareils √† tr√®s faibles ressources.

**Sp√©cifications techniques :**
- **Vitesse** : 115 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 0.15 kWh/million tokens üå±
- **Licence** : Google Gemma Terms of Use
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Ultra-compact` `Embarqu√©` `Efficient` `Rapide`

**Cas d'usage :**
- D√©ploiement sur appareils IoT et syst√®mes embarqu√©s avec int√©gration API
- Applications n√©cessitant inf√©rence locale sur CPU avec appels √† des fonctions
- T√¢ches textuelles basiques avec temps de r√©ponse instantan√© et function calling
- Assistants compacts pour applications grand public avec int√©gration services externes
- Syst√®mes de contr√¥le intelligents int√©grant plusieurs APIs/services

---

### mistral-small3.1:24b
**Mistral AI ‚Ä¢ 24B param√®tres ‚Ä¢ Contexte : 120 000 tokens**

Mod√®le compact et r√©actif de Mistral AI, sp√©cialement con√ßu pour offrir une assistance conversationnelle fluide et pertinente avec une vitesse de r√©ponse optimale.

**Sp√©cifications techniques :**
- **Vitesse** : 34 tokens/seconde tokens/seconde
- **Consommation** : 3.83 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Vision` `Agent` `S√©curit√©`

**Cas d'usage :**
- Applications conversationnelles
- Assistants virtuels combinant analyse d'images et texte (26 tokens/s)
- Chatbots de support technique avec acc√®s √† la documentation technique
- Outils de cr√©ation/√©dition de contenu avec r√©ponse imm√©diate (blogs, emails)
- D√©ploiement sur infrastructures standard (24B de param√®tres)

---

### mistral-small3.2:24b
**Mistral AI ‚Ä¢ 24B param√®tres ‚Ä¢ Contexte : 128 000 tokens**

Mise √† jour mineure de Mistral Small 3.1, am√©liorant le suivi d'instructions, la robustesse du function calling et r√©duisant les erreurs de r√©p√©tition.

**Sp√©cifications techniques :**
- **Vitesse** : 56 tokens/seconde tokens/seconde
- **Consommation** : 2.33 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Vision` `Agent` `S√©curit√©` `Instruction Following`

**Cas d'usage :**
- Agents conversationnels avec un suivi d'instructions am√©lior√©
- Int√©gration robuste avec des outils externes via function calling
- Applications n√©cessitant une grande fiabilit√© pour √©viter les r√©p√©titions
- Cas d'usage identiques √† Mistral Small 3.1 avec des performances accrues

---

### deepcoder:14b
**Agentica x Together AI ‚Ä¢ 14B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le IA open source (14B) par Together AI & Agentica, alternative cr√©dible aux mod√®les propri√©taires pour la g√©n√©ration de code.

**Sp√©cifications techniques :**
- **Vitesse** : 9 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 3.72 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Programmation` `Raisonnement` `Open-Source` `Math√©matiques` `Rapide`

**Cas d'usage :**
- G√©n√©ration de code dans plus de 15 langages avec optimisation des performances
- D√©bogage et refactoring de bases de code existantes avec analyse d'impact
- Impl√©mentation d'algorithmes complexes (graphes, arbres, heuristiques)
- Cr√©ation automatis√©e de tests unitaires avec couverture de code > 80%
- Transposition de code entre langagesframeworks (par exemple Python vers JavaScript)

---

### granite3.2-vision:2b
**IBM ‚Ä¢ 2B param√®tres ‚Ä¢ Contexte : 16 384 tokens**

Mod√®le compact r√©volutionnaire d'IBM sp√©cialis√© dans la vision par ordinateur, capable d'analyser et comprendre directement les documents visuels sans recourir √† des technologies OCR interm√©diaires.

**Sp√©cifications techniques :**
- **Vitesse** : 88 tokens/seconde tokens/seconde
- **Consommation** : 0.38 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Vision` `S√©curit√©` `Compact` `Efficient`

**Cas d'usage :**
- Extraction de donn√©es structur√©es √† partir de factures et formulaires sans OCR
- Analyse directe de tableaux et graphiques avec interpr√©tation des tendances
- Lecture et interpr√©tation de diagrammes techniques (√©lectriques, m√©caniques)
- Traitement de documents manuscrits avec taux de reconnaissance √©lev√©
- Vision par ordinateur l√©g√®re (2B param√®tres) avec vitesse √©lev√©e (50 tokens/s)

---

### granite3.3:8b
**IBM ‚Ä¢ 8B param√®tres ‚Ä¢ Contexte : 60 000 tokens**

Mod√®le Granite 8B fine-tun√© par IBM pour un raisonnement et un suivi d'instructions am√©lior√©s, avec un contexte de 128k tokens.

**Sp√©cifications techniques :**
- **Vitesse** : 39 tokens/seconde tokens/seconde
- **Consommation** : 0.85 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Agent` `Raisonnement` `S√©curit√©` `Efficient`

**Cas d'usage :**
- T√¢ches g√©n√©rales d'instruction-following (classification, extraction, Q&A)
- Assistants IA multilingues (12 langues)
- Traitement de documents tr√®s longs (128k tokens) pour les taches de r√©sum√©s, Q&A,...
- G√©n√©ration/compl√©tion de code avec Fill-in-the-Middle
- Int√©gration avec des outils externes via function calling
- Raisonnement structur√© avec le mode "Thinking"

---

### granite3.3:2b
**IBM ‚Ä¢ 2B param√®tres ‚Ä¢ Contexte : 120 000 tokens**

Mod√®le Granite 2B fine-tun√© par IBM, optimis√© pour le raisonnement et le suivi d'instructions, avec un contexte de 128k tokens.

**Sp√©cifications techniques :**
- **Vitesse** : 88 tokens/seconde tokens/seconde
- **Consommation** : 0.38 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Agent` `Raisonnement` `S√©curit√©` `Efficient`

**Cas d'usage :**
- D√©ploiements l√©gers avec grand contexte (128k tokens)
- T√¢ches g√©n√©rales d'instruction-following sur ressources limit√©es
- Assistants IA multilingues compacts
- Traitement de documents longs sur appareils moins puissants
- G√©n√©ration/compl√©tion de code FIM sur postes de travail standards

---

### magistral:24b
**Mistral AI ‚Ä¢ 24B param√®tres ‚Ä¢ Contexte : 40 000 tokens**

Le premier mod√®le de raisonnement de Mistral AI, excellant dans le raisonnement sp√©cifique au domaine, transparent et multilingue.

**Sp√©cifications techniques :**
- **Vitesse** : 29 tokens/seconde tokens/seconde
- **Consommation** : 4.59 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Raisonnement` `Multilingue`

**Cas d'usage :**
- Strat√©gie et op√©rations commerciales (mod√©lisation des risques)
- Industries r√©glement√©es (juridique, finance) avec raisonnement tra√ßable
- Ing√©nierie logicielle (planification de projet, architecture)
- Cr√©ation de contenu et communication (r√©daction cr√©ative, narration)

---

### cogito:32b
**Deep Cogito ‚Ä¢ 32B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Version avanc√©e du mod√®le Cogito offrant des capacit√©s de raisonnement et d'analyse consid√©rablement amplifi√©es, con√ßue pour les applications les plus exigeantes en mati√®re d'intelligence artificielle analytique.

**Sp√©cifications techniques :**
- **Vitesse** : 37 tokens/seconde tokens/seconde
- **Consommation** : 7.13 kWh/million tokens
- **Licence** : LLAMA 3.2 Community Licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Compr√©hension` `Analyse`

**Cas d'usage :**
- Analyse de sc√©narios multi-factoriels avec √©valuation probabiliste des r√©sultats
- R√©solution de probl√®mes scientifiques avec d√©monstration formelle des √©tapes
- Applications √† haute criticit√© n√©cessitant pr√©cision et v√©rifiabilit√© des r√©sultats
- Syst√®mes experts dans des domaines sp√©cialis√©s (juridique, m√©dical, technique)
- Analyse avec raisonnement multi-√©tapes et explicabilit√© compl√®te des conclusions

---

### qwen3:32b
**Qwen Team ‚Ä¢ 32B param√®tres ‚Ä¢ Contexte : 40 000 tokens**

Mod√®le puissant de la nouvelle g√©n√©ration Qwen3, offrant des capacit√©s avanc√©es en raisonnement, code, et agentique, avec un contexte √©tendu.

**Sp√©cifications techniques :**
- **Vitesse** : 21 tokens/seconde tokens/seconde
- **Consommation** : 6.35 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Multilingue` `Grand Contexte`

**Cas d'usage :**
- Agents conversationnels avanc√©s avec grand contexte et int√©gration d'outils (MCP)
- R√©solution de probl√®mes complexes (maths, code) avec mode "Thinking"
- Analyse et g√©n√©ration de documents volumineux
- Applications multilingues (>100 langues) n√©cessitant une compr√©hension profonde

---

### qwq:32b
**Qwen Team ‚Ä¢ 32B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le de 32 milliards de param√®tres am√©lior√© par apprentissage par renforcement (RL) pour exceller dans le raisonnement, le codage, les math√©matiques et les t√¢ches d'agent.

**Sp√©cifications techniques :**
- **Vitesse** : 11 tokens/seconde tokens/seconde
- **Consommation** : 23.99 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Codage` `Math√©matiques`

**Cas d'usage :**
- R√©solution de probl√®mes complexes n√©cessitant raisonnement et utilisation d'outils
- G√©n√©ration et ex√©cution de code avec v√©rification des r√©sultats
- T√¢ches math√©matiques avanc√©es avec v√©rification de l'exactitude
- Applications d'agent capables d'interagir avec l'environnement
- Instruction following am√©lior√© et alignement avec les pr√©f√©rences humaines

---

### deepseek-r1:14b
**DeepSeek AI ‚Ä¢ 14B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Version compacte et efficiente du mod√®le DeepSeek-R1, offrant un excellent compromis entre performance et l√©g√®ret√© pour les d√©ploiements n√©cessitant flexibilit√© et r√©activit√©.

**Sp√©cifications techniques :**
- **Vitesse** : 23 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 1.45 kWh/million tokens
- **Licence** : MIT licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Raisonnement` `Compact` `Polyvalent` `Rapide`

**Cas d'usage :**
- Applications g√©n√©ralistes avec besoins d'inf√©rence rapide (44 tokens/s)
- D√©ploiements sur serveurs standard sans GPU sp√©cialis√© (14B param√®tres)
- Traitement de texte avec analyse contextuelle et temps de r√©ponse rapides
- D√©ploiement sur edge computing avec inf√©rence locale optimis√©e
- Prototypage rapide d'applications IA avec temps d'it√©ration court

---

### deepseek-r1:32b
**DeepSeek AI ‚Ä¢ 32B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Version interm√©diaire du mod√®le DeepSeek-R1 offrant un √©quilibre strat√©gique entre les capacit√©s avanc√©es de la version 70B et l'efficience de la version 14B, pour une polyvalence et performance optimales.

**Sp√©cifications techniques :**
- **Vitesse** : 20 tokens/seconde tokens/seconde
- **Consommation** : 13.18 kWh/million tokens
- **Licence** : MIT licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Raisonnement` `Polyvalent`

**Cas d'usage :**
- Applications n√©cessitant un bon √©quilibre puissance/co√ªt (32B param√®tres)
- Traitement de texte professionnel avec analyse des subtilit√©s s√©mantiques
- G√©n√©ration automatis√©e de rapports structur√©s √† partir de donn√©es brutes
- Applications combinant analyse de donn√©es et g√©n√©ration de contenus
- Assistants sp√©cialis√©s pour secteurs techniques (juridique, m√©dical, technique)

---

### cogito:3b
**Deep Cogito ‚Ä¢ 3B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Version compacte du mod√®le Cogito, optimis√©e pour le raisonnement sur des appareils √† ressources limit√©es.

**Sp√©cifications techniques :**
- **Vitesse** : 78 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 0.43 kWh/million tokens üå±
- **Licence** : LLAMA 3.2 Community Licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Raisonnement` `Compact` `Embarqu√©` `Efficient` `Rapide`

---

### granite-embedding:278m
**IBM ‚Ä¢ 278M param√®tres ‚Ä¢ Contexte : 512 tokens**

Mod√®le d'embedding ultra-l√©ger d'IBM pour la recherche s√©mantique et la classification.

**Sp√©cifications techniques :**
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Embedding` `Compact` `S√©mantique` `Efficient`

---

### granite3-guardian:2b
**IBM ‚Ä¢ 2B param√®tres ‚Ä¢ Contexte : 8 192 tokens**

Mod√®le compact d'IBM sp√©cialis√© dans la s√©curit√© et la conformit√©, d√©tectant les risques et les contenus inappropri√©s.

**Sp√©cifications techniques :**
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `S√©curit√©` `Conformit√©` `Compact` `Filtrage` `Efficient`

---

### granite3-guardian:8b
**IBM ‚Ä¢ 8B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le d'IBM sp√©cialis√© dans la s√©curit√© et la conformit√©, offrant des capacit√©s avanc√©es de d√©tection des risques.

**Sp√©cifications techniques :**
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `S√©curit√©` `Conformit√©` `Filtrage`

---

### qwen3:0.6b
**Qwen Team ‚Ä¢ 0.6B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le compact et efficace de la famille Qwen3, adapt√© aux t√¢ches g√©n√©rales sur ressources limit√©es.

**Sp√©cifications techniques :**
- **Vitesse** : 28 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 0.6 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Compact` `Rapide` `Polyvalent` `Efficient`

---

### qwen3:1.7b
**Qwen Team ‚Ä¢ 1.7B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le tr√®s compact de la famille Qwen3, offrant un bon √©quilibre performance/taille pour les d√©ploiements l√©gers.

**Sp√©cifications techniques :**
- **Vitesse** : 46 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 0.73 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Compact` `Rapide` `Embarqu√©` `Efficient`

---

### qwen3:4b
**Qwen Team ‚Ä¢ 4B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le compact de la famille Qwen3 offrant d'excellentes performances dans un format l√©ger et √©conomique.

**Sp√©cifications techniques :**
- **Vitesse** : 29 tokens/seconde tokens/seconde
- **Consommation** : 1.15 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Compact` `Efficient`

---

### qwen3-2507-think:4b
**Qwen Team ‚Ä¢ 4B param√®tres ‚Ä¢ Contexte : 250 000 tokens**

Mod√®le Qwen3-4B optimis√© pour le raisonnement, avec des performances am√©lior√©es sur les t√¢ches logiques, les math√©matiques, la science et le code, et un contexte √©tendu √† 250K tokens.

**Sp√©cifications techniques :**
- **Vitesse** : 77 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 1.73 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Grand Contexte` `Compact` `Rapide`

**Cas d'usage :**
- T√¢ches de raisonnement tr√®s complexes (logique, maths, science, code).
- Agents conversationnels avec un historique de conversation tr√®s √©tendu (256k tokens).
- Analyse de documents tr√®s volumineux avec raisonnement profond.
- Int√©gration avec des outils externes via function calling sur de tr√®s grands contextes.

---

### qwen3-2507:4b
**Qwen Team ‚Ä¢ 4B param√®tres ‚Ä¢ Contexte : 250 000 tokens**

Version mise √† jour du mode non-pens√©e de Qwen3-4B, avec des am√©liorations significatives des capacit√©s g√©n√©rales, une couverture de connaissances √©tendue et un meilleur alignement avec les pr√©f√©rences des utilisateurs.

**Sp√©cifications techniques :**
- **Vitesse** : 69 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 1.93 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Grand Contexte` `Compact` `Rapide` `Multilingue`

**Cas d'usage :**
- T√¢ches g√©n√©rales n√©cessitant un suivi d'instructions pr√©cis et un raisonnement logique.
- Applications multilingues avec une large couverture de connaissances.
- G√©n√©ration de texte de haute qualit√© pour des t√¢ches ouvertes et subjectives.
- Analyse de documents tr√®s volumineux gr√¢ce au contexte de 256k tokens.

---

### qwen3:8b
**Qwen Team ‚Ä¢ 8B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le Qwen3 8B offrant un bon √©quilibre entre performance et efficacit√© pour les t√¢ches g√©n√©rales.

**Sp√©cifications techniques :**
- **Vitesse** : 18 tokens/seconde tokens/seconde
- **Consommation** : 1.85 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Raisonnement` `Agent` `Multilingue` `Efficient`

---

### qwen2.5vl:3b
**Qwen Team ‚Ä¢ 3.8B param√®tres ‚Ä¢ Contexte : 128 000 tokens**

Mod√®le Vision-Langage compact, solution performante pour l'IA en p√©riph√©rie (edge AI).

**Sp√©cifications techniques :**
- **Vitesse** : 73 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 0.45 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `Agent` `Raisonnement` `Rapide` `Efficient` `OCR` `Localisation Visuelle` `Edge AI`

---

### qwen2.5vl:7b
**Qwen Team ‚Ä¢ 7B (8.3B) param√®tres ‚Ä¢ Contexte : 128 000 tokens**

Mod√®le Vision-Langage performant, surpassant GPT-4o-mini sur certaines t√¢ches.

**Sp√©cifications techniques :**
- **Vitesse** : 48 tokens/seconde tokens/seconde
- **Consommation** : 0.69 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `Agent` `Raisonnement` `Efficient` `OCR` `Localisation Visuelle`

---

### devstral:24b
**Mistral AI & All Hands AI ‚Ä¢ 24B param√®tres ‚Ä¢ Contexte : 100 000 tokens**

Devstral est un LLM agentique pour les t√¢ches d'ing√©nierie logicielle.

**Sp√©cifications techniques :**
- **Vitesse** : 50 tokens/seconde tokens/seconde
- **Consommation** : 5.27 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Agent` `Programmation` `Open-Source` `Grand Contexte`

**Cas d'usage :**
- Exploration et modification de bases de code
- Agentic
- Europ√©en

---

### cogito:8b
**Deep Cogito ‚Ä¢ 8B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le de taille interm√©diaire de la famille Cogito, offrant un bon √©quilibre entre les capacit√©s de raisonnement et l'efficacit√©.

**Sp√©cifications techniques :**
- **Vitesse** : 43 tokens/seconde tokens/seconde
- **Consommation** : 0.77 kWh/million tokens üå±
- **Licence** : LLAMA 3.2 Community Licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Polyvalent` `Efficient`

---

### granite4-small-h:32b
**IBM ‚Ä¢ 32B (9B actifs) param√®tres ‚Ä¢ Contexte : 128 000 tokens**

Mod√®le MoE (Mixture-of-Experts) d'IBM, con√ßu comme un "cheval de bataille" pour les t√¢ches d'entreprise quotidiennes, avec une excellente efficacit√© pour les longs contextes.

**Sp√©cifications techniques :**
- **Vitesse** : 28 tokens/seconde tokens/seconde
- **Consommation** : 1.19 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Agent` `Raisonnement` `S√©curit√©` `MoE` `Grand Contexte` `Efficient`

**Cas d'usage :**
- Agents conversationnels pour le support client avec acc√®s √† des bases de connaissances √©tendues.
- Automatisation de workflows d'entreprise n√©cessitant l'utilisation de plusieurs outils.
- Analyse de documents longs avec une consommation de ressources optimis√©e.
- D√©ploiements sur des infrastructures de taille moyenne gr√¢ce √† son efficacit√©.

---

### granite4-tiny-h:7b
**IBM ‚Ä¢ 7B (1B actif) param√®tres ‚Ä¢ Contexte : 128 000 tokens**

Mod√®le MoE hybride ultra-efficace d'IBM, con√ßu pour la faible latence, les applications "edge" et locales, et comme brique de base pour les workflows agentiques.

**Sp√©cifications techniques :**
- **Vitesse** : 77 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 0.43 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Agent` `Raisonnement` `S√©curit√©` `MoE` `Grand Contexte` `Efficient` `Rapide` `Compact`

**Cas d'usage :**
- Applications embarqu√©es et "edge" n√©cessitant une faible latence.
- T√¢ches rapides au sein de workflows agentiques plus larges (ex: function calling).
- Analyse de documents sur du mat√©riel grand public.
- D√©ploiements n√©cessitant une empreinte m√©moire minimale.

---

### deepseek-ocr
**DeepSeek AI ‚Ä¢ 3B param√®tres ‚Ä¢ Contexte : 8 192 tokens**

Mod√®le OCR sp√©cialis√© de DeepSeek, con√ßu pour une extraction de texte haute pr√©cision avec pr√©servation de la mise en forme.

**Sp√©cifications techniques :**
- **Vitesse** : 120 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 0.16 kWh/million tokens üå±
- **Licence** : MIT licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `OCR` `Efficient`

**Cas d'usage :**
- Extraction de texte structur√© (Markdown/latex) depuis des images/PDF
- Num√©risation de documents avec tableaux et formules complexes

---

## Cas d'Usage Recommand√©s

### Dialogue multilingue
Chatbots et assistants capables de communiquer dans plusieurs langues avec d√©tection automatique, maintien du contexte sur l'ensemble de la conversation et compr√©hension des sp√©cificit√©s linguistiques

**Mod√®les recommand√©s :**
- Llama 3.3
- Mistral Small 3.2
- Qwen 3
- Openai OSS
- Granite 4

### Analyse de documents longs
Traitement de documents volumineux (>100 pages) avec maintien du contexte sur l'ensemble du texte, extraction d'informations cl√©s, g√©n√©ration de r√©sum√©s pertinents et r√©ponse √† des questions sp√©cifiques sur le contenu

**Mod√®les recommand√©s :**
- Gemma 3
- Qwen next
- Qwen 3
- Granite 4

### Programmation et d√©veloppement
G√©n√©ration et optimisation de code dans multiples langages, d√©bogage, refactoring, d√©veloppement de fonctionnalit√©s compl√®tes, compr√©hension des impl√©mentations algorithmiques complexes et cr√©ation de tests unitaires

**Mod√®les recommand√©s :**
- DeepCoder
- Qwen3 coder
- Granite 4
- Devstral

### Analyse visuelle
Traitement direct d'images et documents visuels sans pr√©-traitement OCR, interpr√©tation de diagrammes techniques, graphiques, tableaux, dessins et photos avec g√©n√©ration d'explications textuelles d√©taill√©es du contenu visuel

**Mod√®les recommand√©s :**
- deepseek-OCR
- Mistral Small 3.2
- Gemma 3
- Qwen2.5-VL

### S√©curit√© et conformit√©
Applications n√©cessitant des capacit√©s sp√©cifiques en mati√®re de s√©curit√© ; filtrage de contenu sensible, tra√ßabilit√© des raisonnements, v√©rification RGPD/HDS, minimisation des risques, analyse des vuln√©rabilit√©s et respect des r√©glementations sectorielles

**Mod√®les recommand√©s :**
- Granite Guardian
- Granite 4
- Devstral
- Mistral Small 3.2
- Magistral 24b

### D√©ploiements l√©gers et embarqu√©s
Applications n√©cessitant une empreinte minimale en ressources, d√©ploiement sur appareils √† capacit√© limit√©e, inf√©rence en temps r√©el sur CPU standard et int√©gration dans des syst√®mes embarqu√©s ou IoT

**Mod√®les recommand√©s :**
- Gemma 3
- Granite Guardian
- Granite 4 tiny
- DeepSeek-OCR
