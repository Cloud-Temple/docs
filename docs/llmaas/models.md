---
title: Catalogue des Mod√®les IA
sidebar_position: 2
---

# Catalogue des Mod√®les LLM as a Service

## Vue d'ensemble

Cloud Temple LLMaaS propose **42 mod√®les de langage large** soigneusement s√©lectionn√©s et optimis√©s pour r√©pondre aux exigences **SecNumCloud** les plus strictes. Notre catalogue couvre l'ensemble du spectre, des micro-mod√®les ultra-efficaces aux mod√®les extr√™mement volumineux.

### Statistiques Globales

| M√©trique | Valeur |
|----------|--------|
| **Nombre total de mod√®les** | 42 mod√®les |
| **Contexte minimum** | 2,048 tokens |
| **Contexte maximum** | 262,144 tokens |
| **Conformit√©** | SecNumCloud ‚úÖ HDS ‚úÖ Souverainet√© ‚úÖ C5 ‚úÖ |
| **Localisation** | 100% France üá´üá∑ |

### Tarification

| Type d'utilisation | Prix |
|-------------------|------|
| **Tokens d'entr√©e** | 0.9‚Ç¨ / million de tokens |
| **Tokens de sortie** | 4‚Ç¨ / million de tokens |
| **Raisonnement avanc√©** | 21‚Ç¨ / million de tokens |

## Mod√®les de Grande Taille

### cogito:32b
**Deep Cogito ‚Ä¢ 32B param√®tres ‚Ä¢ Contexte : 32,000 tokens**

Version avanc√©e du mod√®le Cogito offrant des capacit√©s de raisonnement et d'analyse consid√©rablement amplifi√©es, con√ßue pour les applications les plus exigeantes en mati√®re d'intelligence artificielle analytique.

**Sp√©cifications techniques:**
- **Vitesse** : 20 tokens/seconde
- **Consommation** : 6.67 kWh/million tokens
- **Licence** : [LLAMA 3.2 Community Licence](./licences/llama_3.2_community_licence.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Compr√©hension` `Analyse`

**Cas d'usage :**
- Analyse de sc√©narios multi-factoriels avec √©valuation probabiliste des r√©sultats
- R√©solution de probl√®mes scientifiques avec d√©monstration formelle des √©tapes
- Applications √† haute criticit√© n√©cessitant pr√©cision et v√©rifiabilit√© des r√©sultats
- Syst√®mes experts dans des domaines sp√©cialis√©s (juridique, m√©dical, technique)
- Analyse avec raisonnement multi-√©tapes et explicabilit√© compl√®te des conclusions

---

### gemma3:27b
**Google ‚Ä¢ 27B param√®tres ‚Ä¢ Contexte : 120,000 tokens**

Mod√®le r√©volutionnaire de Google offrant un √©quilibre optimal entre puissance et efficacit√©, avec un rapport performance/co√ªt exceptionnel pour les applications professionnelles exigeantes.

**Sp√©cifications techniques:**
- **Vitesse** : 21 tokens/seconde
- **Consommation** : 6.35 kWh/million tokens
- **Licence** : [Google Gemma Terms of Use](./licences/google_gemma_terms_of_use.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `Agent` `Grand contexte`

**Cas d'usage :**
- Analyse de documents avec contexte √©tendu jusqu'√† 120K tokens (environ 400 pages)
- Indexation et recherche s√©mantique dans des bases documentaires volumineuses
- Traitement d'images et texte en simultan√© gr√¢ce aux capacit√©s multimodales
- Extraction structur√©e de donn√©es √† partir de PDF et documents scann√©s
- Int√©gration avec des outils externes via l'API function calling

---

### glm-4.7:358b
**Zhipu AI ‚Ä¢ 358B param√®tres ‚Ä¢ Contexte : 120,000 tokens**

Mod√®le polyvalent de haute performance con√ßu par Zhipu AI, excellent dans le raisonnement logique, la compr√©hension multilingue et les t√¢ches complexes.

**Sp√©cifications techniques:**
- **Vitesse** : 18 tokens/seconde
- **Consommation** : 7.41 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Grand Contexte` `Multilingue`

**Cas d'usage :**
- T√¢ches de raisonnement complexe
- Analyse de documents longs
- Assistants conversationnels avanc√©s

---

### gpt-oss:120b
**OpenAI ‚Ä¢ 120B param√®tres ‚Ä¢ Contexte : 120,000 tokens**

Mod√®le de langage open-weight de pointe d'OpenAI, offrant de solides performances avec une licence flexible Apache 2.0.

**Sp√©cifications techniques:**
- **Vitesse** : 104 tokens/seconde
- **Consommation** : 2.19 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `MoE` `Agent` `Raisonnement` `Open-Source` `Tr√®s Large`

**Cas d'usage :**
- Agents conversationnels avanc√©s avec raisonnement complexe et int√©gration d'outils.
- Applications n√©cessitant une transparence totale du processus de raisonnement (chain-of-thought).
- Sc√©narios commerciaux n√©cessitant une licence permissive (Apache 2.0).
- Fine-tuning pour des t√¢ches sp√©cialis√©es n√©cessitant un mod√®le de base puissant.

---

### llama3.3:70b
**Meta ‚Ä¢ 70B param√®tres ‚Ä¢ Contexte : 132,000 tokens**

Mod√®le multilingue de pointe d√©velopp√© par Meta, con√ßu pour exceller dans le dialogue naturel, le raisonnement complexe et la compr√©hension nuanc√©e des instructions.

**Sp√©cifications techniques:**
- **Vitesse** : 29 tokens/seconde
- **Consommation** : 7.85 kWh/million tokens
- **Licence** : [LLAMA 3.3 Community Licence](./licences/llama_3.3_community_licence.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Dialogue` `Multilingue`

**Cas d'usage :**
- Chatbots multilingues prenant en charge 8 langues simultan√©ment
- Ex√©cution d'instructions complexes encha√Æn√©es (prompt chaining)
- Traitement d'une fen√™tre de dialogue de 60K tokens pour historique conversationnel
- Analyse de documents juridiques ou techniques volumineux (>100 pages)
- G√©n√©ration de textes structur√©s avec fid√©lit√© aux consignes stylistiques

---

### ministral-3:14b
**Mistral AI ‚Ä¢ 14B param√®tres ‚Ä¢ Contexte : 250,000 tokens**

Le plus puissant de la famille Ministral, con√ßu pour les t√¢ches complexes sur infrastructure locale.

**Sp√©cifications techniques:**
- **Vitesse** : 31 tokens/seconde
- **Consommation** : 4.30 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Haute Performance` `Edge` `Raisonnement` `Code`

**Cas d'usage :**
- R√©solution de probl√®mes complexes en local
- Assistants de codage et d'ing√©nierie
- Analyse approfondie de documents avec raisonnement

---

### nemotron-3-nano:30b
**NVIDIA ‚Ä¢ 30B param√®tres ‚Ä¢ Contexte : 250,000 tokens**

Mod√®le NVIDIA optimis√© pour le raisonnement complexe et l'utilisation d'outils, d√©ploy√© avec un contexte √©tendu.

**Sp√©cifications techniques:**
- **Vitesse** : 89 tokens/seconde
- **Consommation** : 1.62 kWh/million tokens
- **Licence** : [NVIDIA Community License](./licences/nvidia_community_license.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Grand Contexte`

**Cas d'usage :**
- Agents autonomes complexes avec appels d'outils multiples
- Raisonnement logique et r√©solution de probl√®mes
- Analyse de documents longs avec extraction pr√©cise

---

### olmo-3:32b
**AllenAI ‚Ä¢ 32B param√®tres ‚Ä¢ Contexte : 65,536 tokens**

Le premier mod√®le de raisonnement enti√®rement ouvert √† cette √©chelle, rivalisant avec les meilleurs mod√®les propri√©taires.

**Sp√©cifications techniques:**
- **Vitesse** : 19 tokens/seconde
- **Consommation** : 7.02 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Open-Source` `Grand Contexte` `Raisonnement` `Transparent` `Code` `Haute Performance`

**Cas d'usage :**
- Raisonnement complexe et r√©solution de probl√®mes multi-√©tapes
- D√©veloppement logiciel avanc√© et g√©n√©ration de code
- Analyse approfondie n√©cessitant une transparence sur le processus de d√©cision

---

### olmo-3:7b
**AllenAI ‚Ä¢ 7B param√®tres ‚Ä¢ Contexte : 65,536 tokens**

Mod√®le "Fully Open" de r√©f√©rence, offrant une transparence totale (donn√©es, code, poids) et une efficacit√© remarquable.

**Sp√©cifications techniques:**
- **Vitesse** : 37 tokens/seconde
- **Consommation** : 1.65 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Open-Source` `Grand Contexte` `Transparent` `Efficient` `Maths` `Code`

**Cas d'usage :**
- Recherche acad√©mique et scientifique n√©cessitant une reproductibilit√© totale
- T√¢ches de programmation et r√©solution de probl√®mes math√©matiques
- Analyse de documents moyens avec tra√ßabilit√© compl√®te

---

### qwen3-2507:235b
**Qwen Team ‚Ä¢ 235B param√®tres ‚Ä¢ Contexte : 130,000 tokens**

Mod√®le MoE massif de 235 milliards de param√®tres, avec seulement 22 milliards actifs, offrant des performances de pointe.

**Sp√©cifications techniques:**
- **Vitesse** : 58 tokens/seconde
- **Consommation** : 3.93 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `MoE` `Agent` `Raisonnement` `Tr√®s Large`

**Cas d'usage :**
- R√©solution de probl√®mes math√©matiques et logiques complexes
- T√¢ches n√©cessitant une vaste base de connaissances
- Assistant de codage avanc√©
- Analyse approfondie de documents

---

### qwen3-2507:30b-a3b
**Qwen Team ‚Ä¢ 30B param√®tres ‚Ä¢ Contexte : 250,000 tokens**

Version am√©lior√©e du mode non-pens√©e de Qwen3-30B, avec des capacit√©s g√©n√©rales, une couverture de connaissances et un alignement utilisateur am√©lior√©s.

**Sp√©cifications techniques:**
- **Vitesse** : 104 tokens/seconde
- **Consommation** : 1.39 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Grand Contexte` `MoE` `Multilingue`

**Cas d'usage :**
- T√¢ches complexes n√©cessitant un suivi d'instructions pr√©cis et un raisonnement logique.
- Applications multilingues avec une large couverture de connaissances.
- G√©n√©ration de texte de haute qualit√© pour des t√¢ches ouvertes et subjectives.
- Analyse de documents tr√®s volumineux gr√¢ce au contexte de 250k tokens.

---

### qwen3-coder:30b
**Qwen Team ‚Ä¢ 30B param√®tres ‚Ä¢ Contexte : 250,000 tokens**

Mod√®le MoE optimis√© pour les t√¢ches d'ing√©nierie logicielle, avec un contexte tr√®s long.

**Sp√©cifications techniques:**
- **Vitesse** : 104 tokens/seconde
- **Consommation** : 1.39 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Programmation` `Grand Contexte` `MoE`

**Cas d'usage :**
- Agents d'ing√©nierie logicielle pour explorer et modifier des bases de code
- G√©n√©ration de code complexe avec compr√©hension √† l'√©chelle du d√©p√¥t (repository-scale)
- T√¢ches de raisonnement sur des contextes √©tendus
- Am√©lioration de code via apprentissage par renforcement

---

### qwen3-next:80b
**Qwen Team ‚Ä¢ 80B param√®tres ‚Ä¢ Contexte : 262,144 tokens**

Mod√®le Next 80B de Qwen, optimis√© pour les grands contextes et le raisonnement, servi via vLLM (A100).

**Sp√©cifications techniques:**
- **Vitesse** : 148 tokens/seconde
- **Consommation** : 1.54 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Grand Contexte` `MoE`

**Cas d'usage :**
- Agents conversationnels avanc√©s avec int√©gration d'outils
- Analyse de documents tr√®s volumineux (jusqu'√† 260k tokens)
- G√©n√©ration de code et t√¢ches complexes n√©cessitant raisonnement structur√©

---

### qwen3-omni:30b
**Qwen Team ‚Ä¢ 30B param√®tres ‚Ä¢ Contexte : 32,768 tokens**

Qwen3-Omni 30B est un mod√®le omnimodal natif, capable de comprendre le texte, l'image, la vid√©o et l'audio dans un m√™me flux.

**Sp√©cifications techniques:**
- **Vitesse** : 86 tokens/seconde
- **Consommation** : 2.65 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Omni` `Audio` `Vision` `Agent` `Multimodal` `BF16`

**Cas d'usage :**
- Interactions multimodales fluides (parle, voit, √©coute)
- Analyse vid√©o et audio combin√©e
- Assistants intelligents de nouvelle g√©n√©ration

---

### qwen3-vl:235b
**Qwen Team ‚Ä¢ 235B param√®tres ‚Ä¢ Contexte : 200,000 tokens**

Le mod√®le multimodal le plus puissant du catalogue, alliant une compr√©hension visuelle de pointe √† des capacit√©s de raisonnement exceptionnelles.

**Sp√©cifications techniques:**
- **Vitesse** : 31 tokens/seconde
- **Consommation** : 7.35 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Grand Contexte` `NVFP4` `Blackwell` `Vision`

**Cas d'usage :**
- Automatisation de processus documentaires complexes (OCR multilingue, extraction structur√©e)
- Agents visuels intelligents pour l'interaction logicielle et l'automatisation d'interface
- Analyse scientifique et technique avanc√©e (STEM, raisonnement spatial 3D)
- RAG Multimodal sur documents volumineux (>200k tokens) et vid√©os

---

### qwen3-vl:30b
**Qwen Team ‚Ä¢ 30B param√®tres ‚Ä¢ Contexte : 250,000 tokens**

Mod√®le multimodal de pointe (Qwen3-VL) offrant une compr√©hension visuelle exceptionnelle et un raisonnement temporel pr√©cis.

**Sp√©cifications techniques:**
- **Vitesse** : 43 tokens/seconde
- **Consommation** : 3.10 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `Agent` `Grand Contexte` `Multimodal` `Vid√©o` `OCR`

**Cas d'usage :**
- Analyse approfondie de vid√©os longues et surveillance intelligente
- Extraction de donn√©es structur√©es complexes (documents, tableaux, graphiques)
- Assistants visuels avanc√©s avec compr√©hension spatiale
- Raisonnement multimodal sur des s√©quences d'√©v√©nements

---

### qwen3-vl:32b
**Qwen Team ‚Ä¢ 32B param√®tres ‚Ä¢ Contexte : 250,000 tokens**

Variante haute performance de Qwen3-VL, optimis√©e pour les t√¢ches de vision les plus exigeantes.

**Sp√©cifications techniques:**
- **Vitesse** : 17 tokens/seconde
- **Consommation** : 7.84 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `Agent` `Grand Contexte` `Multimodal` `Vid√©o` `OCR`

**Cas d'usage :**
- Analyse scientifique et technique d'images haute r√©solution
- Automatisation de processus visuels complexes
- Compr√©hension d√©taill√©e de sc√®nes dynamiques

---

### qwen3:14b
**Qwen Team ‚Ä¢ 14B param√®tres ‚Ä¢ Contexte : 131,072 tokens**

Mod√®le Qwen3 14B √©quilibr√©, offrant de solides performances g√©n√©rales avec une bonne vitesse d'inf√©rence.

**Sp√©cifications techniques:**
- **Vitesse** : 68.2 tokens/seconde
- **Consommation** : 0.90 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Polyvalent` `Multilingue`

**Cas d'usage :**
- Assistants virtuels performants
- G√©n√©ration de contenu de qualit√©
- T√¢ches de classification et d'extraction

---

## Mod√®les Sp√©cialis√©s

### bge-m3:567m
**BAAI ‚Ä¢ 567M param√®tres ‚Ä¢ Contexte : 8,192 tokens**

Mod√®le d'embedding multilingue de pointe (BGE-M3), offrant des capacit√©s de recherche s√©mantique exceptionnelles sur plus de 100 langues.

**Sp√©cifications techniques:**
- **Vitesse** : 171 tokens/seconde
- **Consommation** : 0.36 kWh/million tokens
- **Licence** : [MIT](./licences/mit.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Embedding` `Multilingue` `Efficient`

**Cas d'usage :**
- Recherche s√©mantique multilingue
- Retrieval-Augmented Generation (RAG)
- Clustering et classification de documents

---

### deepseek-ocr
**DeepSeek AI ‚Ä¢ 3B param√®tres ‚Ä¢ Contexte : 8,192 tokens**

Mod√®le OCR sp√©cialis√© de DeepSeek, con√ßu pour une extraction de texte haute pr√©cision avec pr√©servation de la mise en forme.

**Sp√©cifications techniques:**
- **Vitesse** : 79 tokens/seconde
- **Consommation** : 1.01 kWh/million tokens
- **Licence** : [MIT licence](./licences/mit_licence.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚ùå Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `OCR` `Efficient`

**Cas d'usage :**
- Extraction de texte structur√© (Markdown/latex) depuis des images/PDF
- Num√©risation de documents avec tableaux et formules complexes

---

### devstral-small-2:24b
**Mistral AI & All Hands AI ‚Ä¢ 24B param√®tres ‚Ä¢ Contexte : 380,000 tokens**

Seconde it√©ration de Devstral (Small 2), mod√®le agentique de pointe pour l'ing√©nierie logicielle, d√©ploy√© sur Mac Studio avec un contexte massif.

**Sp√©cifications techniques:**
- **Vitesse** : 23 tokens/seconde
- **Consommation** : 5.80 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Agent` `Programmation` `Vision` `Open-Source` `Tr√®s Grand Contexte`

**Cas d'usage :**
- Agents de codage autonomes sur tr√®s grandes bases de code
- Modernisation de syst√®mes legacy
- Correction de bugs complexes n√©cessitant une vision globale du projet

---

### devstral:24b
**Mistral AI & All Hands AI ‚Ä¢ 24B param√®tres ‚Ä¢ Contexte : 120,000 tokens**

Devstral 24b est un LLM agentique sp√©cialis√© pour l'ing√©nierie logicielle, co-d√©velopp√© par Mistral AI et All Hands AI.

**Sp√©cifications techniques:**
- **Vitesse** : 44 tokens/seconde
- **Consommation** : 3.28 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Agent` `Programmation` `Open-Source` `Grand Contexte` `FP8`

**Cas d'usage :**
- Exploration et modification de bases de code
- Agents autonomes d'ing√©nierie logicielle
- Refactoring et g√©n√©ration de code complexe

---

### embeddinggemma:300m
**Google ‚Ä¢ 300M param√®tres ‚Ä¢ Contexte : 2,048 tokens**

Mod√®le d'embedding de pointe de Google, optimis√© pour sa taille, id√©al pour les t√¢ches de recherche et de r√©cup√©ration s√©mantique.

**Sp√©cifications techniques:**
- **Vitesse** : 175 tokens/seconde
- **Consommation** : 0.35 kWh/million tokens
- **Licence** : [Google Gemma Terms of Use](./licences/google_gemma_terms_of_use.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Embedding` `Compact` `S√©mantique` `Efficient` `Multilingue`

**Cas d'usage :**
- Recherche et r√©cup√©ration d'informations (Retrieval)
- Classification et clustering de documents
- Recherche de similarit√© s√©mantique
- D√©ploiement sur des appareils √† ressources limit√©es (mobile, laptop)

---

### gemma3:1b
**Google ‚Ä¢ 1B param√®tres ‚Ä¢ Contexte : 120,000 tokens**

Micro-mod√®le Gemma 3, ultra-rapide et efficace.

**Sp√©cifications techniques:**
- **Vitesse** : 53 tokens/seconde
- **Consommation** : 1.15 kWh/million tokens
- **Licence** : [Google Gemma Terms of Use](./licences/google_gemma_terms_of_use.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Compact` `Efficient` `Edge`

**Cas d'usage :**
- Classification de texte rapide
- Chatbots simples
- Prototypage rapide

---

### gemma3:4b
**Google ‚Ä¢ 4B param√®tres ‚Ä¢ Contexte : 120,000 tokens**

Mod√®le compact Gemma 3 4B, offrant un excellent ratio performance/taille.

**Sp√©cifications techniques:**
- **Vitesse** : 48.0 tokens/seconde
- **Consommation** : 1.27 kWh/million tokens
- **Licence** : [Google Gemma Terms of Use](./licences/google_gemma_terms_of_use.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Compact` `Efficient` `Edge`

**Cas d'usage :**
- Assistants personnels sur laptop
- R√©sum√© de texte
- Traduction l√©g√®re

---

### gpt-oss:20b
**OpenAI ‚Ä¢ 20B param√®tres ‚Ä¢ Contexte : 120,000 tokens**

Mod√®le de langage open-weight d'OpenAI, optimis√© pour l'efficacit√© et le d√©ploiement sur du mat√©riel grand public.

**Sp√©cifications techniques:**
- **Vitesse** : 9 tokens/seconde
- **Consommation** : 14.81 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `MoE` `Agent` `Raisonnement` `Open-Source` `Compact` `Rapide`

**Cas d'usage :**
- D√©ploiements sur des appareils √† ressources limit√©es (edge devices) ou des serveurs √† faible co√ªt.
- Applications n√©cessitant une inf√©rence rapide avec de bonnes capacit√©s de raisonnement.
- Cas d'usage agentiques avec appel de fonctions, navigation web et ex√©cution de code.
- Fine-tuning pour des t√¢ches sp√©cialis√©es sur du mat√©riel grand public.

---

### granite-embedding:278m
**IBM ‚Ä¢ 278M param√®tres ‚Ä¢ Contexte : 8,192 tokens**

Mod√®le d'embedding IBM Granite ultra-compact, con√ßu pour une efficacit√© maximale.

**Sp√©cifications techniques:**
- **Vitesse** : 196.3 tokens/seconde
- **Consommation** : 0.31 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Embedding` `Compact` `Efficient`

**Cas d'usage :**
- Recherche s√©mantique
- Clustering de documents

---

### granite4-small-h:32b
**IBM ‚Ä¢ 32B (9B actifs) param√®tres ‚Ä¢ Contexte : 128,000 tokens**

Mod√®le MoE (Mixture-of-Experts) d'IBM, con√ßu comme un "cheval de bataille" pour les t√¢ches d'entreprise quotidiennes, avec une excellente efficacit√© pour les longs contextes.

**Sp√©cifications techniques:**
- **Vitesse** : 33 tokens/seconde
- **Consommation** : 4.04 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Agent` `Raisonnement` `S√©curit√©` `MoE` `Grand Contexte` `Efficient`

**Cas d'usage :**
- Agents conversationnels pour le support client avec acc√®s √† des bases de connaissances √©tendues.
- Automatisation de workflows d'entreprise n√©cessitant l'utilisation de plusieurs outils.
- Analyse de documents longs avec une consommation de ressources optimis√©e.
- D√©ploiements sur des infrastructures de taille moyenne gr√¢ce √† son efficacit√©.

---

### granite4-tiny-h:7b
**IBM ‚Ä¢ 7B (1B actif) param√®tres ‚Ä¢ Contexte : 128,000 tokens**

Mod√®le MoE hybride ultra-efficace d'IBM, con√ßu pour la faible latence, les applications "edge" et locales, et comme brique de base pour les workflows agentiques.

**Sp√©cifications techniques:**
- **Vitesse** : 58 tokens/seconde
- **Consommation** : 1.05 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Agent` `Raisonnement` `S√©curit√©` `MoE` `Grand Contexte` `Efficient` `Rapide` `Compact`

**Cas d'usage :**
- Applications embarqu√©es et "edge" n√©cessitant une faible latence.
- T√¢ches rapides au sein de workflows agentiques plus larges (ex : function calling).
- Analyse de documents sur du mat√©riel grand public.
- D√©ploiements n√©cessitant une empreinte m√©moire minimale.

---

### medgemma:27b
**Google ‚Ä¢ 27B param√®tres ‚Ä¢ Contexte : 128,000 tokens**

MedGemma est un mod√®le ouvert parmis les plus performants de Google pour la compr√©hension de textes et d'images m√©dicales, bas√©s sur Gemma 3.

**Sp√©cifications techniques:**
- **Vitesse** : 22 tokens/seconde
- **Consommation** : 6.56 kWh/million tokens
- **Licence** : [Google Gemma Terms of Use](./licences/google_gemma_terms_of_use.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `M√©dical` `Vision` `Sp√©cialis√©` `Grand Contexte`

**Cas d'usage :**
- Interpr√©tation d'images m√©dicales (G√©n√©ration de rapports et VQA)
- Compr√©hension de textes m√©dicaux et raisonnement clinique (Aide √† la d√©cision)
- Interaction patient (Entretien et triage m√©dical)
- Synth√®se de dossiers m√©dicaux et recherche dans la litt√©rature

---

### ministral-3:3b
**Mistral AI ‚Ä¢ 3B param√®tres ‚Ä¢ Contexte : 250,000 tokens**

Mod√®le compact de pointe de Mistral AI, con√ßu pour l'efficacit√© sur les d√©ploiements locaux et edge.

**Sp√©cifications techniques:**
- **Vitesse** : 50 tokens/seconde
- **Consommation** : 1.22 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Compact` `Efficient` `Edge`

**Cas d'usage :**
- Inf√©rence locale sur appareils mobiles ou edge devices
- Assistants personnels r√©actifs
- T√¢ches de routage et classification rapides

---

### ministral-3:8b
**Mistral AI ‚Ä¢ 8B param√®tres ‚Ä¢ Contexte : 250,000 tokens**

Mod√®le de taille interm√©diaire de la famille Ministral, offrant un √©quilibre optimal entre performance et ressources.

**Sp√©cifications techniques:**
- **Vitesse** : 55 tokens/seconde
- **Consommation** : 2.42 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Efficient` `Edge` `Raisonnement`

**Cas d'usage :**
- Assistants conversationnels avanc√©s en local
- Analyse de documents et extraction d'informations
- T√¢ches n√©cessitant un bon compromis vitesse/qualit√©

---

### mistral-small3.2:24b
**Mistral AI ‚Ä¢ 24B param√®tres ‚Ä¢ Contexte : 128,000 tokens**

Mise √† jour mineure de Mistral Small 3.1, am√©liorant le suivi d'instructions, la robustesse du function calling et r√©duisant les erreurs de r√©p√©tition.

**Sp√©cifications techniques:**
- **Vitesse** : 27 tokens/seconde
- **Consommation** : 5.35 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Vision` `Agent` `S√©curit√©` `Instruction Following`

**Cas d'usage :**
- Agents conversationnels avec un suivi d'instructions am√©lior√©
- Int√©gration robuste avec des outils externes via function calling
- Applications n√©cessitant une grande fiabilit√© pour √©viter les r√©p√©titions
- Cas d'usage identiques √† Mistral Small 3.1 avec des performances accrues

---

### qwen3-2507-think:4b
**Qwen Team ‚Ä¢ 4B param√®tres ‚Ä¢ Contexte : 250,000 tokens**

Mod√®le Qwen3-4B optimis√© pour le raisonnement, avec des performances am√©lior√©es sur les t√¢ches logiques, les math√©matiques, la science et le code, et un contexte √©tendu √† 250K tokens.

**Sp√©cifications techniques:**
- **Vitesse** : 52 tokens/seconde
- **Consommation** : 2.56 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Grand Contexte` `Compact` `Rapide`

**Cas d'usage :**
- T√¢ches de raisonnement tr√®s complexes (logique, maths, science, code).
- Agents conversationnels avec un historique de conversation tr√®s √©tendu (256k tokens).
- Analyse de documents tr√®s volumineux avec raisonnement profond.
- Int√©gration avec des outils externes via function calling sur de tr√®s grands contextes.

---

### qwen3-2507:4b
**Qwen Team ‚Ä¢ 4B param√®tres ‚Ä¢ Contexte : 250,000 tokens**

Version mise √† jour du mode non-pens√©e de Qwen3-4B, avec des am√©liorations significatives des capacit√©s g√©n√©rales, une couverture de connaissances √©tendue et un meilleur alignement avec les pr√©f√©rences des utilisateurs.

**Sp√©cifications techniques:**
- **Vitesse** : 30 tokens/seconde
- **Consommation** : 4.44 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Grand Contexte` `Compact` `Rapide` `Multilingue`

**Cas d'usage :**
- T√¢ches g√©n√©rales n√©cessitant un suivi d'instructions pr√©cis et un raisonnement logique.
- Applications multilingues avec une large couverture de connaissances.
- G√©n√©ration de texte de haute qualit√© pour des t√¢ches ouvertes et subjectives.
- Analyse de documents tr√®s volumineux gr√¢ce au contexte de 256k tokens.

---

### qwen3-embedding:0.6b
**Qwen Team ‚Ä¢ 0.6B param√®tres ‚Ä¢ Contexte : 32,768 tokens**

Mod√®le d'embedding Qwen3 ultra-l√©ger, optimis√© pour la vitesse et l'efficacit√© sur les infrastructures √† ressources limit√©es.

**Sp√©cifications techniques:**
- **Vitesse** : N/A
- **Consommation** : 0.57 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Embedding` `Compact` `Efficient`

**Cas d'usage :**
- Recherche s√©mantique rapide
- Classification de texte en temps r√©el

---

### qwen3-embedding:4b
**Qwen Team ‚Ä¢ 4B param√®tres ‚Ä¢ Contexte : 40,000 tokens**

Mod√®le d'embedding Qwen3-4B ultra-performant, offrant une compr√©hension s√©mantique profonde et une fen√™tre de contexte √©tendue.

**Sp√©cifications techniques:**
- **Vitesse** : N/A
- **Consommation** : 0.57 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Embedding` `Grand Contexte` `Efficient`

**Cas d'usage :**
- Recherche s√©mantique sur documents longs
- RAG avec fen√™tres de contexte √©tendues
- Analyse s√©mantique de pr√©cision

---

### qwen3-vl:2b
**Qwen Team ‚Ä¢ 2B param√®tres ‚Ä¢ Contexte : 250,000 tokens**

Mod√®le multimodal ultra-compact Qwen3-VL, apportant des capacit√©s de vision avanc√©es sur edge devices.

**Sp√©cifications techniques:**
- **Vitesse** : 64 tokens/seconde
- **Consommation** : 0.95 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `Compact` `Efficient` `Multimodal` `Edge` `OCR`

**Cas d'usage :**
- Analyse d'images en temps r√©el sur appareils mobiles
- OCR et lecture de documents l√©gers
- Tri et classification visuelle rapide

---

### qwen3-vl:4b
**Qwen Team ‚Ä¢ 4B param√®tres ‚Ä¢ Contexte : 250,000 tokens**

Mod√®le multimodal Qwen3-VL √©quilibr√©, offrant de solides performances de vision avec une empreinte r√©duite.

**Sp√©cifications techniques:**
- **Vitesse** : 57 tokens/seconde
- **Consommation** : 2.34 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `Compact` `Multimodal` `Efficient` `Vid√©o` `OCR`

**Cas d'usage :**
- Analyse documentaire automatis√©e (factures, formulaires)
- Compr√©hension de contenu vid√©o
- Assistants visuels interactifs

---

### qwen3-vl:8b
**Qwen Team ‚Ä¢ 8B param√®tres ‚Ä¢ Contexte : 250,000 tokens**

Mod√®le multimodal Qwen3-VL (8B), offrant des performances de vision avanc√©es avec une empreinte raisonnable.

**Sp√©cifications techniques:**
- **Vitesse** : 44 tokens/seconde
- **Consommation** : 3.03 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `Compact` `Multimodal` `Efficient` `Vid√©o` `OCR`

**Cas d'usage :**
- Analyse documentaire automatis√©e
- Compr√©hension de contenu vid√©o
- Assistants visuels interactifs

---

### qwen3:0.6b
**Qwen Team ‚Ä¢ 0.6B param√®tres ‚Ä¢ Contexte : 40,000 tokens**

Mod√®le Qwen3 ultra-l√©ger de 0.6 milliard de param√®tres, offrant une vitesse d'inf√©rence exceptionnelle pour les t√¢ches simples et rapides.

**Sp√©cifications techniques:**
- **Vitesse** : 46 tokens/seconde
- **Consommation** : 1.33 kWh/million tokens
- **Licence** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Compact` `Rapide` `Efficient` `Multilingue`

**Cas d'usage :**
- T√¢ches de traitement de texte simples
- Classification et tri rapide
- Assistants l√©gers avec faible latence

---

### rnj-1:8b
**Essential AI ‚Ä¢ 8B param√®tres ‚Ä¢ Contexte : 32,000 tokens**

Mod√®le 8B "Open Weight" sp√©cialis√© dans le code, les math√©matiques et les sciences (STEM).

**Sp√©cifications techniques:**
- **Vitesse** : 31 tokens/seconde
- **Consommation** : 1.97 kWh/million tokens
- **Licence** : [Open Weights](./licences/open_weights.licence.md)
- **Localisation** : FR üá´üá∑

**Capacit√©s:**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Code` `Maths` `STEM` `Raisonnement` `Efficient`

**Cas d'usage :**
- Assistant de programmation avanc√© et g√©n√©ration de code
- R√©solution de probl√®mes math√©matiques complexes
- T√¢ches scientifiques et techniques (STEM)

---

## Cas d'Usage Recommand√©s

### Dialogue multilingue

Chatbots et assistants capables de communiquer dans plusieurs langues avec d√©tection automatique, maintien du contexte sur l'ensemble de la conversation et compr√©hension des sp√©cificit√©s linguistiques

**Mod√®les recommand√©s:**

- Llama 3.3
- Mistral Small 3.2
- Qwen 3
- Openai OSS
- Granite 4

### Analyse de documents longs

Traitement de documents volumineux (>100 pages) avec maintien du contexte sur l'ensemble du texte, extraction d'informations cl√©s, g√©n√©ration de r√©sum√©s pertinents et r√©ponse √† des questions sp√©cifiques sur le contenu

**Mod√®les recommand√©s:**

- Gemma 3
- Qwen next
- Qwen 3
- Granite 4

### Programmation et d√©veloppement

G√©n√©ration et optimisation de code dans multiples langages, d√©bogage, refactoring, d√©veloppement de fonctionnalit√©s compl√®tes, compr√©hension des impl√©mentations algorithmiques complexes et cr√©ation de tests unitaires

**Mod√®les recommand√©s:**

- DeepCoder
- Qwen3 coder
- Granite 4
- Devstral

### Analyse visuelle

Traitement direct d'images et documents visuels sans pr√©-traitement OCR, interpr√©tation de diagrammes techniques, graphiques, tableaux, dessins et photos avec g√©n√©ration d'explications textuelles d√©taill√©es du contenu visuel

**Mod√®les recommand√©s:**

- deepseek-OCR
- Mistral Small 3.2
- Gemma 3
- Qwen 3 VL

### S√©curit√© et conformit√©

Applications n√©cessitant des capacit√©s sp√©cifiques en mati√®re de s√©curit√© ; filtrage de contenu sensible, tra√ßabilit√© des raisonnements, v√©rification RGPD/HDS, minimisation des risques, analyse des vuln√©rabilit√©s et respect des r√©glementations sectorielles

**Mod√®les recommand√©s:**

- Granite Guardian
- Granite 4
- Devstral
- Mistral Small 3.2
- Magistral small

### D√©ploiements l√©gers et embarqu√©s

Applications n√©cessitant une empreinte minimale en ressources, d√©ploiement sur appareils √† capacit√© limit√©e, inf√©rence en temps r√©el sur CPU standard et int√©gration dans des syst√®mes embarqu√©s ou IoT

**Mod√®les recommand√©s:**

- Gemma 3n
- Granite 4 tiny
- Qwen 3 VL (2B)
