# URL de l'API Cloud Temple LLMaaS (par défaut https://api.ai.cloud-temple.com/v1)
CLOUDTEMPLE_API_URL=https://api.ai.cloud-temple.com/v1/chat/completions

# Clé API pour Cloud Temple LLMaaS
CLOUDTEMPLE_API_KEY="WolFH3xGSCMPvlfEru5JAt_KWZIrYreQOm1dDB2x5X4"

# Optionnel: Chemin de base de la documentation (par défaut '.')
# DOC_BASE_PATH=.

# Optionnel: Modèle de traduction (par défaut 'qwen3:30b-a3b')
TRANSLATION_MODEL=qwen3-2507:30b-a3b

# Optionnel: Type de modèle pour la gestion du tokenizer ('openai' ou 'other', par défaut 'other')
MODEL_TYPE=openai

# Optionnel: Température pour la traduction (par défaut '1')
TRANSLATION_TEMPERATURE=0.1

# Optionnel: Top_p pour la traduction (par défaut '1')
# TRANSLATION_TOP_P=1

# Optionnel: Nombre de fichiers à traduire en parallèle (par défaut 4 dans le script)
CONCURRENT_TRANSLATIONS=16
MAX_RETRIES=5
RETRY_DELAY=5.0

# Optionnel: Taille maximale d'un bloc de traduction en tokens (par défaut 5000)
MAX_TOKENS_PER_BLOCK=4000

# Optionnel: Longueur maximale du contexte du modèle en tokens (par défaut 32768 pour qwen3:30b-a3b)
MAX_MODEL_CONTEXT_LENGTH=32000

# Optionnel: Nombre de tokens de sécurité à soustraire du contexte disponible (par défaut 200)
BUFFER_TOKENS=200
