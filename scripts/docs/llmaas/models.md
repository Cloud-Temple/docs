---
title: Catalogue des Mod√®les LLMaaS
sidebar_position: 2
---

# Catalogue des Mod√®les LLM as a Service

## Vue d'ensemble

Cloud Temple LLMaaS propose **45 mod√®les de langage large** soigneusement s√©lectionn√©s et optimis√©s pour r√©pondre aux exigences **SecNumCloud** les plus strictes. Notre catalogue couvre l'ensemble du spectre, des micro-mod√®les ultra-efficaces aux mod√®les extr√™mement volumineux.

### Statistiques Globales

| M√©trique | Valeur |
|----------|--------|
| **Nombre total de mod√®les** | 45 mod√®les |
| **Contexte minimum** | 8 192 tokens |
| **Contexte maximum** | 128 000 tokens |
| **Conformit√©** | SecNumCloud ‚úÖ HDS ‚úÖ Souverainet√© ‚úÖ C5 ‚ùå |
| **Localisation** | 100% France üá´üá∑ |

### Tarification

| Type d'utilisation | Prix |
|-------------------|------|
| **Tokens d'entr√©e** | 0.9‚Ç¨ / million de tokens |
| **Tokens de sortie** | 4‚Ç¨ / million de tokens |
| **Raisonnement avanc√©** | 21‚Ç¨ / million de tokens |

## Mod√®les de Grande Taille

### Llama 3.3 70B
**Meta ‚Ä¢ 70B param√®tres ‚Ä¢ Contexte : 60 000 tokens**

Mod√®le multilingue de pointe d√©velopp√© par Meta, con√ßu pour exceller dans le dialogue naturel, le raisonnement complexe et la compr√©hension nuanc√©e des instructions.

**Sp√©cifications techniques :**
- **Vitesse** : 26 tokens/seconde tokens/seconde
- **Consommation** : 11.75 kWh/million tokens
- **Licence** : LLAMA 3.3 Community Licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Dialogue` `Multilingue`

**Cas d'usage :**
- Chatbots multilingues prenant en charge 8 langues simultan√©ment
- Ex√©cution d'instructions complexes encha√Æn√©es (prompt chaining)
- Traitement d'une fen√™tre de dialogue de 60K tokens pour historique conversationnel
- Analyse de documents juridiques ou techniques volumineux (>100 pages)
- G√©n√©ration de textes structur√©s avec fid√©lit√© aux consignes stylistiques

---

### Qwen3 235B
**Qwen Team ‚Ä¢ 235B param√®tres ‚Ä¢ Contexte : 60 000 tokens**

Mod√®le tr√®s volumineux de la nouvelle g√©n√©ration Qwen3, offrant des capacit√©s √©tendues pour les t√¢ches les plus complexes.

**Sp√©cifications techniques :**
- **Vitesse** : 17 tokens/seconde tokens/seconde
- **Consommation** : 7.84 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Multilingue` `Tr√®s Large`

**Cas d'usage :**
- Agents conversationnels tr√®s avanc√©s avec grand contexte et int√©gration d'outils (MCP)
- R√©solution de probl√®mes extr√™mement complexes (maths, code)
- Analyse et g√©n√©ration de documents tr√®s volumineux et techniques
- Applications multilingues (>100 langues) n√©cessitant une compr√©hension et une g√©n√©ration de tr√®s haute fid√©lit√©

---

### DeepSeek-R1 671B
**DeepSeek AI ‚Ä¢ 671B param√®tres ‚Ä¢ Contexte : 16 000 tokens**

Mod√®le extr√™mement volumineux de DeepSeek AI, con√ßu pour le summum du raisonnement et de la g√©n√©ration.

**Sp√©cifications techniques :**
- **Vitesse** : 12 tokens/seconde tokens/seconde
- **Consommation** : 11.11 kWh/million tokens
- **Licence** : MIT Licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Raisonnement` `Extr√™mement Large`

**Cas d'usage :**
- T√¢ches de raisonnement de pointe
- G√©n√©ration de texte de qualit√© sup√©rieure
- Recherche et d√©veloppement en IA

---

### Gemma 3 27B
**Google ‚Ä¢ 27B param√®tres ‚Ä¢ Contexte : 120 000 tokens**

Mod√®le r√©volutionnaire de Google offrant un √©quilibre optimal entre puissance et efficacit√©, avec un rapport performance/co√ªt exceptionnel pour les applications professionnelles exigeantes.

**Sp√©cifications techniques :**
- **Vitesse** : 20 tokens/seconde tokens/seconde
- **Consommation** : 6.67 kWh/million tokens
- **Licence** : Google Gemma Terms of Use
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `Agent` `Grand contexte`

**Cas d'usage :**
- Analyse de documents avec contexte √©tendu jusqu'√† 120K tokens (environ 400 pages)
- Indexation et recherche s√©mantique dans des bases documentaires volumineuses
- Traitement d'images et texte en simultan√© gr√¢ce aux capacit√©s multimodales
- Extraction structur√©e de donn√©es √† partir de PDF et documents scann√©s
- Int√©gration avec des outils externes via l'API function calling

---

### Qwen3 30B-A3B FP8
**Qwen Team ‚Ä¢ 30B-A3B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le MoE FP8 (3B activ√©s) nouvelle g√©n√©ration, avec modes de pens√©e hybrides et capacit√©s agentiques avanc√©es.

**Sp√©cifications techniques :**
- **Vitesse** : 106 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 2.88 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `MoE` `Agent` `Raisonnement` `Rapide` `Multilingue`

**Cas d'usage :**
- Agents conversationnels avanc√©s avec int√©gration d'outils (MCP)
- R√©solution de probl√®mes complexes (maths, code) avec mode "Thinking"
- Applications multilingues (>100 langues)
- Sc√©narios n√©cessitant un √©quilibre co√ªt/performance (MoE) sur VLLM
- Dialogue multi-tours engageant et suivi d'instructions pr√©cis

---

### DeepSeek-R1 70B
**DeepSeek AI ‚Ä¢ 70B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le 70B de DeepSeek AI

**Sp√©cifications techniques :**
- **Vitesse** : 21 tokens/seconde tokens/seconde
- **Consommation** : 12.56 kWh/million tokens
- **Licence** : MIT Licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Raisonnement` `Large`

**Cas d'usage :**
- T√¢ches de raisonnement de pointe
- G√©n√©ration de texte de qualit√© sup√©rieure
- Recherche et d√©veloppement en IA

---

### Qwen2.5-VL 32B
**Qwen Team ‚Ä¢ 32B param√®tres ‚Ä¢ Contexte : 120 000 tokens**

Version la plus puissante de la s√©rie Qwen2.5-VL, offrant des capacit√©s de compr√©hension visuelle et d'agentique de pointe.

**Sp√©cifications techniques :**
- **Vitesse** : 18 tokens/seconde tokens/seconde
- **Consommation** : 7.41 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `Agent` `Raisonnement` `OCR` `Localisation Visuelle` `Large`

**Cas d'usage :**
- Analyse de documents et de diagrammes tr√®s complexes
- Agents visuels autonomes pour la navigation et l'interaction avec des GUI
- T√¢ches de localisation d'objets et de reconnaissance de texte de haute pr√©cision
- G√©n√©ration de descriptions riches et d√©taill√©es √† partir d'images complexes

---

### Qwen2.5-VL 72B
**Qwen Team ‚Ä¢ 72B param√®tres ‚Ä¢ Contexte : 128 000 tokens**

Version la plus puissante de la s√©rie Qwen2.5-VL, offrant des capacit√©s de compr√©hension visuelle et d'agentique de pointe pour les t√¢ches les plus exigeantes.

**Sp√©cifications techniques :**
- **Vitesse** : 15 tokens/seconde tokens/seconde
- **Consommation** : 8.89 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `Agent` `Raisonnement` `OCR` `Localisation Visuelle` `Tr√®s Large`

**Cas d'usage :**
- Analyse de documents et de diagrammes tr√®s complexes
- Agents visuels autonomes pour la navigation et l'interaction avec des GUI
- T√¢ches de localisation d'objets et de reconnaissance de texte de tr√®s haute pr√©cision
- G√©n√©ration de descriptions riches et d√©taill√©es √† partir d'images tr√®s complexes

---

## Mod√®les Sp√©cialis√©s

### Qwen3 14B
**Qwen Team ‚Ä¢ 14B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le dense nouvelle g√©n√©ration Qwen3 (14B), offrant des performances √©quivalentes √† Qwen2.5 32B avec une meilleure efficacit√©.

**Sp√©cifications techniques :**
- **Vitesse** : 68 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 3.88 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Rapide` `Multilingue`

**Cas d'usage :**
- T√¢ches g√©n√©rales n√©cessitant performance et grand contexte
- G√©n√©ration de contenu cr√©atif et technique
- Analyse de donn√©es et raisonnement complexe
- Int√©gration avec des outils externes via function calling

---

### Gemma 3 12B
**Google ‚Ä¢ 12B param√®tres ‚Ä¢ Contexte : 120 000 tokens**

Version interm√©diaire du mod√®le Gemma 3 offrant un excellent √©quilibre entre performance et efficacit√©.

**Sp√©cifications techniques :**
- **Vitesse** : 56 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 4.71 kWh/million tokens
- **Licence** : Google Gemma Terms of Use
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `Rapide` `Grand Contexte`

**Cas d'usage :**
- Applications multimodales avec contraintes de ressources mod√©r√©es
- Traitement de documents avec contexte standard (jusqu'√† 100 pages)
- G√©n√©ration de contenu textuel et analyse d'images combin√©es
- D√©ploiements sur GPU standard sans infrastructure sp√©cialis√©e
- Chatbots avanc√©s avec capacit√©s visuelles et textuelles int√©gr√©es

---

### Gemma 3 4B
**Google ‚Ä¢ 4B param√®tres ‚Ä¢ Contexte : 120 000 tokens**

Mod√®le compact de Google offrant d'excellentes performances dans un format l√©ger et √©conomique.

**Sp√©cifications techniques :**
- **Vitesse** : 57 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 0.58 kWh/million tokens üå±
- **Licence** : Google Gemma Terms of Use
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `Rapide` `Compact` `Grand Contexte` `Efficient`

**Cas d'usage :**
- Applications embarqu√©es et edge computing avec traitement d'images
- Chatbots multimodaux r√©actifs n√©cessitant une faible latence
- D√©ploiements √† grande √©chelle avec capacit√©s visuelles et textuelles
- Applications mobiles avec analyse d'images et textes
- Traitement de requ√™tes visuelles simples √† moyenne complexit√© avec haute performance

---

### Gemma 3 1B
**Google ‚Ä¢ 1B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Micro-mod√®le ultra-l√©ger con√ßu pour les d√©ploiements sur appareils √† tr√®s faibles ressources.

**Sp√©cifications techniques :**
- **Vitesse** : 112 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 0.15 kWh/million tokens üå±
- **Licence** : Google Gemma Terms of Use
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Ultra-compact` `Embarqu√©` `Efficient` `Rapide`

**Cas d'usage :**
- D√©ploiement sur appareils IoT et syst√®mes embarqu√©s avec int√©gration API
- Applications n√©cessitant inf√©rence locale sur CPU avec appels √† des fonctions
- T√¢ches textuelles basiques avec temps de r√©ponse instantan√© et function calling
- Assistants compacts pour applications grand public avec int√©gration services externes
- Syst√®mes de contr√¥le intelligents int√©grant plusieurs APIs/services

---

### Lucie-7B-Instruct
**OpenLLM-France ‚Ä¢ 7B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le causal multilingue open-source (7B), fine-tun√© depuis Lucie-7B. Optimis√© pour le fran√ßais.

**Sp√©cifications techniques :**
- **Vitesse** : 4 tokens/seconde tokens/seconde
- **Consommation** : 8.33 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Fran√ßais` `Open-Source` `Efficient`

---

### Mistral Small 3.1
**Mistral AI ‚Ä¢ 24B param√®tres ‚Ä¢ Contexte : 120 000 tokens**

Mod√®le compact et r√©actif de Mistral AI, sp√©cialement con√ßu pour offrir une assistance conversationnelle fluide et pertinente avec une vitesse de r√©ponse optimale.

**Sp√©cifications techniques :**
- **Vitesse** : 35 tokens/seconde tokens/seconde
- **Consommation** : 3.72 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Vision` `Agent` `S√©curit√©`

**Cas d'usage :**
- Applications conversationnelles
- Assistants virtuels combinant analyse d'images et texte (26 tokens/s)
- Chatbots de support technique avec acc√®s √† la documentation technique
- Outils de cr√©ation/√©dition de contenu avec r√©ponse imm√©diate (blogs, emails)
- D√©ploiement sur infrastructures standard (24B de param√®tres)

---

### Mistral Small 3.2
**Mistral AI ‚Ä¢ 24B param√®tres ‚Ä¢ Contexte : 120 000 tokens**

Mise √† jour mineure de Mistral Small 3.1, am√©liorant le suivi d'instructions, la robustesse du function calling et r√©duisant les erreurs de r√©p√©tition.

**Sp√©cifications techniques :**
- **Vitesse** : 35 tokens/seconde tokens/seconde
- **Consommation** : 3.72 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Vision` `Agent` `S√©curit√©` `Instruction Following`

**Cas d'usage :**
- Agents conversationnels avec un suivi d'instructions am√©lior√©
- Int√©gration robuste avec des outils externes via function calling
- Applications n√©cessitant une grande fiabilit√© pour √©viter les r√©p√©titions
- Cas d'usage identiques √† Mistral Small 3.1 avec des performances accrues

---

### DeepCoder
**Agentica x Together AI ‚Ä¢ 14B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le IA open source (14B) par Together AI & Agentica, alternative cr√©dible aux mod√®les propri√©taires pour la g√©n√©ration de code.

**Sp√©cifications techniques :**
- **Vitesse** : 64 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 4.12 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Programmation` `Raisonnement` `Open-Source` `Math√©matiques` `Rapide`

**Cas d'usage :**
- G√©n√©ration de code dans plus de 15 langages avec optimisation des performances
- D√©bogage et refactoring de bases de code existantes avec analyse d'impact
- Impl√©mentation d'algorithmes complexes (graphes, arbres, heuristiques)
- Cr√©ation automatis√©e de tests unitaires avec couverture de code > 80%
- Transposition de code entre langagesframeworks (par exemple Python vers JavaScript)

---

### Granite 3.2 Vision
**IBM ‚Ä¢ 2B param√®tres ‚Ä¢ Contexte : 16 384 tokens**

Mod√®le compact r√©volutionnaire d'IBM sp√©cialis√© dans la vision par ordinateur, capable d'analyser et comprendre directement les documents visuels sans recourir √† des technologies OCR interm√©diaires.

**Sp√©cifications techniques :**
- **Vitesse** : 48 tokens/seconde tokens/seconde
- **Consommation** : 0.69 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Vision` `S√©curit√©` `Compact` `Efficient`

**Cas d'usage :**
- Extraction de donn√©es structur√©es √† partir de factures et formulaires sans OCR
- Analyse directe de tableaux et graphiques avec interpr√©tation des tendances
- Lecture et interpr√©tation de diagrammes techniques (√©lectriques, m√©caniques)
- Traitement de documents manuscrits avec taux de reconnaissance √©lev√©
- Vision par ordinateur l√©g√®re (2B param√®tres) avec vitesse √©lev√©e (50 tokens/s)

---

### Granite 3.3 8B
**IBM ‚Ä¢ 8B param√®tres ‚Ä¢ Contexte : 60 000 tokens**

Mod√®le Granite 8B fine-tun√© par IBM pour un raisonnement et un suivi d'instructions am√©lior√©s, avec un contexte de 128k tokens.

**Sp√©cifications techniques :**
- **Vitesse** : 30 tokens/seconde tokens/seconde
- **Consommation** : 1.11 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Agent` `Raisonnement` `S√©curit√©` `Efficient`

**Cas d'usage :**
- T√¢ches g√©n√©rales d'instruction-following (classification, extraction, Q&A)
- Assistants IA multilingues (12 langues)
- Traitement de documents tr√®s longs (128k tokens) pour les taches de r√©sum√©s, Q&A,...
- G√©n√©ration/compl√©tion de code avec Fill-in-the-Middle
- Int√©gration avec des outils externes via function calling
- Raisonnement structur√© avec le mode "Thinking"

---

### Granite 3.3 2B
**IBM ‚Ä¢ 2B param√®tres ‚Ä¢ Contexte : 120 000 tokens**

Mod√®le Granite 2B fine-tun√© par IBM, optimis√© pour le raisonnement et le suivi d'instructions, avec un contexte de 128k tokens.

**Sp√©cifications techniques :**
- **Vitesse** : 45 tokens/seconde tokens/seconde
- **Consommation** : 0.74 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Agent` `Raisonnement` `S√©curit√©` `Efficient`

**Cas d'usage :**
- D√©ploiements l√©gers avec grand contexte (128k tokens)
- T√¢ches g√©n√©rales d'instruction-following sur ressources limit√©es
- Assistants IA multilingues compacts
- Traitement de documents longs sur appareils moins puissants
- G√©n√©ration/compl√©tion de code FIM sur postes de travail standards

---

### Magistral 24B
**Mistral AI ‚Ä¢ 24B param√®tres ‚Ä¢ Contexte : 40 000 tokens**

Le premier mod√®le de raisonnement de Mistral AI, excellant dans le raisonnement sp√©cifique au domaine, transparent et multilingue.

**Sp√©cifications techniques :**
- **Vitesse** : 25 tokens/seconde tokens/seconde
- **Consommation** : 5.33 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Raisonnement` `Multilingue`

**Cas d'usage :**
- Strat√©gie et op√©rations commerciales (mod√©lisation des risques)
- Industries r√©glement√©es (juridique, finance) avec raisonnement tra√ßable
- Ing√©nierie logicielle (planification de projet, architecture)
- Cr√©ation de contenu et communication (r√©daction cr√©ative, narration)

---

### Granite 3.1 MoE
**IBM ‚Ä¢ 3B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le innovant d'IBM utilisant l'architecture Mixture-of-Experts (MoE) pour offrir des performances exceptionnelles tout en optimisant drastiquement l'utilisation des ressources computationnelles.

**Sp√©cifications techniques :**
- **Vitesse** : 74 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 0.45 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Agent` `S√©curit√©` `Rapide` `MoE` `Efficacit√©` `Efficient`

**Cas d'usage :**
- Applications g√©n√©ralistes avec co√ªt d'inf√©rence optimis√© (42 tokens/seconde)
- Traitement de documents dans des environnements CPU avec utilisation RAM limit√©e
- Analyses sp√©cialis√©es avec activation dynamique des parties pertinentes du mod√®le
- D√©ploiements haute densit√© avec faible consommation √©nerg√©tique par inf√©rence
- Traitement parall√®le de plusieurs types de requ√™tes avec sp√©cialisation MoE

---

### cogito:14b
**Deep Cogito ‚Ä¢ 14B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le de Deep Cogito sp√©cialement con√ßu pour exceller dans les t√¢ches de raisonnement profond et de compr√©hension contextuelle nuanc√©e, id√©al pour les applications analytiques sophistiqu√©es.

**Sp√©cifications techniques :**
- **Vitesse** : 60 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 4.4 kWh/million tokens
- **Licence** : LLAMA 3.2 Community Licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Compr√©hension` `Analyse` `Rapide`

**Cas d'usage :**
- Analyse s√©mantique de textes avec identification des implications non explicites
- Raisonnement causal structur√© avec identification des relations cause-effet
- Synth√®se de documents complexes avec extraction des informations cl√©s
- Syst√®mes de question-r√©ponse pr√©cis sur corpus documentaires sp√©cialis√©s
- Analyse argumentative avec √©valuation de la solidit√© des raisonnements

---

### Cogito 32B
**Deep Cogito ‚Ä¢ 32B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Version avanc√©e du mod√®le Cogito offrant des capacit√©s de raisonnement et d'analyse consid√©rablement amplifi√©es, con√ßue pour les applications les plus exigeantes en mati√®re d'intelligence artificielle analytique.

**Sp√©cifications techniques :**
- **Vitesse** : 32 tokens/seconde tokens/seconde
- **Consommation** : 8.25 kWh/million tokens
- **Licence** : LLAMA 3.2 Community Licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Compr√©hension` `Analyse`

**Cas d'usage :**
- Analyse de sc√©narios multi-factoriels avec √©valuation probabiliste des r√©sultats
- R√©solution de probl√®mes scientifiques avec d√©monstration formelle des √©tapes
- Applications √† haute criticit√© n√©cessitant pr√©cision et v√©rifiabilit√© des r√©sultats
- Syst√®mes experts dans des domaines sp√©cialis√©s (juridique, m√©dical, technique)
- Analyse avec raisonnement multi-√©tapes et explicabilit√© compl√®te des conclusions

---

### Qwen3 32B
**Qwen Team ‚Ä¢ 32B param√®tres ‚Ä¢ Contexte : 40 000 tokens**

Mod√®le puissant de la nouvelle g√©n√©ration Qwen3, offrant des capacit√©s avanc√©es en raisonnement, code, et agentique, avec un contexte √©tendu.

**Sp√©cifications techniques :**
- **Vitesse** : 18 tokens/seconde tokens/seconde
- **Consommation** : 7.41 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Multilingue` `Grand Contexte`

**Cas d'usage :**
- Agents conversationnels avanc√©s avec grand contexte et int√©gration d'outils (MCP)
- R√©solution de probl√®mes complexes (maths, code) avec mode "Thinking"
- Analyse et g√©n√©ration de documents volumineux
- Applications multilingues (>100 langues) n√©cessitant une compr√©hension profonde

---

### QwQ-32B
**Qwen Team ‚Ä¢ 32B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le de 32 milliards de param√®tres am√©lior√© par apprentissage par renforcement (RL) pour exceller dans le raisonnement, le codage, les math√©matiques et les t√¢ches d'agent.

**Sp√©cifications techniques :**
- **Vitesse** : 35 tokens/seconde tokens/seconde
- **Consommation** : 7.54 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Codage` `Math√©matiques`

**Cas d'usage :**
- R√©solution de probl√®mes complexes n√©cessitant raisonnement et utilisation d'outils
- G√©n√©ration et ex√©cution de code avec v√©rification des r√©sultats
- T√¢ches math√©matiques avanc√©es avec v√©rification de l'exactitude
- Applications d'agent capables d'interagir avec l'environnement
- Instruction following am√©lior√© et alignement avec les pr√©f√©rences humaines

---

### DeepSeek-R1 14B
**DeepSeek AI ‚Ä¢ 14B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Version compacte et efficiente du mod√®le DeepSeek-R1, offrant un excellent compromis entre performance et l√©g√®ret√© pour les d√©ploiements n√©cessitant flexibilit√© et r√©activit√©.

**Sp√©cifications techniques :**
- **Vitesse** : 62 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 4.26 kWh/million tokens
- **Licence** : MIT licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Raisonnement` `Compact` `Polyvalent` `Rapide`

**Cas d'usage :**
- Applications g√©n√©ralistes avec besoins d'inf√©rence rapide (44 tokens/s)
- D√©ploiements sur serveurs standard sans GPU sp√©cialis√© (14B param√®tres)
- Traitement de texte avec analyse contextuelle et temps de r√©ponse rapides
- D√©ploiement sur edge computing avec inf√©rence locale optimis√©e
- Prototypage rapide d'applications IA avec temps d'it√©ration court

---

### DeepSeek-R1 32B
**DeepSeek AI ‚Ä¢ 32B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Version interm√©diaire du mod√®le DeepSeek-R1 offrant un √©quilibre strat√©gique entre les capacit√©s avanc√©es de la version 70B et l'efficience de la version 14B, pour une polyvalence et performance optimales.

**Sp√©cifications techniques :**
- **Vitesse** : 33 tokens/seconde tokens/seconde
- **Consommation** : 7.99 kWh/million tokens
- **Licence** : MIT licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Raisonnement` `Polyvalent`

**Cas d'usage :**
- Applications n√©cessitant un bon √©quilibre puissance/co√ªt (32B param√®tres)
- Traitement de texte professionnel avec analyse des subtilit√©s s√©mantiques
- G√©n√©ration automatis√©e de rapports structur√©s √† partir de donn√©es brutes
- Applications combinant analyse de donn√©es et g√©n√©ration de contenus
- Assistants sp√©cialis√©s pour secteurs techniques (juridique, m√©dical, technique)

---

### Cogito 3B
**Deep Cogito ‚Ä¢ 3B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Version compacte du mod√®le Cogito, optimis√©e pour le raisonnement sur des appareils √† ressources limit√©es.

**Sp√©cifications techniques :**
- **Vitesse** : 55 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 0.61 kWh/million tokens üå±
- **Licence** : LLAMA 3.2 Community Licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Raisonnement` `Compact` `Embarqu√©` `Efficient` `Rapide`

---

### Granite Embedding
**IBM ‚Ä¢ 278M param√®tres ‚Ä¢ Contexte : 512 tokens**

Mod√®le d'embedding ultra-l√©ger d'IBM pour la recherche s√©mantique et la classification.

**Sp√©cifications techniques :**
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Embedding` `Compact` `S√©mantique` `Efficient`

---

### Granite 3 Guardian 2B
**IBM ‚Ä¢ 2B param√®tres ‚Ä¢ Contexte : 8 192 tokens**

Mod√®le compact d'IBM sp√©cialis√© dans la s√©curit√© et la conformit√©, d√©tectant les risques et les contenus inappropri√©s.

**Sp√©cifications techniques :**
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `S√©curit√©` `Conformit√©` `Compact` `Filtrage` `Efficient`

---

### Granite 3 Guardian 8B
**IBM ‚Ä¢ 8B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le d'IBM sp√©cialis√© dans la s√©curit√© et la conformit√©, offrant des capacit√©s avanc√©es de d√©tection des risques.

**Sp√©cifications techniques :**
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `S√©curit√©` `Conformit√©` `Filtrage`

---

### Qwen 2.5 0.5B
**Qwen Team ‚Ä¢ 0.5B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Micro-mod√®le ultra-l√©ger de la famille Qwen 2.5, con√ßu pour une efficacit√© maximale sur appareils contraints.

**Sp√©cifications techniques :**
- **Vitesse** : 162 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 0.1 kWh/million tokens üå±
- **Licence** : MIT licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Ultra-compact` `Rapide` `Embarqu√©` `Efficient`

---

### Qwen 2.5 1.5B
**Qwen Team ‚Ä¢ 1.5B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le tr√®s compact de la famille Qwen 2.5, offrant un bon √©quilibre performance/taille pour les d√©ploiements l√©gers.

**Sp√©cifications techniques :**
- **Vitesse** : 102 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 0.33 kWh/million tokens üå±
- **Licence** : MIT licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Compact` `Rapide` `Embarqu√©` `Efficient`

---

### Qwen 2.5 14B
**Qwen Team ‚Ä¢ 14B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le polyvalent de taille moyenne de la famille Qwen 2.5, bon √©quilibre performance/ressources.

**Sp√©cifications techniques :**
- **Vitesse** : 61 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 4.33 kWh/million tokens
- **Licence** : MIT licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Polyvalent` `Multilingue` `Rapide`

---

### Qwen 2.5 32B
**Qwen Team ‚Ä¢ 32B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le puissant de la famille Qwen 2.5, offrant des capacit√©s avanc√©es en compr√©hension et g√©n√©ration.

**Sp√©cifications techniques :**
- **Vitesse** : 31 tokens/seconde tokens/seconde
- **Consommation** : 8.51 kWh/million tokens
- **Licence** : MIT licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Polyvalent` `Multilingue` `Raisonnement`

---

### Qwen 2.5 3B
**Qwen Team ‚Ä¢ 3B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le compact et efficace de la famille Qwen 2.5, adapt√© aux t√¢ches g√©n√©rales sur ressources limit√©es.

**Sp√©cifications techniques :**
- **Vitesse** : 64 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 0.52 kWh/million tokens üå±
- **Licence** : MIT licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Compact` `Rapide` `Polyvalent` `Efficient`

---

### Qwen3 0.6b
**Qwen Team ‚Ä¢ 0.6B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le compact et efficace de la famille Qwen3, adapt√© aux t√¢ches g√©n√©rales sur ressources limit√©es.

**Sp√©cifications techniques :**
- **Vitesse** : 112 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 0.15 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Compact` `Rapide` `Polyvalent` `Efficient`

---

### Qwen3 1.7b
**Qwen Team ‚Ä¢ 1.7B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le tr√®s compact de la famille Qwen3, offrant un bon √©quilibre performance/taille pour les d√©ploiements l√©gers.

**Sp√©cifications techniques :**
- **Vitesse** : 88 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 0.38 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Compact` `Rapide` `Embarqu√©` `Efficient`

---

### Qwen3 4b
**Qwen Team ‚Ä¢ 4B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le compact de la famille Qwen3 offrant d'excellentes performances dans un format l√©ger et √©conomique.

**Sp√©cifications techniques :**
- **Vitesse** : 49 tokens/seconde tokens/seconde
- **Consommation** : 0.68 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Compact` `Efficient`

---

### Qwen3 8b
**Qwen Team ‚Ä¢ 8B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le Qwen3 8B offrant un bon √©quilibre entre performance et efficacit√© pour les t√¢ches g√©n√©rales.

**Sp√©cifications techniques :**
- **Vitesse** : 33 tokens/seconde tokens/seconde
- **Consommation** : 1.01 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Raisonnement` `Agent` `Multilingue` `Efficient`

---

### Qwen2.5-VL 3B
**Qwen Team ‚Ä¢ 3.8B param√®tres ‚Ä¢ Contexte : 128 000 tokens**

Mod√®le Vision-Langage compact, solution performante pour l'IA en p√©riph√©rie (edge AI).

**Sp√©cifications techniques :**
- **Vitesse** : 65 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 0.51 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `Agent` `Raisonnement` `Rapide` `Efficient` `OCR` `Localisation Visuelle` `Edge AI`

---

### Qwen2.5-VL 7B
**Qwen Team ‚Ä¢ 7B (8.3B) param√®tres ‚Ä¢ Contexte : 128 000 tokens**

Mod√®le Vision-Langage performant, surpassant GPT-4o-mini sur certaines t√¢ches.

**Sp√©cifications techniques :**
- **Vitesse** : 35 tokens/seconde tokens/seconde
- **Consommation** : 0.95 kWh/million tokens üå±
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Vision` `Agent` `Raisonnement` `Efficient` `OCR` `Localisation Visuelle`

---

### Foundation-Sec-8B
**Foundation AI ‚Äî Cisco ‚Ä¢ 8B param√®tres ‚Ä¢ Contexte : 16 384 tokens**

Mod√®le de langage sp√©cialis√© pour la cybers√©curit√©, optimis√© pour l'efficacit√©.

**Sp√©cifications techniques :**
- **Vitesse** : 21 tokens/seconde tokens/seconde
- **Consommation** : 1.59 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `S√©curit√©` `Compact`

---

### devstral 24B
**Mistral AI & All Hands AI ‚Ä¢ 24B param√®tres ‚Ä¢ Contexte : 120 000 tokens**

Devstral est un LLM agentique pour les t√¢ches d'ing√©nierie logicielle.

**Sp√©cifications techniques :**
- **Vitesse** : 45 tokens/seconde tokens/seconde
- **Consommation** : 5.86 kWh/million tokens
- **Licence** : Apache 2.0
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚úÖ S√©curit√©

**Tags :** `Agent` `Programmation` `Open-Source` `Grand Contexte`

**Cas d'usage :**
- Exploration et modification de bases de code
- Agentic
- Europ√©en

---

### Cogito 8B
**Deep Cogito ‚Ä¢ 8B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le de taille interm√©diaire de la famille Cogito, offrant un bon √©quilibre entre les capacit√©s de raisonnement et l'efficacit√©.

**Sp√©cifications techniques :**
- **Vitesse** : 30 tokens/seconde tokens/seconde
- **Consommation** : 1.11 kWh/million tokens üå±
- **Licence** : LLAMA 3.2 Community Licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚úÖ Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Agent` `Raisonnement` `Polyvalent` `Efficient`

---

### Llama 3.1 8B
**Meta ‚Ä¢ 8B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le de base de la famille Llama 3.1, offrant des performances solides pour sa taille.

**Sp√©cifications techniques :**
- **Vitesse** : 31 tokens/seconde tokens/seconde
- **Consommation** : 1.08 kWh/million tokens üå±
- **Licence** : LLAMA 3.1 Community Licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Polyvalent` `Efficient`

---

### Phi-4 Reasoning 14B
**Microsoft ‚Ä¢ 14B param√®tres ‚Ä¢ Contexte : 32 000 tokens**

Mod√®le de la famille Phi de Microsoft, sp√©cialis√© dans le raisonnement complexe et les math√©matiques.

**Sp√©cifications techniques :**
- **Vitesse** : 71 tokens/seconde tokens/seconde ‚ö°
- **Consommation** : 3.71 kWh/million tokens
- **Licence** : MIT Licence
- **Localisation** : FR üá´üá∑

**Capacit√©s :**
‚ùå Outils/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Raisonnement ‚Ä¢ ‚ùå S√©curit√©

**Tags :** `Raisonnement` `Math√©matiques` `Programmation` `Rapide`

---

## Cas d'Usage Recommand√©s

### Dialogue multilingue
Chatbots et assistants capables de communiquer dans plusieurs langues avec d√©tection automatique, maintien du contexte sur l'ensemble de la conversation et compr√©hension des sp√©cificit√©s linguistiques

**Mod√®les recommand√©s :**
- Llama 3.3
- Mistral Small 3.1
- Qwen 2.5
- Granite 3.3

### Analyse de documents longs
Traitement de documents volumineux (>100 pages) avec maintien du contexte sur l'ensemble du texte, extraction d'informations cl√©s, g√©n√©ration de r√©sum√©s pertinents et r√©ponse √† des questions sp√©cifiques sur le contenu

**Mod√®les recommand√©s :**
- Gemma 3
- DeepSeek-R1
- Granite 3.3

### Programmation et d√©veloppement
G√©n√©ration et optimisation de code dans multiples langages, d√©bogage, refactoring, d√©veloppement de fonctionnalit√©s compl√®tes, compr√©hension des impl√©mentations algorithmiques complexes et cr√©ation de tests unitaires

**Mod√®les recommand√©s :**
- DeepCoder
- QwQ
- DeepSeek-R1
- Granite 3.3
- Devstral

### Analyse visuelle
Traitement direct d'images et documents visuels sans pr√©-traitement OCR, interpr√©tation de diagrammes techniques, graphiques, tableaux, dessins et photos avec g√©n√©ration d'explications textuelles d√©taill√©es du contenu visuel

**Mod√®les recommand√©s :**
- Granite 3.2 Vision
- Mistral Small 3.1
- Gemma 3
- Qwen2.5-VL

### S√©curit√© et conformit√©
Applications n√©cessitant des capacit√©s sp√©cifiques en mati√®re de s√©curit√© ; filtrage de contenu sensible, tra√ßabilit√© des raisonnements, v√©rification RGPD/HDS, minimisation des risques, analyse des vuln√©rabilit√©s et respect des r√©glementations sectorielles

**Mod√®les recommand√©s :**
- Granite Guardian
- Granite 3.3
- Devstral
- Mistral Small 3.1
- Magistral 24b
- Foundation-Sec-8B

### D√©ploiements l√©gers et embarqu√©s
Applications n√©cessitant une empreinte minimale en ressources, d√©ploiement sur appareils √† capacit√© limit√©e, inf√©rence en temps r√©el sur CPU standard et int√©gration dans des syst√®mes embarqu√©s ou IoT

**Mod√®les recommand√©s :**
- Gemma 3
- Granite 3.1 MoE
- Granite Guardian
- Granite 3.3

