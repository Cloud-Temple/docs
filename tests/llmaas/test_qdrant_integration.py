#!/usr/bin/env python3
"""
Test d'Int√©gration Qdrant avec LLMaaS Cloud Temple

Ce script est con√ßu pour valider l'int√©gration du service d'embeddings de LLMaaS Cloud Temple
avec la base de donn√©es vectorielle Qdrant. Il couvre les √©tapes cl√©s d'un pipeline RAG (Retrieval Augmented Generation) :
1.  Connexion √† l'API LLMaaS pour la g√©n√©ration d'embeddings.
2.  Connexion √† un serveur Qdrant (local par d√©faut).
3.  Cr√©ation et gestion d'une collection Qdrant.
4.  G√©n√©ration d'embeddings pour des documents de test via LLMaaS.
5.  Insertion de ces documents et de leurs embeddings dans Qdrant.
6.  Ex√©cution d'une requ√™te de recherche de similarit√© dans Qdrant.
7.  Utilisation des documents r√©cup√©r√©s pour g√©n√©rer une r√©ponse RAG avec un LLM Cloud Temple.

Le script s'assure que tous les composants interagissent correctement et que le pipeline RAG
fonctionne comme attendu, en fournissant des logs d√©taill√©s √† chaque √©tape.

Pr√©requis:
- Python 3.9+
- Les biblioth√®ques Python list√©es dans `requirements.txt` (qdrant-client, httpx, langchain, etc.)
- Un serveur Qdrant en cours d'ex√©cution.

Instructions pour lancer Qdrant via Docker (recommand√© pour les tests locaux):
    docker pull qdrant/qdrant
    docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant

Variables d'environnement (√† configurer dans un fichier .env √† la racine du projet ou export√©es):
- LLMAAS_API_KEY: Votre cl√© API pour acc√©der √† LLMaaS Cloud Temple.
- API_URL: L'URL de base de l'API LLMaaS (par d√©faut: https://api.ai.cloud-temple.com/v1).
- EMBEDDING_MODEL: Le mod√®le d'embedding √† utiliser (par d√©faut: granite-embedding:278m).
- DEFAULT_MODEL: Le mod√®le LLM √† utiliser pour la g√©n√©ration de texte (par d√©faut: granite3.3:8b).
- QDRANT_URL: L'URL du serveur Qdrant (par d√©faut: http://localhost:6333).
"""

import os
import sys
import json
import time
import requests
import httpx
from typing import Optional, List, Any, Dict
from pathlib import Path
from dotenv import load_dotenv

# NOTE: Si vous rencontrez des erreurs d'importation (ex: "qdrant_client", "langchain_core"),
# assurez-vous d'avoir install√© les d√©pendances n√©cessaires:
# pip install -r tests/llmaas/requirements.txt
# Et que votre environnement Python dans VSCode est correctement s√©lectionn√©.

# Importations sp√©cifiques √† LangChain pour les embeddings et les utilitaires
from langchain_core.embeddings import Embeddings
from langchain_core.utils.input import SecretStr

# Charger les variables d'environnement depuis le fichier .env
# Cela permet de g√©rer les cl√©s API et autres configurations sensibles
# sans les coder en dur dans le script.
load_dotenv()

# --- Configuration des services Cloud Temple LLMaaS ---
# Cl√© API pour l'authentification aupr√®s de LLMaaS.
# R√©cup√©r√©e depuis les variables d'environnement ou utilise une valeur par d√©faut pour les tests.
API_KEY = os.getenv("LLMAAS_API_KEY", "your-api-key-here")
# URL de base de l'API LLMaaS.
BASE_URL = os.getenv("API_URL", "https://api.ai.cloud-temple.com/v1")
# Mod√®le d'embedding √† utiliser pour convertir le texte en vecteurs num√©riques.
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "granite-embedding:278m")
# Mod√®le de langage large (LLM) √† utiliser pour g√©n√©rer des r√©ponses textuelles.
LLM_MODEL = os.getenv("DEFAULT_MODEL", "granite3.3:8b")

# --- Configuration de Qdrant ---
# URL du serveur Qdrant. Par d√©faut, il s'agit d'une instance locale.
QDRANT_URL = os.getenv("QDRANT_URL", "http://localhost:6333")
# Nom de la collection Qdrant qui sera utilis√©e pour stocker les vecteurs d'embeddings.
QDRANT_COLLECTION_NAME = "cloud_temple_docs_test"

# --- Instructions pour lancer Qdrant via Docker ---
# Ces commandes sont fournies pour faciliter la mise en place d'un environnement de test local.
# docker pull qdrant/qdrant
# docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant

class RAGTestLogger:
    """
    Classe utilitaire pour logger les √©tapes des tests RAG.
    Elle permet de suivre la progression, le statut (succ√®s/√©chec) et le temps √©coul√©
    pour chaque op√©ration, rendant le d√©bogage plus facile.
    """
    
    def __init__(self):
        """Initialise le logger et le chronom√®tre."""
        self.steps = []
        self.start_time = time.time()
    
    def log_step(self, step: str, status: str, details: str = ""):
        """
        Enregistre une √©tape du test avec son statut et des d√©tails optionnels.

        Args:
            step (str): Description de l'√©tape.
            status (str): Statut de l'√©tape ("SUCCESS", "ERROR", "PROGRESS", "INFO").
            details (str): Informations suppl√©mentaires sur l'√©tape.
        """
        timestamp = time.time() - self.start_time
        self.steps.append({
            "step": step,
            "status": status,
            "details": details,
            "timestamp": f"{timestamp:.2f}s"
        })
        
        # D√©termine l'ic√¥ne √† afficher en fonction du statut pour une meilleure lisibilit√©.
        status_icon = "‚úÖ" if status == "SUCCESS" else "‚ùå" if status == "ERROR" else "üîÑ"
        print(f"{status_icon} [{timestamp:6.2f}s] {step}")
        if details:
            print(f"    üìù {details}")

    def print_summary(self) -> bool:
        """
        Affiche un r√©sum√© final de tous les tests ex√©cut√©s.

        Returns:
            bool: True si toutes les √©tapes ont r√©ussi, False sinon.
        """
        total_time = time.time() - self.start_time
        success_count = sum(1 for step in self.steps if step["status"] == "SUCCESS")
        total_steps = len(self.steps)
        
        print(f"\n{'='*70}")
        print(f"üìä R√âSUM√â DES TESTS D'INT√âGRATION QDRANT")
        print(f"{'='*70}")
        print(f"‚è±Ô∏è  Dur√©e totale des tests: {total_time:.2f}s")
        print(f"‚úÖ √âtapes r√©ussies: {success_count}/{total_steps}")
        print(f"üìà Taux de succ√®s global: {success_count/total_steps*100:.1f}%")
        
        # Retourne True si toutes les √©tapes ont √©t√© un succ√®s, False sinon.
        return success_count == total_steps

class LLMaaSEmbeddings(Embeddings):
    """
    Classe d'embedding personnalis√©e pour interagir avec l'API LLMaaS de Cloud Temple.
    Cette classe est con√ßue pour √™tre compatible avec l'interface `Embeddings` de LangChain,
    permettant son utilisation dans des pipelines LangChain tout en appelant notre API sp√©cifique.
    """
    def __init__(self, api_key: str, base_url: str, model_name: str, logger: RAGTestLogger):
        """
        Initialise la classe LLMaaSEmbeddings.

        Args:
            api_key (str): Cl√© API pour l'authentification LLMaaS.
            base_url (str): URL de base de l'API LLMaaS.
            model_name (str): Nom du mod√®le d'embedding √† utiliser.
            logger (RAGTestLogger): Instance du logger pour suivre les op√©rations.
        """
        self.api_key = api_key
        self.base_url = base_url
        self.model_name = model_name
        self.logger = logger
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

    def _embed(self, texts: List[str]) -> List[List[float]]:
        """
        M√©thode interne pour g√©n√©rer des embeddings √† partir d'une liste de textes.
        Elle envoie une requ√™te POST √† l'endpoint /v1/embeddings de l'API LLMaaS.

        Args:
            texts (List[str]): Liste des textes √† vectoriser.

        Returns:
            List[List[float]]: Liste des vecteurs d'embeddings g√©n√©r√©s.

        Raises:
            httpx.HTTPStatusError: Si l'API renvoie une erreur HTTP.
            httpx.RequestError: Si une erreur r√©seau se produit.
        """
        payload = {"input": texts, "model": self.model_name}
        try:
            with httpx.Client(timeout=30.0) as client:
                response = client.post(f"{self.base_url}/embeddings", headers=self.headers, json=payload)
                response.raise_for_status() # L√®ve une exception pour les codes d'erreur HTTP (4xx, 5xx)
                data = response.json()['data']
                # Les donn√©es retourn√©es par l'API incluent un index pour chaque embedding.
                # Nous les trions pour garantir que l'ordre des embeddings correspond √† l'ordre des textes d'entr√©e.
                data.sort(key=lambda e: e['index'])
                self.logger.log_step("Embeddings g√©n√©r√©s", "SUCCESS", f"{len(data)} vecteurs pour {len(texts)} textes")
                return [item['embedding'] for item in data]
        except httpx.HTTPStatusError as e:
            self.logger.log_step("Erreur Embeddings", "ERROR", f"HTTP {e.response.status_code}: {e.response.text}")
            raise # R√©l√®ve l'exception apr√®s logging
        except httpx.RequestError as e:
            self.logger.log_step("Erreur Embeddings", "ERROR", f"R√©seau: {e}")
            raise # R√©l√®ve l'exception apr√®s logging

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """
        Impl√©mentation de la m√©thode `embed_documents` requise par l'interface LangChain.
        Utilis√©e pour g√©n√©rer des embeddings pour une liste de documents.
        """
        return self._embed(texts)

    def embed_query(self, text: str) -> List[float]:
        """
        Impl√©mentation de la m√©thode `embed_query` requise par l'interface LangChain.
        Utilis√©e pour g√©n√©rer un embedding pour une seule requ√™te.
        """
        return self._embed([text])[0]

def test_qdrant_connection(logger: RAGTestLogger) -> bool:
    """
    Teste la connexion au serveur Qdrant.
    V√©rifie si le client Qdrant peut s'initialiser et interagir avec le serveur.

    Args:
        logger (RAGTestLogger): Instance du logger.

    Returns:
        bool: True si la connexion est r√©ussie, False sinon.
    """
    logger.log_step("Test connexion Qdrant", "PROGRESS", f"Tentative de connexion √† {QDRANT_URL}")
    try:
        # Importation locale pour g√©rer les d√©pendances optionnelles.
        from qdrant_client import QdrantClient
        # Initialise le client Qdrant.
        client = QdrantClient(host="localhost", port=6333)
        
        # Tente de r√©cup√©rer des collections pour v√©rifier que le serveur r√©pond.
        collections = client.get_collections()
        logger.log_step("Connexion Qdrant", "SUCCESS", f"{len(collections.collections)} collections trouv√©es sur le serveur")
        return True
    except ImportError:
        logger.log_step("Qdrant Client", "ERROR", "Module 'qdrant-client' non install√©. Installez avec: pip install qdrant-client")
        return False
    except Exception as e:
        logger.log_step("Connexion Qdrant", "ERROR", f"Impossible de se connecter √† Qdrant: {e}. Assurez-vous que Qdrant est lanc√© (ex: docker run -p 6333:6333 qdrant/qdrant)")
        return False

def test_qdrant_integration():
    """
    Fonction principale qui ex√©cute le test d'int√©gration complet avec Qdrant.
    Elle orchestre toutes les √©tapes du pipeline RAG avec Qdrant.
    """
    logger = RAGTestLogger()
    logger.log_step("D√©but test int√©gration Qdrant", "INFO", "Validation du pipeline RAG avec Qdrant et LLMaaS Embeddings")

    # V√©rifie la connexion √† Qdrant avant de poursuivre.
    if not test_qdrant_connection(logger):
        logger.log_step("Test Qdrant", "ERROR", "Connexion Qdrant √©chou√©e, arr√™t du test.")
        return False

    try:
        # Importations n√©cessaires pour LangChain et Qdrant.
        from qdrant_client import QdrantClient, models
        from langchain_community.document_loaders import TextLoader
        from langchain.text_splitter import RecursiveCharacterTextSplitter
        from langchain_community.vectorstores import Qdrant
        from langchain.chains import RetrievalQA
        from langchain_openai import ChatOpenAI # Utilis√© car compatible avec l'API LLMaaS

        # 1. Initialisation des clients et nettoyage de la collection Qdrant.
        logger.log_step("Initialisation clients et nettoyage", "PROGRESS")
        qdrant_client = QdrantClient(host="localhost", port=6333)
        
        # Supprime la collection de test si elle existe d√©j√† pour garantir un √©tat propre √† chaque ex√©cution.
        if qdrant_client.collection_exists(collection_name=QDRANT_COLLECTION_NAME):
            qdrant_client.delete_collection(collection_name=QDRANT_COLLECTION_NAME)
            logger.log_step("Nettoyage collection", "SUCCESS", f"Collection '{QDRANT_COLLECTION_NAME}' supprim√©e pour un nouveau test.")

        # Cr√©e une nouvelle collection Qdrant avec les param√®tres de vecteurs appropri√©s.
        # La taille du vecteur (size) doit correspondre √† la dimension des embeddings g√©n√©r√©s par le mod√®le LLMaaS.
        # all-MiniLM-L6-v2 (souvent utilis√© pour les embeddings) a une dimension de 384.
        qdrant_client.create_collection(
            collection_name=QDRANT_COLLECTION_NAME,
            vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE), 
        )
        logger.log_step("Collection Qdrant", "SUCCESS", f"Collection '{QDRANT_COLLECTION_NAME}' cr√©√©e avec succ√®s.")

        # Initialisation de la classe d'embeddings personnalis√©e LLMaaSEmbeddings.
        # C'est cette classe qui fera les appels √† l'API LLMaaS pour obtenir les vecteurs.
        embeddings = LLMaaSEmbeddings(
            api_key=API_KEY,
            base_url=BASE_URL,
            model_name=EMBEDDING_MODEL,
            logger=logger
        )
        logger.log_step("LLMaaS Embeddings", "SUCCESS", f"Classe d'embeddings LLMaaS initialis√©e avec le mod√®le: {EMBEDDING_MODEL}")

        # 2. Cr√©ation de documents de test.
        # Ces documents simulent une base de connaissances √† partir de laquelle le RAG va r√©cup√©rer des informations.
        logger.log_step("Cr√©ation documents de test", "PROGRESS", "G√©n√©ration de contenu pour la base de connaissances Qdrant.")
        documents_content = [
            "Cloud Temple est un fournisseur de cloud souverain fran√ßais avec la qualification SecNumCloud de l'ANSSI.",
            "L'API LLMaaS de Cloud Temple permet d'acc√©der √† 36 mod√®les d'intelligence artificielle.",
            "Les tarifs LLMaaS sont de 0.9‚Ç¨ pour l'input et 4‚Ç¨ pour l'output par million de tokens.",
            "La s√©curit√© Cloud Temple est garantie par les certifications HDS et ISO 27001.",
            "Les cas d'usage de LLMaaS incluent le dialogue multilingue et l'analyse de documents longs."
        ]
        
        # Conversion du contenu brut en objets Document de LangChain.
        from langchain.docstore.document import Document
        documents = [Document(page_content=d) for d in documents_content]
        logger.log_step("Documents de test", "SUCCESS", f"{len(documents)} documents de test cr√©√©s en m√©moire.")

        # 3. Division des documents en chunks (morceaux).
        # Cette √©tape est cruciale pour le RAG afin de g√©rer des documents longs et d'optimiser la recherche.
        # Ici, les documents sont petits, donc le chunking aura un effet minimal mais la logique est pr√©sente.
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)
        splits = text_splitter.split_documents(documents)
        logger.log_step("Division en chunks", "SUCCESS", f"{len(splits)} chunks de texte g√©n√©r√©s.")

        # 4. Ajout des documents et de leurs embeddings √† Qdrant.
        # La m√©thode `from_documents` de Qdrant (via LangChain) g√©n√®re les embeddings
        # en utilisant la classe `embeddings` fournie (notre LLMaaSEmbeddings)
        # et les ins√®re dans la collection Qdrant.
        logger.log_step("Ajout documents √† Qdrant", "PROGRESS", "G√©n√©ration des embeddings et insertion dans la base vectorielle.")
        vectorstore = Qdrant.from_documents(
            splits,
            embeddings,
            url=QDRANT_URL,
            collection_name=QDRANT_COLLECTION_NAME,
            force_recreate=False # La collection est d√©j√† cr√©√©e et nettoy√©e au d√©but du test.
        )
        logger.log_step("Documents ajout√©s √† Qdrant", "SUCCESS", f"{len(splits)} points (documents + embeddings) ins√©r√©s dans Qdrant.")

        # 5. Configuration du LLM pour la cha√Æne RAG.
        # Utilisation de ChatOpenAI de langchain_openai car il est compatible avec l'API LLMaaS.
        logger.log_step("Configuration LLM", "PROGRESS", f"Initialisation du mod√®le LLM: {LLM_MODEL}")
        llm = ChatOpenAI(
            api_key=SecretStr(API_KEY), # Utilisation de SecretStr pour la cl√© API
            base_url=BASE_URL,
            model=LLM_MODEL,
            temperature=0.3 # Une temp√©rature basse favorise des r√©ponses plus factuelles, id√©al pour le RAG.
        )
        logger.log_step("LLM configur√©", "SUCCESS", "Mod√®le LLM Cloud Temple pr√™t pour la g√©n√©ration de r√©ponses.")

        # 6. Cr√©ation de la cha√Æne RAG avec Qdrant.
        # `RetrievalQA` est une cha√Æne LangChain qui combine la r√©cup√©ration de documents
        # (via le retriever de Qdrant) et la g√©n√©ration de r√©ponses (via le LLM).
        logger.log_step("Cr√©ation cha√Æne RAG Qdrant", "PROGRESS", "Assemblage du retriever (Qdrant) et du g√©n√©rateur (LLMaaS).")
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff", # "stuff" combine tous les documents r√©cup√©r√©s en un seul prompt.
            retriever=vectorstore.as_retriever(search_kwargs={"k": 2}), # R√©cup√®re les 2 documents les plus pertinents.
            return_source_documents=True # Permet de voir quels documents ont √©t√© utilis√©s pour la r√©ponse.
        )
        logger.log_step("Cha√Æne RAG Qdrant", "SUCCESS", "Cha√Æne RetrievalQA cr√©√©e avec succ√®s.")

        # 7. Ex√©cution d'une requ√™te de test.
        # Cette requ√™te simule une question utilisateur √† laquelle le pipeline RAG doit r√©pondre
        # en utilisant les documents stock√©s dans Qdrant.
        question = "Quelle est la qualification principale de Cloud Temple et quels sont les tarifs LLMaaS ?"
        logger.log_step("Ex√©cution requ√™te RAG", "PROGRESS", f"Question pos√©e au pipeline RAG: '{question}'")
        
        start_time = time.time()
        result = qa_chain({"query": question})
        query_time = time.time() - start_time

        answer = result['result']
        source_docs = result['source_documents']

        logger.log_step("R√©ponse RAG", "SUCCESS", f"R√©ponse g√©n√©r√©e en {query_time:.2f}s, bas√©e sur {len(source_docs)} sources.")
        print(f"\n--- R√©sultat de la requ√™te RAG ---")
        print(f"Question: {question}")
        print(f"R√©ponse: {answer}")
        print(f"Sources utilis√©es ({len(source_docs)}):")
        for doc in source_docs:
            # Affiche un aper√ßu du contenu des documents sources pour v√©rification.
            print(f"  - {doc.page_content[:100]}...")
        print("-----------------------------------\n")

        # 8. Validation simple de la r√©ponse.
        # V√©rifie si les mots-cl√©s attendus sont pr√©sents dans la r√©ponse g√©n√©r√©e.
        if "SecNumCloud" in answer and "0.9‚Ç¨" in answer and "4‚Ç¨" in answer:
            logger.log_step("Validation r√©ponse", "SUCCESS", "Les mots-cl√©s 'SecNumCloud', '0.9‚Ç¨' et '4‚Ç¨' sont pr√©sents dans la r√©ponse.")
            return True
        else:
            logger.log_step("Validation r√©ponse", "ERROR", "Certains mots-cl√©s attendus ('SecNumCloud', '0.9‚Ç¨', '4‚Ç¨') sont manquants dans la r√©ponse.")
            return False

    except Exception as e:
        # Capture et log toute exception survenant pendant le test.
        logger.log_step("Erreur test Qdrant", "ERROR", f"Une erreur inattendue est survenue: {str(e)}")
        import traceback
        traceback.print_exc() # Affiche la stack trace pour le d√©bogage.
        return False
    finally:
        # 9. Nettoyage final de la collection Qdrant.
        # Cette √©tape est cruciale pour ne pas laisser de donn√©es de test sur le serveur Qdrant.
        logger.log_step("Nettoyage final Qdrant", "PROGRESS", "Suppression de la collection de test.")
        try:
            qdrant_client = QdrantClient(host="localhost", port=6333)
            if qdrant_client.collection_exists(collection_name=QDRANT_COLLECTION_NAME):
                qdrant_client.delete_collection(collection_name=QDRANT_COLLECTION_NAME)
                logger.log_step("Nettoyage final", "SUCCESS", f"Collection '{QDRANT_COLLECTION_NAME}' supprim√©e avec succ√®s.")
        except Exception as e:
            logger.log_step("Erreur nettoyage", "ERROR", f"Impossible de nettoyer la collection Qdrant: {e}")

def main():
    """
    Fonction principale du script de test.
    Elle initialise le logger et ex√©cute le test d'int√©gration Qdrant.
    """
    logger = RAGTestLogger()
    logger.log_step("D√©marrage des tests d'int√©gration Qdrant avec LLMaaS", "INFO")
    print("=" * 70)
    print("ATTENTION: Ce test n√©cessite un serveur Qdrant en cours d'ex√©cution.")
    print("Pour lancer Qdrant via Docker: docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant")
    print("Assurez-vous que votre cl√© API LLMaaS est configur√©e dans le fichier .env ou comme variable d'environnement.")
    print("=" * 70)

    # Ex√©cute le test d'int√©gration Qdrant.
    success = test_qdrant_integration()
    
    # Affiche le r√©sum√© des √©tapes du test.
    all_steps_passed = logger.print_summary()
    
    # D√©termine le code de sortie du script.
    if success and all_steps_passed:
        print("\nüéâ SUCC√àS GLOBAL - L'int√©gration Qdrant avec LLMaaS est valid√©e!")
        sys.exit(0)
    else:
        print("\n‚ùå √âCHEC GLOBAL - L'int√©gration Qdrant avec LLMaaS a rencontr√© des probl√®mes.")
        sys.exit(1)

if __name__ == "__main__":
    main()
