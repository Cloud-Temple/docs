---
title: Katalog der KI-Modelle
sidebar_position: 2
---

# Katalog der LLM as a Service-Modelle

## Übersicht

Cloud Temple LLMaaS bietet **44 ausgewählte und optimierte Sprachmodelle**, die den strengsten **SecNumCloud**-Anforderungen entsprechen. Unser Katalog umfasst das gesamte Spektrum, von ultra-effizienten Mikromodellen bis hin zu extrem großen Modellen.

### Globale Statistiken

| Metrik | Wert |
|----------|--------|
| **Gesamtanzahl der Modelle** | 44 Modelle |
| **Minimale Kontextlänge** | 8.192 Tokens |
| **Maximale Kontextlänge** | 128.000 Tokens |
| **Konformität** | SecNumCloud ✅ HDS ✅ Souveränität ✅ C5 ✅ |
| **Standort** | 100 % Frankreich 🇫🇷 |

### Preise

| Typ der Nutzung | Preis |
|-------------------|------|
| **Eingabetokens** | 0,90 € / Million Tokens |
| **Ausgabetokens** | 4,00 € / Million Tokens |
| **Erweitertes Reasoning** | 21,00 € / Million Tokens |

## Große Modelle

### DeepSeek-R1 671B
**DeepSeek AI • 671B Parameter • Kontext: 16.000 Tokens**

Extrem großes Modell von DeepSeek AI, optimiert für maximales Reasoning und Generierung.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 12 Tokens/Sekunde
- **Verbrauch** : 11,11 kWh/Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Werkzeuge/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit


**Anwendungsfälle:**
- Hochleistungs-Reasoning-Aufgaben
- Hochwertige Textgenerierung
- Forschung und Entwicklung in der KI

---

### DeepSeek-R1 70B
**DeepSeek AI • 70B Parameter • Kontext: 32.000 Tokens**

70B-Modell von DeepSeek AI

**Technische Spezifikationen:**
- **Geschwindigkeit** : 21 Tokens/Sekunde
- **Verbrauch** : 12,56 kWh/Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Werkzeuge/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit


**Anwendungsfälle:**
- Hochleistungs-Reasoning-Aufgaben
- Hochwertige Textgenerierung
- Forschung und Entwicklung in der KI

---

### Gemma 3 27B
**Google • 27B Parameter • Kontext: 120.000 Tokens**

Revolutionäres Modell von Google mit optimaler Balance zwischen Leistung und Effizienz, mit einem außergewöhnlichen Leistungs-Kosten-Verhältnis für anspruchsvolle professionelle Anwendungen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 20 Tokens/Sekunde
- **Verbrauch** : 6,67 kWh/Million Tokens
- **Lizenz** : [Google Gemma Nutzungsbedingungen](./licences/google_gemma_terms_of_use.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Werkzeuge/Agent • ✅ Vision • ❌ Reasoning • ❌ Sicherheit


**Anwendungsfälle:**
- Dokumentenanalyse mit erweitertem Kontext bis zu 120K Tokens (ca. 400 Seiten)
- Semantische Suche in umfangreichen Dokumentenbanken
- Bild- und Textverarbeitung gleichzeitig dank multimodaler Fähigkeiten
- Strukturierte Datenextraktion aus PDFs und gescannten Dokumenten
- Integration mit externen Tools über die API-Funktionaufruf

---

### Llama 3.3 70B
**Meta • 70B Parameter • Kontext: 60.000 Tokens**

Multisprachiges Spitzenmodell von Meta, optimiert für natürliche Gespräche, komplexes Reasoning und feine Anweisungsverstehen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 26 Tokens/Sekunde
- **Verbrauch** : 11,75 kWh/Million Tokens
- **Lizenz** : [LLAMA 3.3 Community Lizenz](./licences/llama_3.3_community_licence.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Werkzeuge/Agent • ❌ Vision • ❌ Reasoning • ❌ Sicherheit


**Anwendungsfälle:**
- Multisprachige Chatbots, die 8 Sprachen gleichzeitig unterstützen
- Ausführung komplexer, verketteter Anweisungen (Prompt-Chaining)
- Verarbeitung einer Gesprächsfenster von 60K Tokens für Konversationshistorien
- Analyse umfangreicher juristischer oder technischer Dokumente (>100 Seiten)
- Generierung strukturierter Texte mit Stilvorgaben

---

### Qwen2.5-VL 32B
**Qwen Team • 32B Parameter • Kontext: 120.000 Tokens**

Stärkste Version der Qwen2.5-VL-Serie mit fortschrittlichen visuellen und Agentenfähigkeiten.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 18 Tokens/Sekunde
- **Verbrauch** : 7,41 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Werkzeuge/Agent • ✅ Vision • ❌ Reasoning • ❌ Sicherheit


**Anwendungsfälle:**
- Analyse sehr komplexer Dokumente und Diagramme
- Autonome visuelle Agenten für Navigation und GUI-Interaktion
- Objekterkennung und Texterkennung mit hoher Präzision
- Generierung reicher und detaillierter Beschreibungen aus komplexen Bildern

---

### Qwen2.5-VL 72B
**Qwen Team • 72B Parameter • Kontext: 128.000 Tokens**

Stärkste Version der Qwen2.5-VL-Serie mit fortschrittlichen visuellen und Agentenfähigkeiten für anspruchsvollste Aufgaben.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 15 Tokens/Sekunde
- **Verbrauch** : 8,89 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Werkzeuge/Agent • ✅ Vision • ✅ Reasoning • ❌ Sicherheit


**Anwendungsfälle:**
- Analyse sehr komplexer Dokumente und Diagramme
- Autonome visuelle Agenten für Navigation und GUI-Interaktion
- Objekterkennung und Texterkennung mit sehr hoher Präzision
- Generierung reicher und detaillierter Beschreibungen aus sehr komplexen Bildern

---

### Qwen3 235B
**Qwen Team • 235B Parameter • Kontext: 60.000 Tokens**

Sehr großes Modell der neuen Qwen3-Serie mit erweiterten Fähigkeiten für anspruchsvollste Aufgaben.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 17 Tokens/Sekunde
- **Verbrauch** : 7,84 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Werkzeuge/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit


**Anwendungsfälle:**
- Sehr fortgeschrittene conversationelle Agenten mit großem Kontext und Werkzeugintegration (MCP)
- Lösung extrem komplexer Probleme (Mathematik, Code)
- Analyse und Generierung sehr umfangreicher und technischer Dokumente
- Multisprachige Anwendungen (>100 Sprachen) mit hoher Genauigkeit

---

### Qwen3 30B-A3B FP8
**Qwen Team • 30B-A3B Parameter • Kontext: 32.000 Tokens**

Neue Generation MoE FP8-Modell (3B aktiviert) mit hybriden Denkmodi und fortgeschrittenen Agentenfähigkeiten.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 106 Tokens/Sekunde
- **Verbrauch** : 2,88 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Werkzeuge/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit


**Anwendungsfälle:**
- Fortgeschrittene conversationelle Agenten mit Werkzeugintegration (MCP)
- Lösung komplexer Probleme (Mathematik, Code) mit "Thinking"-Modus
- Multisprachige Anwendungen (>100 Sprachen)
- Szenarien mit Kosten-Leistungs-Optimierung (MoE) auf VLLM
- Engagierende Multi-Turn-Dialoge mit präziser Anweisungsverfolgung

---

## Spezialisierte Modelle

### Cogito 14B
**Deep Cogito • 14B Parameter • Kontext: 32.000 Tokens**

Modell von Deep Cogito, speziell für tiefes Reasoning und nuancierte Kontextverstehen optimiert, ideal für anspruchsvolle analytische Anwendungen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 60 Tokens/Sekunde
- **Verbrauch** : 4,40 kWh/Million Tokens
- **Lizenz** : [LLAMA 3.2 Community Lizenz](./licences/llama_3.2_community_licence.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Werkzeuge/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit


**Anwendungsfälle:**
- Semantische Textanalyse mit Identifizierung impliziter Implikationen
- Strukturiertes kausales Reasoning mit Identifizierung von Ursache-Wirkungs-Beziehungen
- Synthese komplexer Dokumente mit Extraktion der Schlüsselinformationen
- Präzise Frage-Antwort-Systeme auf spezialisierten Dokumentenkorpora
- Argumentationsanalyse mit Bewertung der Stärke der Reasoning-Strukturen

---

### Cogito 32B
**Deep Cogito • 32B Parameter • Kontext: 32.000 Tokens**

Erweiterte Version des Cogito-Modells mit erheblich verstärkten Reasoning- und Analysefähigkeiten, konzipiert für anspruchsvollste Anwendungen im Bereich analytischer KI.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 32 Tokens/Sekunde
- **Verbrauch** : 8,25 kWh/Million Tokens
- **Lizenz** : [LLAMA 3.2 Community Lizenz](./licences/llama_3.2_community_licence.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Werkzeuge/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit


**Anwendungsfälle:**
- Analyse multi-faktorieller Szenarien mit probabilistischer Ergebniseinschätzung
- Lösung wissenschaftlicher Probleme mit formaler Beweisführung
- Hochkritische Anwendungen mit Präzision und Nachvollziehbarkeit der Ergebnisse
- Expertensysteme in spezialisierten Bereichen (juristisch, medizinisch, technisch)
- Analyse mit mehrstufigem Reasoning und vollständiger Erklärbarkeit der Schlussfolgerungen

---

### Cogito 3B
**Deep Cogito • 3B Parameter • Kontext: 32.000 Tokens**

Kompakte Version des Cogito-Modells, optimiert für Reasoning auf Geräten mit begrenzten Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 55 Tokens/Sekunde
- **Verbrauch** : 0,61 kWh/Million Tokens
- **Lizenz** : [LLAMA 3.2 Community Lizenz](./licences/llama_3.2_community_licence.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Werkzeuge/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit



---

### Cogito 8B
**Deep Cogito • 8B Parameter • Kontext: 32.000 Tokens**

...
Mittleres Modell der Cogito-Familie mit einem guten Gleichgewicht zwischen Rechenkapazitäten und Effizienz.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 30 Tokens/Sekunde
- **Verbrauch** : 1,11 kWh pro Million Tokens
- **Lizenz** : [LLAMA 3.2 Community Lizenz](./licences/llama_3.2_community_licence.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit



---

### DeepCoder
**Agentica x Together AI • 14B Parameter • Kontext: 32.000 Tokens**

Open-Source-IA-Modell (14B) von Together AI & Agentica, eine glaubwürdige Alternative zu proprietären Modellen für die Codegenerierung.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 64 Tokens/Sekunde
- **Verbrauch** : 4,12 kWh pro Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit


**Anwendungsfälle:**
- Codegenerierung in mehr als 15 Sprachen mit Leistungsoptimierung
- Debugging und Refactoring von Code-Basen mit Auswirkungsanalyse
- Implementierung komplexer Algorithmen (Graphen, Bäume, Heuristiken)
- {'Code-Übertragung zwischen Sprachen/Frameworks (z. B. 'Python zu JavaScript)'}
- Automatisierte Erstellung von Einheitstests mit Codeabdeckung > 80%


---

### DeepSeek-R1 14B
**DeepSeek AI • 14B Parameter • Kontext: 32.000 Tokens**

Kompakte und effiziente Version des DeepSeek-R1-Modells, die ein hervorragendes Verhältnis zwischen Leistung und Leichtigkeit für Deployment-Anforderungen bietet, die Flexibilität und Reaktivität erfordern.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 62 Tokens/Sekunde
- **Verbrauch** : 4,26 kWh pro Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit


**Anwendungsfälle:**
- Allgemeine Anwendungen mit Bedarf an schneller Inferenz (44 Tokens/s)
- Deployment auf Standardservern ohne spezialisierte GPU (14B Parameter)
- Textverarbeitung mit kontextueller Analyse und Antwortzeit < 2s
- Deployment auf Edge Computing mit optimierter lokaler Inferenz
- Schnelles Prototyping von IA-Anwendungen mit kurzer Iterationszeit


---

### DeepSeek-R1 32B
**DeepSeek AI • 32B Parameter • Kontext: 32.000 Tokens**

Mittlere Version des DeepSeek-R1-Modells, die ein strategisches Gleichgewicht zwischen den fortgeschrittenen Fähigkeiten der 70B-Version und der Effizienz der 14B-Version bietet, für maximale Vielseitigkeit und Leistung.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 33 Tokens/Sekunde
- **Verbrauch** : 7,99 kWh pro Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit


**Anwendungsfälle:**
- Anwendungen, die ein gutes Gleichgewicht zwischen Leistung und Kosten benötigen (32B Parameter)
- Professionelle Textverarbeitung mit Analyse der semantischen Feinheiten
- Automatisierte Generierung strukturierter Berichte aus Rohdaten
- Anwendungen, die Datenanalyse und Inhaltsgenerierung kombinieren
- Spezialisierte Assistenten für technische Branchen (Recht, Medizin, Technik)


---

### Foundation-Sec-8B
**Foundation AI — Cisco • 8B Parameter • Kontext: 16.384 Tokens**

Sprachmodell für Cybersecurity, optimiert für Effizienz.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 21 Tokens/Sekunde
- **Verbrauch** : 1,59 kWh pro Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ✅ Reasoning • ✅ Sicherheit



---

### Gemma 3 12B
**Google • 12B Parameter • Kontext: 120.000 Tokens**

Mittlere Version des Gemma 3-Modells mit einem hervorragenden Gleichgewicht zwischen Leistung und Effizienz.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 56 Tokens/Sekunde
- **Verbrauch** : 4,71 kWh pro Million Tokens
- **Lizenz** : [Google Gemma Nutzungsbedingungen](./licences/google_gemma_terms_of_use.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ✅ Vision • ❌ Reasoning • ❌ Sicherheit


**Anwendungsfälle:**
- Multimodale Anwendungen mit moderaten Ressourcenanforderungen
- Dokumentenverarbeitung mit Standardkontext (bis zu 100 Seiten)
- Generierung von Textinhalt und kombinierte Bildanalyse
- Deployment auf Standard-GPUs ohne spezialisierte Infrastruktur
- Fortschrittliche Chatbots mit integrierten visuellen und textuellen Fähigkeiten


---

### Gemma 3 1B
**Google • 1B Parameter • Kontext: 32.000 Tokens**

Ultra-leichtes Mikro-Modell für Deployment auf Geräten mit sehr geringen Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 112 Tokens/Sekunde
- **Verbrauch** : 0,15 kWh pro Million Tokens
- **Lizenz** : [Google Gemma Nutzungsbedingungen](./licences/google_gemma_terms_of_use.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ❌ Reasoning • ❌ Sicherheit


**Anwendungsfälle:**
- Deployment auf IoT-Geräten und eingebetteten Systemen mit API-Integration
- Anwendungen, die lokale Inferenz auf CPU mit Funktionsaufrufen benötigen
- Grundlegende Textaufgaben mit sofortiger Antwortzeit und Funktionsaufruf
- Kompakte Assistenten für Massenanwendungen mit externen Dienstintegration
- Intelligente Steuersysteme mit mehreren APIs/Services


---

### Gemma 3 4B
**Google • 4B Parameter • Kontext: 120.000 Tokens**

Kompaktes Google-Modell mit hervorragenden Leistungen in einem leichtgewichtigen und wirtschaftlichen Format.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 57 Tokens/Sekunde
- **Verbrauch** : 0,58 kWh pro Million Tokens
- **Lizenz** : [Google Gemma Nutzungsbedingungen](./licences/google_gemma_terms_of_use.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ✅ Vision • ❌ Reasoning • ❌ Sicherheit


**Anwendungsfälle:**
- Eingebettete Anwendungen und Edge Computing mit Bildverarbeitung
- Reaktive multimodale Chatbots mit geringer Latenz (<50ms)
- Skalierbare Deployment mit visuellen und textuellen Fähigkeiten
- Mobile Anwendungen mit Bild- und Textanalyse
- Verarbeitung einfacher bis mittelkomplexer visueller Anfragen mit hoher Leistung


---

### Granite 3 Guardian 2B
**IBM • 2B Parameter • Kontext: 8.192 Tokens**

Kompaktes IBM-Modell spezialisiert auf Sicherheit und Compliance, das Risiken und unangemessene Inhalte erkennt.

**Technische Spezifikationen:**
- **Geschwindigkeit** : N/A
- **Verbrauch** : N/A
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ❌ Reasoning • ✅ Sicherheit



---

### Granite 3 Guardian 8B
**IBM • 8B Parameter • Kontext: 32.000 Tokens**

IBM-Modell spezialisiert auf Sicherheit und Compliance, mit erweiterten Fähigkeiten zur Risikodetektion.

**Technische Spezifikationen:**
- **Geschwindigkeit** : N/A
- **Verbrauch** : N/A
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ❌ Reasoning • ✅ Sicherheit



---

### Granite 3.1 MoE
**IBM • 3B Parameter • Kontext: 32.000 Tokens**

Innovatives IBM-Modell mit Mixture-of-Experts (MoE)-Architektur, das hervorragende Leistungen bietet und die Berechnungsressourcen stark optimiert.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 74 Tokens/Sekunde
- **Verbrauch** : 0,45 kWh pro Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ❌ Reasoning • ✅ Sicherheit


**Anwendungsfälle:**
- Allgemeine Anwendungen mit optimiertem Inferenzkosten (42 Tokens/Sekunde)
- Dokumentenverarbeitung in CPU-Umgebungen mit begrenztem RAM
- Spezialisierte Analysen mit dynamischer Aktivierung relevanter Modellteile
- Hochdichte Deployment mit geringem Energieverbrauch pro Inferenz
- Parallele Verarbeitung mehrerer Anfragentypen mit MoE-Spezialisierung


---

### Granite 3.2 Vision
**IBM • 2B Parameter • Kontext: 16.384 Tokens**

Revolutionäres, kompaktes IBM-Modell spezialisiert auf Computer Vision, das visuelle Dokumente direkt analysieren und verstehen kann, ohne Zwischentechnologien wie OCR zu verwenden.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 48 Tokens/Sekunde
- **Verbrauch** : 0,69 kWh pro Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ✅ Vision • ❌ Reasoning • ✅ Sicherheit


**Anwendungsfälle:**
- Strukturierte Datenextraktion aus Rechnungen und Formularen ohne OCR
- Direkte Analyse von Tabellen und Grafiken mit Trendinterpretation
- Lesen und Interpretieren technischer Diagramme (elektrisch, mechanisch)
- Verarbeitung manueller Dokumente mit hohem Erkennungsrhythmus
- Leichte Computer Vision (2B Parameter) mit hoher Geschwindigkeit (50 Tokens/s)


---

### Granite 3.3 2B
**IBM • 2B Parameter • Kontext: 120.000 Tokens**

Granite 2B-Modell, feinabgestimmt von IBM, optimiert für Reasoning und Anweisungsfolge mit einem Kontext von 128k Tokens.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 45 Tokens/Sekunde
- **Verbrauch** : 0,74 kWh pro Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ✅ Sicherheit


**Anwendungsfälle:**
- Leichte Deployment mit großem Kontext (128k Tokens)
- Allgemeine Anweisungsfolgeaufgaben auf begrenzten Ressourcen
- Kompakte multilinguale IA-Assistenten
- Verarbeitung langer Dokumente auf weniger leistungsstarken Geräten
- Codegenerierung/Code-Vervollständigung (FIM) auf Standardarbeitsplätzen


---

### Granite 3.3 8B
**IBM • 8B Parameter • Kontext: 60.000 Tokens**
Granite 8B-Modell, feingetuntet von IBM für verbessertes Reasoning und Instruction Following, mit einem Kontext von 128k Tokens.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 30 Tokens/Sekunde
- **Verbrauch** : 1,11 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ✅ Sicherheit


**Anwendungsfälle:**
- Allgemeine Instruction-following-Aufgaben (Klassifizierung, Extraktion, Q&A)
- Multisprachige IA-Assistenten (12 Sprachen)
- {'Verarbeitung sehr langer Dokumente (128k Tokens)': 'Zusammenfassungen, Q&A'}
- Codegenerierung/Code-Vervollständigung mit Fill-in-the-Middle
- Integration mit externen Tools über Function Calling
- Strukturiertes Reasoning mit dem Modus "Thinking"

---

### Granite Embedding
**IBM • 278M Parameter • Kontext : 512 Tokens**

Ultra-leichtes Embedding-Modell von IBM für semantische Suche und Klassifizierung.

**Technische Spezifikationen:**
- **Geschwindigkeit** : N/A
- **Verbrauch** : N/A
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ❌ Reasoning • ❌ Sicherheit



---

### Llama 3.1 8B
**Meta • 8B Parameter • Kontext : 32.000 Tokens**

Grundmodell der Llama 3.1-Familie mit soliden Leistungen für seine Größe.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 31 Tokens/Sekunde
- **Verbrauch** : 1,08 kWh/Million Tokens
- **Lizenz** : [LLAMA 3.1 Community Lizenz](./licences/llama_3.1_community_licence.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ❌ Reasoning • ❌ Sicherheit



---

### Lucie-7B-Instruct
**OpenLLM-France • 7B Parameter • Kontext : 32.000 Tokens**

Open-Source-Kausal-Modell (7B), feingetuntet von Lucie-7B. Optimiert für Französisch.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 4 Tokens/Sekunde
- **Verbrauch** : 8,33 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ❌ Reasoning • ❌ Sicherheit



---

### Magistral 24B
**Mistral AI • 24B Parameter • Kontext : 40.000 Tokens**

Das erste Reasoning-Modell von Mistral AI, das sich durch spezifisches Domain-Reasoning, Transparenz und Mehrsprachigkeit auszeichnet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 25 Tokens/Sekunde
- **Verbrauch** : 5,33 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ✅ Reasoning • ✅ Sicherheit


**Anwendungsfälle:**
- Strategie und Geschäftsbetrieb (Risikomodellierung)
- Regulierten Branchen (Recht, Finanzen) mit nachvollziehbarem Reasoning
- Software-Engineering (Projektplanung, Architektur)
- Inhaltscreation und Kommunikation (kreative Schreibweise, Erzählung)

---

### Mistral Small 3.1
**Mistral AI • 24B Parameter • Kontext : 60.000 Tokens**

Kompaktes und reaktives Modell von Mistral AI, speziell für flüssige und relevante Konversationen mit optimaler Antwortgeschwindigkeit konzipiert.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 48 Tokens/Sekunde
- **Verbrauch** : 5,50 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ✅ Vision • ❌ Reasoning • ✅ Sicherheit


**Anwendungsfälle:**
- Konversationelle Anwendungen
- Virtuelle Assistenten mit Bild- und Textanalyse (26 Tokens/s)
- Technische Support-Chatbots mit Zugriff auf technische Dokumentation
- Inhalts-Editoren mit sofortiger Antwort (Blogs, E-Mails)
- Deployment auf Standard-Infrastrukturen (24B Parameter)

---

### Phi-4 Reasoning 14B
**Microsoft • 14B Parameter • Kontext : 32.000 Tokens**

Modell der Phi-Familie von Microsoft, spezialisiert auf komplexes Reasoning und Mathematik.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 71 Tokens/Sekunde
- **Verbrauch** : 3,71 kWh/Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit



---

### QwQ-32B
**Qwen Team • 32B Parameter • Kontext : 32.000 Tokens**

32 Milliarden Parameter umfassendes Modell, verbessert durch Verstärkungslernen (RL), um sich in Reasoning, Code, Mathematik und Agent-Aufgaben auszuzeichnen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 35 Tokens/Sekunde
- **Verbrauch** : 7,54 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit


**Anwendungsfälle:**
- Lösung komplexer Probleme mit Reasoning und Werkzeugnutzung
- Codegenerierung und -ausführung mit Ergebnisverifikation
- Fortschrittliche mathematische Aufgaben mit Genauigkeitsprüfung
- Agenten-Anwendungen, die mit der Umgebung interagieren
- Verbessertes Instruction Following und menschliche Präferenzausrichtung

---

### Qwen 2.5 0.5B
**Qwen Team • 0.5B Parameter • Kontext : 32.000 Tokens**

Ultra-leichtes Mikro-Modell der Qwen 2.5-Familie, für maximale Effizienz auf eingeschränkten Geräten konzipiert.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 162 Tokens/Sekunde
- **Verbrauch** : 0,10 kWh/Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ❌ Reasoning • ❌ Sicherheit



---

### Qwen 2.5 1.5B
**Qwen Team • 1.5B Parameter • Kontext : 32.000 Tokens**

Sehr kompaktes Modell der Qwen 2.5-Familie, das ein gutes Leistungs-/Größenverhältnis für leichte Deployment-Optionen bietet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 102 Tokens/Sekunde
- **Verbrauch** : 0,33 kWh/Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ❌ Reasoning • ❌ Sicherheit



---

### Qwen 2.5 14B
**Qwen Team • 14B Parameter • Kontext : 32.000 Tokens**

Vielseitiges mittelgroßes Modell der Qwen 2.5-Familie mit gutem Leistungs-/Ressourcenverhältnis.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 61 Tokens/Sekunde
- **Verbrauch** : 4,33 kWh/Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ❌ Reasoning • ❌ Sicherheit



---

### Qwen 2.5 32B
**Qwen Team • 32B Parameter • Kontext : 32.000 Tokens**

Leistungsstarkes Modell der Qwen 2.5-Familie mit fortgeschrittenen Fähigkeiten in Verständnis und Generierung.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 31 Tokens/Sekunde
- **Verbrauch** : 8,51 kWh/Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit



---

### Qwen 2.5 3B
**Qwen Team • 3B Parameter • Kontext : 32.000 Tokens**

Kompaktes und effizientes Modell der Qwen 2.5-Familie, für allgemeine Aufgaben auf begrenzten Ressourcen geeignet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 64 Tokens/Sekunde
- **Verbrauch** : 0,52 kWh/Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ❌ Reasoning • ❌ Sicherheit



---

### Qwen2.5-VL 3B
**Qwen Team • 3,8B Parameter • Kontext : 128.000 Tokens**

Kompaktes Vision-Langage-Modell, leistungsstarker Lösung für Edge AI (Kanten-IA).

**Technische Spezifikationen:**
- **Geschwindigkeit** : 65 Tokens/Sekunde
- **Verbrauch** : 0,51 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ✅ Vision • ✅ Reasoning • ❌ Sicherheit



---

### Qwen2.5-VL 7B
**Qwen Team • 7B (8,3B) Parameter • Kontext : 128.000 Tokens**

Leistungsstarkes Vision-Langage-Modell, das GPT-4o-mini in bestimmten Aufgaben übertrifft.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 35 Tokens/Sekunde
- **Verbrauch** : 0,95 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ✅ Vision • ✅ Reasoning • ❌ Sicherheit



---

### Qwen3 0,6b
**Qwen Team • 0,6B Parameter • Kontext : 32.000 Tokens**

Kompaktes und effizientes Modell der Qwen3-Familie, für allgemeine Aufgaben auf begrenzten Ressourcen geeignet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 112 Tokens/Sekunde
- **Verbrauch** : 0,15 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ❌ Reasoning • ❌ Sicherheit



---

### Qwen3 1,7b
**Qwen Team • 1,7B Parameter • Kontext : 32.000 Tokens**

Sehr kompaktes Modell der Qwen3-Familie, das ein gutes Leistungs-/Größenverhältnis für leichte Deployment-Optionen bietet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 88 Tokens/Sekunde
- **Verbrauch** : 0,38 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ❌ Reasoning • ❌ Sicherheit



---

### Qwen3 14B
**Qwen Team • 14B Parameter • Kontext : 32.000 Tokens**

Neue Generation Qwen3-Modell (14B), das mit besserer Effizienz vergleichbare Leistungen wie Qwen2.5 32B bietet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 68 Tokens/Sekunde
- **Verbrauch** : 3,88 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit


**Anwendungsfälle:**
- Allgemeine Aufgaben mit Leistung und großem Kontext
- Kreative und technische Inhaltsgenerierung
- Datenanalyse und komplexes Reasoning
- Integration mit externen Tools über Function Calling

---

### Qwen3 32B
**Qwen Team • 32B Parameter • Kontext: 40.000 Tokens**

Leistungsstarker Modell der neuen Generation Qwen3 mit fortgeschrittenen Fähigkeiten im Bereich Reasoning, Code und Agentik, mit erweitertem Kontext.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 18 Tokens pro Sekunde
- **Verbrauch** : 7,41 kWh pro Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit


**Anwendungsfälle:**
- Fortgeschrittene conversationale Agenten mit großem Kontext und Integration von Tools (MCP)
- Lösung komplexer Probleme (Mathematik, Code) im "Thinking"-Modus
- Analyse und Generierung umfangreicher Dokumente
- Mehrsprachige Anwendungen (>100 Sprachen), die eine tiefe Verständnisfähigkeit erfordern

---

### Qwen3 4b
**Qwen Team • 4B Parameter • Kontext: 32.000 Tokens**

Kompakter Modell der Qwen3-Familie mit hervorragenden Leistungen in einem leichtgewichtigen und wirtschaftlichen Format.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 49 Tokens pro Sekunde
- **Verbrauch** : 0,68 kWh pro Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ❌ Reasoning • ❌ Sicherheit



---

### Qwen3 8b
**Qwen Team • 8B Parameter • Kontext: 32.000 Tokens**

Qwen3 8B-Modell, das ein gutes Gleichgewicht zwischen Leistung und Effizienz für allgemeine Aufgaben bietet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 33 Tokens pro Sekunde
- **Verbrauch** : 1,01 kWh pro Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit



---

### devstral 24B
**Mistral AI & All Hands AI • 24B Parameter • Kontext: 120.000 Tokens**

Devstral ist ein agentisches LLM für Software-Engineering-Aufgaben.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 45 Tokens pro Sekunde
- **Verbrauch** : 5,86 kWh pro Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ❌ Reasoning • ✅ Sicherheit


**Anwendungsfälle:**
- Exploration und Modifikation von Code-Basen
- Agentic
- Europäisch

---

## Empfohlene Anwendungsfälle

### Mehrsprachige Gespräche

Chatbots und Assistenten, die in mehreren Sprachen kommunizieren können mit automatischer Erkennung, Aufrechterhaltung des Kontexts über die gesamte Unterhaltung und Verständnis sprachlicher Besonderheiten

**Empfohlene Modelle:**

- Llama 3.3
- Mistral Small 3.1
- Qwen 2.5
- Granite 3.3

### Analyse von langen Dokumenten

Verarbeitung umfangreicher Dokumente (>100 Seiten) mit Aufrechterhaltung des Kontexts über den gesamten Text, Extraktion von Schlüsselinformationen, Generierung relevanter Zusammenfassungen und Beantwortung spezifischer Fragen zum Inhalt

**Empfohlene Modelle:**

- Gemma 3
- DeepSeek-R1
- Granite 3.3

### Programmierung und Entwicklung

Generierung und Optimierung von Code in mehreren Sprachen, Debugging, Refactoring, Entwicklung vollständiger Funktionen, Verständnis komplexer algorithmischer Implementierungen und Erstellung von Einheitstests

**Empfohlene Modelle:**

- DeepCoder
- QwQ
- DeepSeek-R1
- Granite 3.3
- Devstral

### Visuelle Analyse

Direkte Verarbeitung von Bildern und visuellen Dokumenten ohne OCR-Vorverarbeitung, Interpretation technischer Diagramme, Grafiken, Tabellen, Zeichnungen und Fotos mit Generierung detaillierter textueller Erklärungen des visuellen Inhalts

**Empfohlene Modelle:**

- Granite 3.2 Vision
- Mistral Small 3.1
- Gemma 3
- Qwen2.5-VL

### Sicherheit und Compliance

Anwendungen, die spezifische Sicherheitsfunktionen erfordern; Inhaltsschutz, Nachverfolgbarkeit der Schlussfolgerungen, RGPD/HDS-Überprüfung, Risikominimierung, Schwachstellenanalyse und Einhaltung branchenspezifischer Vorschriften

**Empfohlene Modelle:**

- Granite Guardian
- Granite 3.3
- Devstral
- Mistral Small 3.1
- Magistral 24b
- Foundation-Sec-8B

### Leichte und eingebettete Deployment

Anwendungen, die eine minimale Ressourcenbelastung erfordern, Deployment auf Geräten mit begrenzter Kapazität, Echtzeit-Infereenz auf Standard-CPU und Integration in eingebettete oder IoT-Systeme

**Empfohlene Modelle:**

- Gemma 3
- Granite 3.1 MoE
- Granite Guardian
- Granite 3.3