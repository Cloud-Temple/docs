---
title: Katalog der Modelle LLMaaS
sidebar_position: 2
---

# Katalog der LLM-Modelle als Dienst

## √úbersicht

Cloud Temple LLMaaS bietet **45 gro√üe Sprachmodelle**, die sorgf√§ltig ausgew√§hlt und optimiert wurden, um den strengsten SecNumCloud-Anforderungen gerecht zu werden. Unser Katalog umfasst das gesamte Spektrum, von ultra-effizienten Mikro-Modellen bis zu extrem gro√üen Modellen.

### Globale Statistiken

| Metrik | Wert |
|--------|------|
| **Gesamtanzahl der Modelle** | 45 Modelle |
| **Minimale Kontextl√§nge** | 8 192 Tokens |
| **Maximale Kontextl√§nge** | 128 000 Tokens |
| **Konformit√§t** | SecNumCloud ‚úÖ HDS ‚úÖ Souver√§nit√§t ‚úÖ C5 ‚ùå |
| **Standort** | 100 % Frankreich üá´üá∑ |

### Preisgestaltung

| Verwendungstyp | Preis |
|----------------|-------|
| **Eingabetokens** | 0,90 ‚Ç¨ / Million Tokens |
| **Ausgabetokens** | 4,00 ‚Ç¨ / Million Tokens |
| **Erweitertes Reasoning** | 21,00 ‚Ç¨ / Million Tokens |

## Gro√üe Modelle

### Llama 3.3 70B  
**Meta ‚Ä¢ 70B Parameter ‚Ä¢ Kontext: 60.000 Tokens**  

Multisprachmodell der Spitzenklasse, entwickelt von Meta, entworfen, um sich in nat√ºrlichen Dialogen, komplexem Denken und feiner Verst√§ndnis von Anweisungen auszuzeichnen.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 26 Tokens pro Sekunde  
- **Verbrauch** : 11,75 kWh pro Million Tokens  
- **Lizenz** : LLAMA 3.3 Community Lizenz  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚ùå Sicherheit  

**Tags:** `Agent` `Dialog` `Multisprachig`  

**Anwendungsf√§lle:**  
- Multisprachige Chatbots, die 8 Sprachen gleichzeitig unterst√ºtzen  
- Ausf√ºhrung komplexer, verketteter Anweisungen (Prompt-Ketten)  
- Verarbeitung einer Dialogfenster von 60.000 Tokens f√ºr Conversationsverl√§ufe  
- Analyse umfangreicher juristischer oder technischer Dokumente (>100 Seiten)  
- Erstellung strukturierter Texte mit Treue zu stilistischen Anweisungen

### Qwen3 235B  
**Qwen Team ‚Ä¢ 235B Parameter ‚Ä¢ Kontext: 60.000 Tokens**  

Ein sehr gro√ües Modell der neuen Qwen3-Generation mit erweiterten F√§higkeiten f√ºr komplexe Aufgaben.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 17 Tokens pro Sekunde  
- **Verbrauch:** 7,84 kWh pro Million Tokens  
- **Lizenz:** Apache 2.0  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Tags:** `Agent` `Reasoning` `Mehrsprachig` `Sehr gro√ü`  

**Anwendungsf√§lle:**  
- Sehr fortgeschrittene conversationelle Agenten mit gro√üem Kontext und Tools-Integration (MCP)  
- L√∂sung extrem komplexer Probleme (Mathematik, Code)  
- Analyse und Generierung sehr umfangreicher und technischer Dokumente  
- Multisprachige Anwendungen (>100 Sprachen), die eine hochpr√§zise Verst√§ndnis- und Generierungsf√§higkeit erfordern

### DeepSeek-R1 671B  
**DeepSeek AI ‚Ä¢ 671B Parameter ‚Ä¢ Kontext: 16.000 Tokens**  

Sehr gro√ües Modell von DeepSeek AI, designed f√ºr den H√∂chststand von Denken und Generierung.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 12 Tokens/Sekunde  
- **Verbrauch:** 11,11 kWh/Million Tokens  
- **Lizenz:** MIT Lizenz  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Denken ‚Ä¢ ‚ùå Sicherheit  

**Tags:** `Denken` `Extrem gro√ü`  

**Anwendungsf√§lle:**  
- H√∂chstleistungsdenkaufgaben  
- Hochwertige Textgenerierung  
- AI-Forschung und -entwicklung

### Gemma 3 27B  
**Google ‚Ä¢ 27B Parameter ‚Ä¢ Kontext: 120.000 Tokens**  

Revolution√§res Modell von Google, das ein optimales Gleichgewicht zwischen Leistung und Effizienz bietet, mit einem au√üergew√∂hnlichen Leistungs-Kosten-Verh√§ltnis f√ºr anspruchsvolle professionelle Anwendungen.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 20 Tokens pro Sekunde  
- **Verbrauch** : 6,67 kWh pro Million Tokens  
- **Lizenz** : Google Gemma Nutzungsbedingungen  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Tags:** `Vision` `Agent` `Gro√üer Kontext`  

**Anwendungsf√§lle:**  
- Dokumentenanalyse mit erweitertem Kontext bis zu 120.000 Tokens (ca. 400 Seiten)  
- Semantische Indexierung und Suche in umfangreichen Dokumentenbanken  
- Gleichzeitige Verarbeitung von Bildern und Text dank multimodaler F√§higkeiten  
- Strukturierte Datenextraktion aus PDFs und gescannten Dokumenten  
- Integration mit externen Tools √ºber die API-Funktionaufruf-Funktion

### Qwen3 30B-A3B FP8
**Qwen Team ‚Ä¢ 30B-A3B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Neue Generation MoE FP8-Modell (3B aktiviert) mit hybriden Denkmustern und starken Agentenf√§higkeiten.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 106 Tokens/Sekunde ‚ö°
- **Verbrauch** : 2,88 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit

**Tags:** `MoE` `Agent` `Reasoning` `Schnell` `Mehrsprachig`

**Anwendungsf√§lle:**
- Fortschrittliche conversationale Agenten mit Integration von Tools (MCP)
- L√∂sung komplexer Probleme (Mathematik, Code) im ‚ÄûDenken‚Äú-Modus
- Mehrsprachige Anwendungen (>100 Sprachen)
- Szenarien, die ein Kosten-Leistungsverh√§ltnis (MoE) auf VLLM erfordern
- Mehrround-Dialoge mit pr√§ziser Anweisungsverfolgung

### DeepSeek-R1 70B  
**DeepSeek AI ‚Ä¢ 70B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Modell 70B von DeepSeek AI  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 21 Tokens pro Sekunde  
- **Verbrauch** : 12,56 kWh pro Million Tokens  
- **Lizenz** : MIT-Lizenz  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Tags:** `Reasoning` `Large`  

**Anwendungsf√§lle:**  
- Spitzenleistungen im Reasoning  
- Hochwertige Textgenerierung  
- AI-Forschung und -Entwicklung  

---

### Qwen2.5-VL 32B
**Qwen Team ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 120.000 Tokens**

Die leistungsst√§rkste Version der Qwen2.5-VL-Serie mit f√ºhrenden F√§higkeiten in visueller Verst√§ndnis und Agententechnologie.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 18 Tokens pro Sekunde
- **Verbrauch** : 7,41 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Begr√ºndung ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Vision` `Agent` `Begr√ºndung` `OCR` `Visuelle Lokalisierung` `Gro√ü`

**Anwendungsf√§lle:**
- Analyse von sehr komplexen Dokumenten und Diagrammen
- Autonome visuelle Agenten f√ºr Navigation und Interaktion mit GUIs
- Objektlokalisierungsaufgaben und hochpr√§zise Texterkennung
- Generierung reicher und detaillierter Beschreibungen aus komplexen Bildern

### Qwen2.5-VL 72B
**Qwen Team ‚Ä¢ 72B Parameter ‚Ä¢ Kontext: 128.000 Tokens**

Die leistungsst√§rkste Version der Qwen2.5-VL-Serie, die visuelle Verst√§ndnisf√§higkeit und Avantgarde-Agentik f√ºr anspruchsvollste Aufgaben bietet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 15 Tokens/Sekunde Tokens/Sekunde
- **Verbrauch** : 8,89 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Begr√ºndung ‚Ä¢ ‚úÖ Visuelle Verst√§ndnisf√§higkeit ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Vision` `Agent` `Begr√ºndung` `OCR` `Visuelle Lokalisierung` `Sehr Gro√ü`

**Anwendungsf√§lle:**
- Analyse von Dokumenten und komplexen Diagrammen
- Autonome visuelle Agenten f√ºr Navigation und Interaktion mit GUIs
- Objektlokalisierungsaufgaben und hochpr√§zise Texterkennung
- Erstellung reicher und detaillierter Beschreibungen aus sehr komplexen Bildern

## Spezialisierte Modelle

### Qwen3 14B
**Qwen Team ‚Ä¢ 14B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Neue Generation dichter Qwen3-Modell (14B) mit Leistungen, die denen von Qwen2.5 32B entsprechen, aber mit besserer Effizienz.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 68 Tokens/Sekunde ‚ö°
- **Verbrauch:** 3,88 kWh pro Million Tokens
- **Lizenz:** Apache 2.0
- **Standort:** FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Agent` `Reasoning` `Schnell` `Mehrsprachig`

**Anwendungsf√§lle:**
- Allgemeine Aufgaben, die Leistung und einen gro√üen Kontext erfordern
- Erstellung kreativer und technischer Inhalte
- Datenanalyse und komplexes Reasoning
- Integration mit externen Tools √ºber Function Calling

### Gemma 3 12B  
**Google ‚Ä¢ 12B Parameter ‚Ä¢ Kontext: 120.000 Tokens**  

Intermediate-Version des Gemma 3-Modells mit einem hervorragenden Gleichgewicht zwischen Leistung und Effizienz.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 56 Tokens/Sekunde ‚ö°  
- **Verbrauch:** 4,71 kWh pro Million Tokens  
- **Lizenz:** Google Gemma Nutzungsbedingungen  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Begr√ºndung ‚Ä¢ ‚ùå Sicherheit  

**Tags:** `Vision` `Schnell` `Gro√üer Kontext`  

**Anwendungsf√§lle:**  
- Multimodale Anwendungen mit moderaten Ressourcenbeschr√§nkungen  
- Dokumentenverarbeitung mit Standardkontext (bis zu 100 Seiten)  
- Textinhaltsgenerierung und kombinierte Bildanalyse  
- Bereitstellung auf Standard-GPUs ohne spezialisierte Infrastruktur  
- Fortgeschrittene Chatbots mit integrierten visuellen und textuellen F√§higkeiten

### Gemma 3 4B  
**Google ‚Ä¢ 4B Parameter ‚Ä¢ Kontext: 120.000 Tokens**  

Kompakter Google-Modell, der hervorragende Leistungen in einem leichten und kosteneffizienten Format bietet.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 57 Tokens/Sekunde ‚ö°  
- **Verbrauch** : 0,58 kWh pro Million Tokens üå±  
- **Lizenz** : Google Gemma Terms of Use  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Tags:** `Vision` `Schnell` `Kompakt` `Gro√üer Kontext` `Effizient`  

**Anwendungsf√§lle:**  
- Eingebettete Anwendungen und Edge Computing mit Bildverarbeitung  
- Multimodale Chatbots mit geringer Latenz  
- Skalierbare Deployment mit visuellen und textuellen F√§higkeiten  
- Mobile Anwendungen mit Bild- und Textanalyse  
- Einfache bis mittelkomplexe visuelle Anfragen mit hoher Leistungsf√§higkeit

### Gemma 3 1B  
**Google ‚Ä¢ 1B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Ultra-leichtgewichtsmodell f√ºr Bereitstellungen auf Ger√§ten mit extrem geringen Ressourcen.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 112 Tokens/Sekunde ‚ö°  
- **Verbrauch** : 0,15 kWh pro Million Tokens üå±  
- **Lizenz** : Google Gemma Nutzungsbedingungen  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Begr√ºndung ‚Ä¢ ‚ùå Sicherheit  

**Tags:** `Ultra-kompakt` `Eingebettet` `Effizient` `Schnell`  

**Anwendungsf√§lle:**  
- Bereitstellung auf IoT-Ger√§ten und eingebetteten Systemen mit API-Integration  
- Anwendungen, die lokale Inferenz auf der CPU mit Funktionsaufrufen erfordern  
- Grundlegende Textaufgaben mit sofortiger Antwortzeit und Funktionsaufrufen  
- Kompakte Assistenten f√ºr Endverbraucher-Anwendungen mit Integration externer Dienste  
- Intelligente Steuersysteme, die mehrere APIs/Dienste integrieren

### Lucie-7B-Instruct
**OpenLLM-France ‚Ä¢ 7B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Kausales multilinguales Open-Source-Modell (7B), gefinetuned von Lucie-7B. Optimiert f√ºr Franz√∂sisch.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 4 Tokens/Sekunde
- **Verbrauch:** 8,33 kWh/Million Tokens üå±
- **Lizenz:** Apache 2.0
- **Standort:** FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Franz√∂sisch` `Open-Source` `Effizient`

### Mistral Small 3.1  
**Mistral AI ‚Ä¢ 24B Parameter ‚Ä¢ Kontext: 120.000 Tokens**  

Kompakter und reaktiver Modell von Mistral AI, speziell entwickelt, um eine fl√ºssige und relevante conversationale Unterst√ºtzung mit optimaler Antwortgeschwindigkeit zu bieten.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 35 Tokens/Sekunde  
- **Verbrauch:** 3,72 kWh pro Million Tokens  
- **Lizenz:** Apache 2.0  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit  

**Tags:** `Vision` `Agent` `Sicherheit`  

**Anwendungsf√§lle:**  
- Konversationale Anwendungen  
- Virtuelle Assistenten, die Bild- und Textanalyse kombinieren (26 Tokens/s)  
- Technische Support-Chatbots mit Zugriff auf technische Dokumentation  
- Tools zur Inhaltserstellung/Redaktion mit sofortiger Antwort (Blogs, E-Mails)  
- Deployment auf Standardinfrastrukturen (24B Parameter)

### Mistral Small 3.2  
**Mistral AI ‚Ä¢ 24B Parameter ‚Ä¢ Kontext: 120.000 Tokens**  

Kleine Aktualisierung von Mistral Small 3.1, die die Befehlsverfolgung, die Robustheit des Function Calls verbessert und Wiederholungsfehler reduziert.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 35 Tokens/Sekunde  
- **Verbrauch:** 3,72 kWh/pro Million Tokens  
- **Lizenz:** Apache 2.0  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit  

**Tags:** `Vision` `Agent` `Sicherheit` `Anweisungsfolge`  

**Anwendungsf√§lle:**  
- Konversationelle Agenten mit verbesserter Befehlsverfolgung  
- Robuste Integration mit externen Tools √ºber Function Calls  
- Anwendungen, die eine hohe Zuverl√§ssigkeit erfordern, um Wiederholungen zu vermeiden  
- Identische Anwendungsf√§lle wie bei Mistral Small 3.1 mit verbesserten Leistungen  

---

### Mistral Small 3.2  
**Mistral AI ‚Ä¢ 24B Parameter ‚Ä¢ Kontext: 120.000 Tokens**  

Kleine Aktualisierung von Mistral Small 3.1, die die Befehlsverfolgung, die Robustheit des Function Calls und die Reduzierung von Wiederholungsfehlern verbessert.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 50 Tokens pro Sekunde  
- **Verbrauch:** 5,28 kWh pro Million Tokens  
- **Lizenz:** Apache 2.0  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Werkzeuge/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit  

**Tags:** `Vision` `Agent` `Sicherheit` `Befehlsverfolgung`  

**Anwendungsf√§lle:**  
- Konversationelle Agenten mit verbesserter Befehlsverfolgung  
- Robuste Integration mit externen Tools √ºber Function Calls  
- Anwendungen, die eine gro√üe Zuverl√§ssigkeit erfordern, um Wiederholungen zu vermeiden  
- √Ñhnliche Anwendungsf√§lle wie bei Mistral Small 3.1 mit verbesserten Leistungen  

---

### DeepCoder  
**Agentica x Together AI ‚Ä¢ 14B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Open-Source-IA-Modell (14B) von Together AI & Agentica, glaubw√ºrdige Alternative zu propriet√§ren Modellen f√ºr die Codegenerierung.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 64 Tokens pro Sekunde ‚ö°  
- **Verbrauch** : 4,12 kWh pro Million Tokens  
- **Lizenz** : Apache 2.0  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Tags:** `Programmierung` `Reasoning` `Open-Source` `Mathematik` `Schnell`  

**Anwendungsf√§lle:**  
- Codegenerierung in mehr als 15 Sprachen mit Leistungsoptimierung  
- Debugging und Refaktorisierung bestehender Code-Basen mit Auswirkungsanalyse  
- Implementierung komplexer Algorithmen (Graphen, B√§ume, Heuristiken)  
- Automatisierte Erstellung von Einheitstests mit Codeabdeckung > 80%  
- Code-√úbertragung zwischen Sprachen/Frameworks (z. B. Python zu JavaScript)

### Granite 3.2 Vision  
**IBM ‚Ä¢ 2B Parameter ‚Ä¢ Kontext: 16.384 Tokens**  

Revolution√§res kompaktes Modell von IBM, spezialisiert auf Computer Vision, das visuelle Dokumente direkt analysieren und verstehen kann, ohne Zwischentechnologien wie OCR zu verwenden.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 48 Tokens/Sekunde  
- **Verbrauch:** 0,69 kWh pro Million Tokens üå±  
- **Lizenz:** Apache 2.0  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Begr√ºndung ‚Ä¢ ‚úÖ Sicherheit  

**Tags:** `Vision` `Sicherheit` `Kompakt` `Effizient`  

**Anwendungsf√§lle:**  
- Strukturierte Datenextraktion aus Rechnungen und Formularen ohne OCR  
- Direkte Analyse von Tabellen und Grafiken mit Interpretation von Trends  
- Lesen und Interpretieren technischer Diagramme (elektrisch, mechanisch)  
- Verarbeitung von handschriftlichen Dokumenten mit hohem Erkennungsrhythmus  
- Leichte Computer Vision (2 Milliarden Parameter) mit hoher Geschwindigkeit (50 Tokens/s)

### Granite 3.3 8B  
**IBM ‚Ä¢ 8B Parameter ‚Ä¢ Kontext: 60.000 Tokens**  

Granite 8B-Modell, feinabgestimmt von IBM f√ºr verbessertes Reasoning und Instruction Following, mit einem Kontext von 128k Tokens.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 30 Tokens pro Sekunde  
- **Verbrauch:** 1,11 kWh pro Million Tokens üå±  
- **Lizenz:** Apache 2.0  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚úÖ Sicherheit  

**Tags:** `Agent` `Reasoning` `Sicherheit` `Effizient`  

**Anwendungsf√§lle:**  
- Allgemeine Aufgaben zur Anweisungsfollowing (Klassifizierung, Extraktion, Q&A)  
- Multisprachige IA-Assistenten (12 Sprachen)  
- Verarbeitung sehr langer Dokumente (128k Tokens) f√ºr Aufgaben wie Zusammenfassungen, Q&A,...  
- Codegenerierung/Code-Vervollst√§ndigung mit Fill-in-the-Middle  
- Integration mit externen Tools √ºber Function Calling  
- Strukturiertes Reasoning mit dem ‚ÄûThinking‚Äú-Modus

### Granite 3.3 2B  
**IBM ‚Ä¢ 2B Parameter ‚Ä¢ Kontext: 120.000 Tokens**  

Feinabgestimmtes Granite 2B-Modell von IBM, optimiert f√ºr Reasoning und Anweisungsbefolgung mit einem Kontext von 128k Tokens.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 45 Tokens/Sekunde  
- **Verbrauch** : 0,74 kWh pro Million Tokens üå±  
- **Lizenz** : Apache 2.0  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚úÖ Sicherheit  

**Tags:** `Agent` `Reasoning` `Sicherheit` `Effizient`  

**Anwendungsf√§lle:**  
- Leichte Deployment mit gro√üem Kontext (128k Tokens)  
- Allgemeine Anweisungsbefolgungsaufgaben auf eingeschr√§nkten Ressourcen  
- Kompakte multilinguale KI-Assistenten  
- Verarbeitung langer Dokumente auf weniger leistungsstarken Ger√§ten  
- FIM-Codegenerierung/Completions auf Standardarbeitspl√§tzen  

---

### Magistral 24B  
**Mistral AI ‚Ä¢ 24B Parameter ‚Ä¢ Kontext: 40.000 Tokens**  

Das erste Reasoning-Modell von Mistral AI, das sich durch spezifisches Dom√§nen-Reasoning, Transparenz und Mehrsprachigkeit auszeichnet.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 25 Tokens pro Sekunde  
- **Verbrauch:** 5,33 kWh pro Million Tokens  
- **Lizenz:** Apache 2.0  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Werkzeuge/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚úÖ Sicherheit  

**Tags:** `Reasoning` `Mehrsprachig`  

**Anwendungsf√§lle:**  
- Strategie und Gesch√§ftsvorg√§nge (Risikomodellierung)  
- Regulierte Branchen (rechtlich, Finanzen) mit nachvollziehbarem Reasoning  
- Softwareentwicklung (Projektplanung, Architektur)  
- Inhaltserstellung und Kommunikation (kreative Schreibweise, Erz√§hlung)

### Granite 3.1 MoE
**IBM ‚Ä¢ 3B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Innovatives Modell von IBM, das die Mixture-of-Experts-Architektur (MoE) verwendet, um au√üergew√∂hnliche Leistungen zu erzielen und die Ressourcennutzung drastisch zu optimieren.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 74 Tokens/Sekunde ‚ö°
- **Verbrauch** : 0,45 kWh pro Million Tokens üå±
- **Lizenz** : Apache 2.0
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit

**Tags:** `Agent` `Sicherheit` `Schnell` `MoE` `Effizienz` `Effizient`

**Anwendungsf√§lle:**
- Allgemeine Anwendungen mit optimiertem Inferenzkostensatz (42 Tokens/Sekunde)
- Dokumentverarbeitung in CPU-Umgebungen mit begrenzter RAM-Verwendung
- Spezialisierte Analysen mit dynamischer Aktivierung relevanter Modellteile
- Hochdichte-Deployment mit geringem Energieverbrauch pro Inferenz
- Parallele Verarbeitung verschiedener Anfragentypen mit MoE-Spezialisierung

### cogito:14b  
**Deep Cogito ‚Ä¢ 14B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Speziell f√ºr tiefes Denken und feines Kontextverstehen entwickelter Deep Cogito-Modell, ideal f√ºr anspruchsvolle analytische Anwendungen.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 60 Tokens/Sekunde ‚ö°  
- **Verbrauch** : 4,4 kWh pro Million Tokens  
- **Lizenz** : LLAMA 3.2 Community-Lizenz  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Denken ‚Ä¢ ‚ùå Sicherheit  

**Tags:** `Agent` `Denken` `Verstehen` `Analyse` `Schnell`  

**Anwendungsf√§lle:**  
- Semantische Analyse von Texten mit Identifizierung impliziter Implikationen  
- Strukturierter kausaler Denkprozess mit Identifizierung von Ursache-Wirkungs-Beziehungen  
- Synthese komplexer Dokumente mit Extraktion der Schl√ºsselinformationen  
- Pr√§zise Frage-Antwort-Systeme f√ºr spezialisierte Dokumentkorpora  
- Argumentationsanalyse mit Bewertung der St√§rke der Denkprozesse

### Cogito 32B  
**Deep Cogito ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Erweiterte Version des Cogito-Modells mit erheblich verst√§rkten F√§higkeiten der Rationalisierung und Analyse, designed f√ºr die anspruchsvollsten Anwendungen im Bereich analytischer KI.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 32 Tokens/Sekunde  
- **Verbrauch:** 8,25 kWh/Million Tokens  
- **Lizenz:** LLAMA 3.2 Community Lizenz  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Rationalit√§t ‚Ä¢ ‚ùå Sicherheit  

**Tags:** `Agent` `Rationalit√§t` `Verst√§ndnis` `Analyse`  

**Anwendungsf√§lle:**  
- Analyse von Multi-Faktor-Szenarien mit wahrscheinlichkeitsbasierten Bewertungen der Ergebnisse  
- L√∂sung wissenschaftlicher Probleme mit formalen Demonstrationen der Schritte  
- Hochkritische Anwendungen, die Genauigkeit und Verifizierbarkeit der Ergebnisse erfordern  
- Expertensysteme in spezialisierten Bereichen (rechtlich, medizinisch, technisch)  
- Analyse mit mehrstufigem Denken und vollst√§ndiger Erkl√§rbarkeit der Schlussfolgerungen

### Qwen3 32B
**Qwen Team ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 40.000 Tokens**

Leistungsstarker Modell der neuen Qwen3-Generation mit fortgeschrittenen F√§higkeiten im Bereich Reasoning, Code und Agentik sowie erweitertem Kontext.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 18 Tokens pro Sekunde
- **Verbrauch:** 7,41 kWh pro Million Tokens
- **Lizenz:** Apache 2.0
- **Standort:** FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Agent` `Reasoning` `Mehrsprachig` `Gro√ües Kontext`

**Anwendungsf√§lle:**
- Fortgeschrittene conversationale Agenten mit gro√üem Kontext und Tool-Integration (MCP)
- L√∂sung komplexer Probleme (Mathematik, Code) mit dem "Thinking"-Modus
- Analyse und Generierung umfangreicher Dokumente
- Mehrsprachige Anwendungen (>100 Sprachen), die eine tiefe Verst√§ndnis erfordern

### QwQ-32B
**Qwen Team ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Modell mit 32 Milliarden Parametern, verbessert durch Reinforcement Learning (RL), um sich in der Begr√ºndung, Codierung, Mathematik und Agentent√§tigkeiten hervorzutun.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 35 Tokens pro Sekunde
- **Verbrauch** : 7,54 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Werkzeuge/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Begr√ºndung ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Agent` `Begr√ºndung` `Codierung` `Mathematik`

**Anwendungsf√§lle:**
- L√∂sung komplexer Probleme, die Begr√ºndung und Nutzung von Werkzeugen erfordern
- Erstellung und Ausf√ºhrung von Code mit Ergebnis√ºberpr√ºfung
- Fortgeschrittene mathematische Aufgaben mit √úberpr√ºfung der Genauigkeit
- Agentenanwendungen, die mit der Umgebung interagieren k√∂nnen
- Verbessertes Anweisungsfollowing und Ausrichtung auf menschliche Pr√§ferenzen

### DeepSeek-R1 14B
**DeepSeek AI ‚Ä¢ 14B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Kompakte und effiziente Version des DeepSeek-R1-Modells, die ein exzellentes Gleichgewicht zwischen Leistung und Leichtigkeit bietet f√ºr Bereitstellungen, die Flexibilit√§t und Reaktionsf√§higkeit erfordern.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 62 Tokens/Sekunde ‚ö°
- **Verbrauch:** 4,26 kWh pro Million Tokens
- **Lizenz:** MIT-Lizenz
- **Standort:** FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Reasoning` `Kompakt` `Vielseitig` `Schnell`

**Anwendungsf√§lle:**
- Allgemeine Anwendungen mit Bedarf an schneller Inferenz (44 Tokens/s)
- Bereitstellung auf Standard-Servern ohne spezialisierte GPU (14B Parameter)
- Textverarbeitung mit kontextueller Analyse und schneller Antwortzeit
- Bereitstellung im Edge Computing mit optimierter lokaler Inferenz
- Schnelle Prototypenerstellung von KI-Anwendungen mit kurzer Iterationszeit

### DeepSeek-R1 32B
**DeepSeek AI ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Zwischenversion des DeepSeek-R1-Modells, die ein strategisches Gleichgewicht zwischen den fortgeschrittenen F√§higkeiten der 70B-Version und der Effizienz der 14B-Version bietet, f√ºr maximale Vielseitigkeit und Leistung.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 33 Tokens/Sekunde
- **Verbrauch:** 7,99 kWh pro Million Tokens
- **Lizenz:** MIT-Lizenz
- **Standort:** FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Reasoning` `Vielseitig`

**Anwendungsf√§lle:**
- Anwendungen, die ein gutes Verh√§ltnis von Leistung/Kosten ben√∂tigen (32B Parameter)
- Professionelle Textverarbeitung mit Analyse der semantischen Nuancen
- Automatisierte Generierung strukturierter Berichte aus Rohdaten
- Anwendungen, die Datenanalyse und Inhaltsgenerierung kombinieren
- Spezialassistenten f√ºr technische Bereiche (rechtlich, medizinisch, technisch)

### Cogito 3B
**Deep Cogito ‚Ä¢ 3B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Kompakte Version des Cogito-Modells, optimiert f√ºr das Denken auf Ger√§ten mit begrenzten Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 55 Tokens pro Sekunde ‚ö°
- **Verbrauch** : 0,61 kWh pro Million Tokens üå±
- **Lizenz** : LLAMA 3.2 Community Lizenz
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Werkzeuge/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Denken` `Kompakt` `Eingebettet` `Effizient` `Schnell`

### Granite Embedding  
**IBM ‚Ä¢ 278M Parameter ‚Ä¢ Kontext: 512 Tokens**  

Ultra-leichtes Embedding-Modell von IBM f√ºr semantische Suche und Klassifizierung.  

**Technische Spezifikationen:**  
- **Lizenz** : Apache 2.0  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Tags :** `Embedding` `Kompakt` `Semantisch` `Effizient`

### Granite 3 Guardian 2B  
**IBM ‚Ä¢ 2B Parameter ‚Ä¢ Kontext: 8 192 Tokens**  

Kompakter IBM-Modell, spezialisiert auf Sicherheit und Compliance, erkennend Risiken und unangemessene Inhalte.  

**Technische Spezifikationen:**  
- **Lizenz** : Apache 2.0  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit  

**Tags :** `Sicherheit` `Compliance` `Kompakt` `Filterung` `Effizient`

### Granite 3 Guardian 8B  
**IBM ‚Ä¢ 8B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

IBM-Modell, spezialisiert auf Sicherheit und Compliance, mit fortgeschrittenen F√§higkeiten zur Risikodetektion.  

**Technische Spezifikationen:**  
- **Lizenz** : Apache 2.0  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit  

**Tags :** `Sicherheit` `Compliance` `Filterung`

### Qwen 2.5 0.5B  
**Qwen Team ‚Ä¢ 0.5B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Mikromodell der Qwen 2.5-Familie, entwickelt f√ºr maximale Effizienz auf Ger√§ten mit begrenzten Ressourcen.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 162 Tokens/Sekunde ‚ö°  
- **Verbrauch:** 0,1 kWh pro Million Tokens üå±  
- **Lizenz:** MIT-Lizenz  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Begr√ºndung ‚Ä¢ ‚ùå Sicherheit  

**Tags:** `Ultra-kompakt` `Schnell` `Eingebettet` `Effizient`

### Qwen 2.5 1.5B
**Qwen Team ‚Ä¢ 1.5B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Sehr kompakter Modell der Qwen 2.5-Familie mit einem guten Leistungs-/Gr√∂√üenverh√§ltnis f√ºr leichte Bereitstellungen.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 102 Tokens pro Sekunde ‚ö°
- **Verbrauch:** 0.33 kWh pro Million Tokens üå±
- **Lizenz:** MIT-Lizenz
- **Standort:** FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Kompakt` `Schnell` `Eingebettet` `Effizient`

### Qwen 2.5 14B
**Qwen-Team ‚Ä¢ 14B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Mittelschweres, vielseitiges Modell der Qwen 2.5-Familie mit einem guten Leistungs-/Ressourcenverh√§ltnis.

**Technische Spezifikationen :**
- **Geschwindigkeit** : 61 Tokens/Sekunde ‚ö°
- **Verbrauch** : 4,33 kWh pro Million Tokens
- **Lizenz** : MIT-Lizenz
- **Standort** : FR üá´üá∑

**F√§higkeiten :**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚ùå Sicherheit

**Tags :** `Vielseitig` `Mehrsprachig` `Schnell`

### Qwen 2.5 32B
**Qwen Team ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Leistungsstarker Modell der Qwen 2.5-Familie mit fortgeschrittenen F√§higkeiten in Verst√§ndnis und Generierung.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 31 Tokens pro Sekunde
- **Verbrauch:** 8,51 kWh pro Million Tokens
- **Lizenz:** MIT-Lizenz
- **Standort:** FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Begr√ºndung ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Vielseitig` `Mehrsprachig` `Begr√ºndung`

### Qwen 2.5 3B
**Qwen Team ‚Ä¢ 3B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Kompakter und effizienter Modell der Qwen 2.5-Familie, geeignet f√ºr allgemeine Aufgaben bei begrenzten Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 64 Tokens pro Sekunde Tokens pro Sekunde ‚ö°
- **Verbrauch** : 0,52 kWh pro Million Tokens üå±
- **Lizenz** : MIT-Lizenz
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Werkzeuge/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Begr√ºndung ‚Ä¢ ‚ùå Sicherheit

**Tags :** `Kompakt` `Schnell` `Vielseitig` `Effizient`

### Qwen3 0.6b  
**Qwen Team ‚Ä¢ 0.6B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Kompakter und effizienter Modell der Qwen3-Familie, geeignet f√ºr allgemeine Aufgaben bei begrenzten Ressourcen.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 112 Tokens pro Sekunde ‚ö°  
- **Verbrauch** : 0.15 kWh pro Million Tokens üå±  
- **Lizenz** : Apache 2.0  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Begr√ºndung ‚Ä¢ ‚ùå Sicherheit  

**Tags:** `Kompakt` `Schnell` `Vielseitig` `Effizient`

### Qwen3 1.7b  
**Qwen Team ‚Ä¢ 1,7B Parameter ‚Ä¢ Kontext: 32 000 Tokens**  

Sehr kompakt Modell der Qwen3-Familie, das ein gutes Leistungs-/Gr√∂√üenverh√§ltnis f√ºr leichte Bereitstellungen bietet.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 88 Tokens pro Sekunde ‚ö°  
- **Verbrauch** : 0,38 kWh pro Million Tokens üå±  
- **Lizenz** : Apache 2.0  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Begr√ºndung ‚Ä¢ ‚ùå Sicherheit  

**Tags:** `Kompakt` `Schnell` `Eingebettet` `Effizient`

### Qwen3 4b  
**Qwen Team ‚Ä¢ 4B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Kompakter Modell der Qwen3-Familie mit exzellenten Leistungen in einem leichtgewichtigen und kosteneffizienten Format.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 49 Tokens/Sekunde  
- **Verbrauch:** 0,68 kWh/pro Million Tokens üå±  
- **Lizenz:** Apache 2.0  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Begr√ºndung ‚Ä¢ ‚ùå Sicherheit  

**Tags:** `Kompakt` `Effizient`

### Qwen3 8b  
**Qwen Team ‚Ä¢ 8B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Modell Qwen3 8B, das ein gutes Gleichgewicht zwischen Leistung und Effizienz f√ºr allgemeine Aufgaben bietet.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 33 Tokens pro Sekunde  
- **Verbrauch** : 1,01 kWh pro Million Tokens üå±  
- **Lizenz** : Apache 2.0  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Tags:** `Reasoning` `Agent` `Mehrsprachig` `Effizient`

### Qwen2.5-VL 3B
**Qwen Team ‚Ä¢ 3,8 Milliarden Parameter ‚Ä¢ Kontext: 128.000 Tokens**

Kompakter Vision-Sprach-Modell, leistungsstarke L√∂sung f√ºr Edge AI.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 65 Tokens pro Sekunde ‚ö°
- **Verbrauch** : 0,51 kWh pro Million Tokens üå±
- **Lizenz** : Apache 2.0
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚úÖ Begr√ºndung ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Vision` `Agent` `Begr√ºndung` `Schnell` `Effizient` `OCR` `Visuelle Lokalisierung` `Edge AI`

### Qwen2.5-VL 7B
**Qwen Team ‚Ä¢ 7B (8,3B) Parameter ‚Ä¢ Kontext: 128.000 Tokens**

Leistungsstarker Vision-Langage-Modell, das GPT-4o-mini in bestimmten Aufgaben √ºbertrifft.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 35 Tokens pro Sekunde Tokens pro Sekunde
- **Verbrauch** : 0,95 kWh pro Million Tokens üå±
- **Lizenz** : Apache 2.0
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Vision` `Agent` `Reasoning` `Effizient` `OCR` `Visuelle Lokalisierung`

### Foundation-Sec-8B
**Foundation AI ‚Äî Cisco ‚Ä¢ 8B Parameter ‚Ä¢ Kontext: 16.384 Tokens**

Spezialmodell f√ºr Cybersecurity, optimiert f√ºr Effizienz.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 21 Tokens pro Sekunde
- **Verbrauch** : 1,59 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚úÖ Sicherheit

**Tags :** `Sicherheit` `Kompakt`

### devstral 24B  
**Mistral AI & All Hands AI ‚Ä¢ 24B Parameter ‚Ä¢ Kontext: 120.000 Tokens**  

Devstral ist ein agentenbasiertes LLM f√ºr Softwareentwicklungsarbeiten.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 45 Tokens/Sekunde  
- **Verbrauch** : 5,86 kWh/Million Tokens  
- **Lizenz** : Apache 2.0  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit  

**Tags :** `Agent` `Programmierung` `Open-Source` `Gro√üer Kontext`  

**Anwendungsf√§lle:**  
- Erkundung und √Ñnderung von Code-Basen  
- Agentenbasiert  
- Europ√§isch

### Cogito 8B  
**Deep Cogito ‚Ä¢ 8B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Mittleres Modell der Cogito-Familie mit einem guten Gleichgewicht zwischen Reasoning-F√§higkeiten und Effizienz.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 30 Tokens/Sekunde  
- **Verbrauch:** 1,11 kWh/Million Tokens üå±  
- **Lizenz:** LLAMA 3.2 Community Lizenz  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Tags:** `Agent` `Reasoning` `Vielseitig` `Effizient`

### Llama 3.1 8B
**Meta ‚Ä¢ 8B Parameter ‚Ä¢ Kontext: 32.000 Token**

Grundmodell der Llama 3.1-Familie mit soliden Leistungen f√ºr seine Gr√∂√üe.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 31 Token pro Sekunde
- **Verbrauch** : 1,08 kWh pro Million Token üå±
- **Lizenz** : LLAMA 3.1 Community Lizenz
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Vielseitig` `Effizient`

### Phi-4 Reasoning 14B  
**Microsoft ‚Ä¢ 14B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Modell der Microsoft-Phi-Familie, spezialisiert auf komplexes Denken und Mathematik.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 71 Tokens/Sekunde ‚ö°  
- **Verbrauch** : 3,71 kWh pro Million Tokens  
- **Lizenz** : MIT-Lizenz  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Begr√ºndung ‚Ä¢ ‚ùå Sicherheit  

**Tags :** `Begr√ºndung` `Mathematik` `Programmierung` `Schnell`

## Empfohlene Anwendungsf√§lle

### Mehrsprachiger Dialog
Chatbots und Assistenten, die in mehreren Sprachen kommunizieren k√∂nnen, mit automatischer Spracherkennung, Beibehaltung des Kontexts √ºber die gesamte Unterhaltung und Verst√§ndnis der sprachlichen Besonderheiten

**Empfohlene Modelle:**
- Llama 3.3
- Mistral Small 3.1
- Qwen 2.5
- Granite 3.3

### Analyse von langen Dokumenten  
Verarbeitung von umfangreichen Dokumenten (>100 Seiten) mit Beibehaltung des Kontexts √ºber den gesamten Text, Extraktion von Schl√ºsselinformationen, Erstellung relevanter Zusammenfassungen und Beantwortung spezifischer Fragen zum Inhalt  

**Empfohlene Modelle:**  
- Gemma 3  
- DeepSeek-R1  
- Granite 3.3

### Programmierung und Entwicklung  
Erstellung und Optimierung von Code in mehreren Sprachen, Debugging, Refactoring, Entwicklung vollst√§ndiger Funktionen, Verst√§ndnis komplexer algorithmischer Implementierungen und Erstellung von Einheitstests  

**Empfohlene Modelle:**  
- DeepCoder  
- QwQ  
- DeepSeek-R1  
- Granite 3.3  
- Devstral

### Visuelle Analyse  
Direkte Verarbeitung von Bildern und visuellen Dokumenten ohne OCR-Vorverarbeitung, Interpretation technischer Diagramme, Grafiken, Tabellen, Zeichnungen und Fotos mit Erstellung detaillierter textueller Erkl√§rungen des visuellen Inhalts  

**Empfohlene Modelle:**  
- Granite 3.2 Vision  
- Mistral Small 3.1  
- Gemma 3  
- Qwen2.5-VL

### Sicherheit und Compliance  
Anwendungen, die spezifische Sicherheitsfunktionen erfordern; Filterung sensibler Inhalte, Nachvollziehbarkeit der Schlussfolgerungen, RGPD/HDS-Pr√ºfung, Risikominimierung, Schwachstellenanalyse und Einhaltung branchenspezifischer Vorschriften  

**Empfohlene Modelle:**  
- Granite Guardian  
- Granite 3.3  
- Devstral  
- Mistral Small 3.1  
- Magistral 24b  
- Foundation-Sec-8B

### Leichte und eingebettete Bereitstellungen  
Anwendungen, die eine minimale Ressourcenbelastung erfordern, Bereitstellung auf Ger√§ten mit begrenzter Kapazit√§t, Echtzeit-Infereenz auf Standard-CPU und Integration in eingebettete Systeme oder IoT  

**Empfohlene Modelle:**  
- Gemma 3  
- Granite 3.1 MoE  
- Granite Guardian  
- Granite 3.3