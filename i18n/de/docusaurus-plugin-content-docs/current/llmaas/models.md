---
title: Katalog der KI-Modelle
sidebar_position: 2
---

# Katalog der Modelle LLM als Dienst

## √úbersicht

Cloud Temple LLMaaS bietet **gro√üe Sprachmodelle** sorgf√§ltig ausgew√§hlt und optimiert. Unser Katalog abdeckt das gesamte Spektrum, von ultra-effizienten Mikromodellen bis zu extrem gro√üen Modellen.

### Hinweis zu Leistungsma√üen
Die Geschwindigkeitswerte (Tokens/s) stellen Leistungsziele unter echten Bedingungen dar. Der Energieverbrauch (kWh/Mtoken) wird berechnet, indem die gesch√§tzte Leistung des Inferenz-Servers (in Watt) durch die gemessene Geschwindigkeit des Modells (in Tokens pro Sekunde) geteilt wird und anschlie√üend in Kilowattstunden pro Million Tokens umgerechnet wird. Diese Methode bietet eine praktische Vergleichsm√∂glichkeit f√ºr die Energieeffizienz verschiedener Modelle und sollte als relativer Indikator, nicht als absoluter Messwert des Energieverbrauchs verwendet werden.

### Globale Statistiken

| Metrik | Wert |
|----------|--------|
| **Gesamtanzahl der Modelle** | 36 Modelle |
| **Minimales Kontext** | 8 192 Tokens |
| **Maximales Kontext** | 120 000 Tokens |
| **Konformit√§t** | SecNumCloud ‚úÖ HDS ‚úÖ Souver√§nit√§t ‚úÖ C5 ‚úÖ |
| **Standort** | 100% Frankreich üá´üá∑ |

### Preisgestaltung

| Typ der Nutzung | Preis |
|-------------------|------|
| **Eingabetokens** | 0,90 ‚Ç¨ / Million Tokens |
| **Ausgabetokens** | 4,00 ‚Ç¨ / Million Tokens |
| **Erweitertes Reasoning** | 21,00 ‚Ç¨ / Million Tokens |

## Gro√üe Modelle

### Llama 3.3 70B  
**Meta ‚Ä¢ 70B Parameter ‚Ä¢ Kontext: 60.000 Tokens**  

Multisprachmodell der Spitzenklasse, entwickelt von Meta, konzipiert, um sich in nat√ºrlichen Dialogen, komplexem Denken und feiner Verst√§ndnis von Anweisungen zu bew√§hren.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 30 Tokens/Sekunde  
- **Verbrauch:** 8,87 kWh/Million Tokens  
- **Lizenz:** [LLAMA 3.3 Community Lizenz](./licences/llama3.3_70b.lizenz.md)  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚ùå Sicherheit  

**Anwendungsf√§lle:**  
- Multisprachige Chatbots, die 8 Sprachen gleichzeitig unterst√ºtzen  
- Ausf√ºhrung komplexer, verketteter Anweisungen (Prompt-Chaining)  
- Verarbeitung einer Dialogfenster von 60.000 Tokens f√ºr conversationelle Historien  
- Analyse von umfangreichen juristischen oder technischen Dokumenten (√ºber 100 Seiten)  
- Erstellung strukturierter Texte mit Treue zu stilistischen Anweisungen

### Qwen3 235B  
**Qwen Team ‚Ä¢ 235B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Ein sehr gro√ües Modell der neuen Generation Qwen3 mit erweiterten F√§higkeiten f√ºr komplexe Aufgaben.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 21 Tokens pro Sekunde  
- **Verbrauch:** 6,35 kWh pro Million Tokens  
- **Lizenz:** [Apache 2.0](./licences/apache2.licence.md)  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Anwendungsf√§lle:**  
- Sehr fortgeschrittene conversationelle Agenten mit gro√üem Kontext und Werkzeugintegration (MCP)  
- L√∂sung extrem komplexer Probleme (Mathematik, Code)  
- Analyse und Generierung sehr umfangreicher und technischer Dokumente  
- Mehrsprachige Anwendungen (>100 Sprachen), die eine sehr hohe Genauigkeit bei Verst√§ndnis und Generierung erfordern

### DeepSeek-R1 671B  
**DeepSeek AI ‚Ä¢ 671B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Sehr gro√ües Modell von DeepSeek AI, konzipiert f√ºr die maximale Leistung bei Reasoning und Generierung.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 16 Tokens/Sekunde  
- **Verbrauch:** 8,33 kWh pro Million Tokens  
- **Lizenz:** [MIT Lizenz](./licences/deepseek-r1_671b.licence.md)  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Anwendungsf√§lle:**  
- Hochleistungs-Reasoning-Aufgaben  
- Hochwertige Textgenerierung  
- AI-Forschung und -Entwicklung  

---

### Gemma 3 27B  
**Google ‚Ä¢ 27B Parameter ‚Ä¢ Kontext: 120.000 Tokens**  

Revolution√§res Modell von Google, das ein optimales Gleichgewicht zwischen Leistung und Effizienz bietet, mit einem au√üergew√∂hnlichen Leistungs-Kosten-Verh√§ltnis f√ºr anspruchsvolle professionelle Anwendungen.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 68 Tokens/Sekunde ‚ö°  
- **Verbrauch** : 3,91 kWh pro Million Tokens  
- **Lizenz** : [Google Gemma Nutzungsbedingungen](./licences/gemma3_27b.licence.md)  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Anwendungsf√§lle:**  
- Dokumentenanalyse mit erweitertem Kontext bis zu 120 K Tokens (ca. 400 Seiten)  
- Semantische Indizierung und Suche in umfangreichen Dokumentenbanken  
- Gleichzeitige Verarbeitung von Bildern und Text dank multimodaler F√§higkeiten  
- Strukturierte Datenextraktion aus PDFs und gescannten Dokumenten  
- Integration mit externen Tools √ºber die API-Funktionaufruf-Funktion

### Qwen3 30B-A3B FP8
**Qwen Team ‚Ä¢ 30B-A3B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Neues FP8-MoE-Modell (3B aktiviert) mit hybriden Denkmodi und fortgeschrittenen Agentenf√§higkeiten.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 103 Tokens/Sekunde ‚ö°
- **Verbrauch** : 2,58 kWh pro Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Begr√ºndung ‚Ä¢ ‚ùå Sicherheit

**Anwendungsf√§lle:**
- Forte conversationelle Agenten mit Tools-Integration (MCP)
- Komplexe Probleml√∂sung (Mathematik, Code) im "Thinking"-Modus
- Mehrsprachige Anwendungen (>100 Sprachen)
- Szenarien, die ein Kosteneffizienz-Gleichgewicht auf VLLM ben√∂tigen
- Mehrround-Dialoge mit pr√§ziser Anweisungsverfolgung

### DeepSeek-R1 70B  
**DeepSeek AI ‚Ä¢ 70B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

70B-Modell von DeepSeek AI  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 20 Tokens pro Sekunde  
- **Verbrauch** : 11,44 kWh pro Million Tokens  
- **Lizenz** : [MIT-Lizenz](./licences/deepseek-r1_70b.licence.md)  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Anwendungsf√§lle:**  
- Komplexe Reasoning-Aufgaben  
- Hochwertige Textgenerierung  
- Tiefe Dokumentenanalyse (im Rahmen des Kontexts von 27k)  

---

## Spezialisierte Modelle

### Qwen3 14B  
**Qwen Team ‚Ä¢ 14B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Neue Generation des dichten Qwen3-Modells (14B) mit Leistungen, die denen von Qwen2.5 32B entsprechen, und besserer Effizienz.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 69 Tokens pro Sekunde ‚ö°  
- **Verbrauch:** 2,65 kWh pro Million Tokens  
- **Lizenz:** [Apache 2.0](./licences/apache2.licence.md)  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Werkzeuge/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Anwendungsf√§lle:**  
- Allgemeine Aufgaben, die Leistung und einen gro√üen Kontext erfordern  
- Erstellung kreativer und technischer Inhalte  
- Datenanalyse und komplexes Denken  
- Integration mit externen Tools √ºber Function Calling

### Gemma 3 12B  
**Google ‚Ä¢ 12B Parameter ‚Ä¢ Kontext: 120.000 Tokens**  

Mittlere Version des Gemma 3-Modells, die ein hervorragendes Gleichgewicht zwischen Leistung und Effizienz bietet.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 67 Tokens pro Sekunde ‚ö°  
- **Verbrauch** : 2,73 kWh pro Million Tokens  
- **Lizenz** : [Google Gemma Terms of Use](./licences/gemma3_12b.licence.md)  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Anwendungsf√§lle:**  
- Multimodale Anwendungen mit moderaten Ressourcenbeschr√§nkungen  
- Dokumentenverarbeitung mit Standardkontext (bis zu 100 Seiten)  
- Textinhaltserzeugung und kombinierte Bildanalyse  
- Bereitstellung auf Standard-GPUs ohne spezialisierte Infrastruktur  
- Fortgeschrittene Chatbots mit integrierten visuellen und textuellen F√§higkeiten

### Gemma 3 4B  
**Google ‚Ä¢ 4B Parameter ‚Ä¢ Kontext: 120.000 Tokens**  

Kompakter Google-Modell, der hervorragende Leistungen in einem leichten und kosteneffizienten Format bietet.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 58 Tokens/Sekunde ‚ö°  
- **Verbrauch** : 0,93 kWh pro Million Tokens üå±  
- **Lizenz** : [Google Gemma Nutzungsbedingungen](./licences/gemma3_4b.licence.md)  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Anwendungsf√§lle:**  
- Eingebettete Anwendungen und Edge Computing mit Bildverarbeitung  
- Reaktive multimodale Chatbots mit geringer Latenz  
- Skalierbare Bereitstellungen mit visuellen und textuellen F√§higkeiten  
- Mobile Anwendungen mit Bild- und Textanalyse  
- Verarbeitung von visuellen Anfragen mit geringer bis mittlerer Komplexit√§t mit hoher Leistung

### Gemma 3 1B
**Google ‚Ä¢ 1B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Mikro-Modell mit extrem geringem Ressourcenbedarf f√ºr Deployment auf Ger√§ten mit sehr begrenzten Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 41 Tokens/Sekunde
- **Verbrauch:** 1,32 kWh pro Million Tokens üå±
- **Lizenz:** [Google Gemma Nutzungsbedingungen](./licences/gemma3_1b.licence.md)
- **Standort:** FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit

**Anwendungsf√§lle:**
- Deployment auf IoT-Ger√§ten und eingebetteten Systemen mit API-Integration
- Anwendungen, die lokale Inferenz auf CPU mit Funktionsaufrufen erfordern
- Grundlegende Textaufgaben mit sofortiger Antwortzeit und Funktionsaufruf
- Kompakte Assistenten f√ºr Endverbraucher-Anwendungen mit Integration externer Dienste
- Intelligente Steuersysteme, die mehrere APIs/Dienste integrieren

### Lucie-7B-Instruct
**OpenLLM-France ‚Ä¢ 7B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Kausales multilinguales Open-Source-Modell (7B), feinabgestimmt von Lucie-7B. Optimiert f√ºr Franz√∂sisch.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 41 tokens/seconde tokens/seconde
- **Verbrauch** : 1,32 kWh/million Tokens üå±
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit

---

### Mistral Small 3.1  
**Mistral AI ‚Ä¢ 24B Parameter ‚Ä¢ Kontext: 60.000 Tokens**  

Kompakter und reaktiver Modell von Mistral AI, speziell entwickelt, um eine fl√ºssige und relevante conversationale Unterst√ºtzung mit optimaler Antwortgeschwindigkeit zu bieten.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 14 Tokens/Sekunde  
- **Verbrauch:** 13,06 kWh/Million Tokens  
- **Lizenz:** [Apache 2.0](./licences/apache2.licence.md)  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit  

**Anwendungsf√§lle:**  
- Konversationale Anwendungen  
- Virtuelle Assistenten, die Bild- und Textanalyse kombinieren (26 Tokens/s)  
- Technische Support-Chatbots mit Zugriff auf technische Dokumentation  
- Tools zur Inhaltserstellung/Redaktion mit sofortiger Antwort (Blogs, E-Mails)  
- Bereitstellung auf Standardinfrastrukturen (24B Parameter)

### DeepCoder  
**Agentica x Together AI ‚Ä¢ 14B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Open-Source-IA-Modell (14B) von Together AI & Agentica, eine glaubw√ºrdige Alternative zu propriet√§ren Modellen f√ºr die Codegenerierung.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 62 Tokens/Sekunde ‚ö°  
- **Verbrauch** : 2,95 kWh/Million Tokens  
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Anwendungsf√§lle:**  
- Codegenerierung in mehr als 15 Sprachen mit Leistungsoptimierung  
- Debugging und Refaktorisierung bestehender Code-Basen mit Auswirkungsanalyse  
- Implementierung komplexer Algorithmen (Graphen, B√§ume, Heuristiken)  
- Code-√úbertragung zwischen Sprachen und Frameworks (z. B. Python zu JavaScript)  
- Automatisierte Erstellung von Einheitstests mit Codeabdeckung > 80%

### Granite 3.2 Vision  
**IBM ‚Ä¢ 2B Parameter ‚Ä¢ Kontext: 16 384 Tokens**  

Revolution√§res, kompaktes Modell von IBM, spezialisiert auf Computer Vision, das visuelle Dokumente direkt analysieren und verstehen kann, ohne Zwischentechnologien wie OCR zu verwenden.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 48 Tokens pro Sekunde ‚ö°  
- **Verbrauch:** 1,13 kWh pro Million Tokens üå±  
- **Lizenz:** [Apache 2.0](./licences/apache2.licence.md)  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit  

**Anwendungsf√§lle:**  
- Strukturierte Datenextraktion aus Rechnungen und Formularen ohne OCR  
- Direkte Analyse von Tabellen und Grafiken mit Trendinterpretation  
- Lesen und Verstehen technischer Diagramme (elektrisch, mechanisch)  
- Verarbeitung von Handschriften mit hohem Erkennungsrhythmus  
- Leichte Computer Vision (2B Parameter) mit hoher Geschwindigkeit (79 Tokens/s)

### Granite 3.3 8B  
**IBM ‚Ä¢ 8B Parameter ‚Ä¢ Kontext: 128.000 Token**  

Feinabgestimmtes Granite 8B-Modell von IBM f√ºr verbessertes Reasoning und Anweisungsbefolgung mit einem Kontext von 128.000 Token.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 27 Token/Sekunde  
- **Verbrauch** : 2,0 kWh pro Million Token üå±  
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚úÖ Sicherheit  

**Anwendungsf√§lle:**  
- Allgemeine Anweisungsbefolgungsaufgaben (Klassifizierung, Extraktion, Q&A)  
- Mehrsprachige IA-Assistenten (12 Sprachen)  
- Verarbeitung sehr langer Dokumente (128.000 Token): Zusammenfassungen und Fragen-Beantwortungen  
- Codegenerierung/Code-Vervollst√§ndigung mit Fill-in-the-Middle  
- Integration mit externen Tools √ºber Function Calling  
- Strukturierter Reasoning im Modus ‚ÄûDenken‚Äú

### Granite 3.3 2B  
**IBM ‚Ä¢ 2B Parameter ‚Ä¢ Kontext: 120.000 Tokens**  

Granite 2B Modell, feingetuntet von IBM, optimiert f√ºr Reasoning und Instruction Following, mit einem Kontext von 128k Tokens.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 45 Tokens/Sekunde ‚ö°  
- **Verbrauch** : 1,2 kWh pro Million Tokens üå±  
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚úÖ Sicherheit  

**Anwendungsf√§lle:**  
- Leichte Deployment mit gro√üem Kontext (128k Tokens)  
- Allgemeine Instruction Following Aufgaben auf eingeschr√§nkten Ressourcen  
- Kompakte multilinguale IA-Assistenten  
- Verarbeitung langer Dokumente auf weniger leistungsstarken Ger√§ten  
- Code-Generierung/Completions FIM auf Standardarbeitspl√§tzen

### Granite 3.1 MoE  
**IBM ‚Ä¢ 3B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Innovatives Modell von IBM, das die Mixture-of-Experts-Architektur (MoE) verwendet, um au√üergew√∂hnliche Leistungen zu erzielen und die Ressourcennutzung drastisch zu optimieren.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 74 Tokens/Sekunde ‚ö°  
- **Verbrauch** : 0,73 kWh pro Million Tokens üå±  
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Berechnungen ‚Ä¢ ‚úÖ Sicherheit  

**Anwendungsf√§lle:**  
- Allgemeine Anwendungen mit optimierten Inferenzkosten (42 Tokens/Sekunde)  
- Dokumentenverarbeitung in CPU-Umgebungen mit begrenzter RAM-Verwendung  
- Spezialanalysen mit dynamischer Aktivierung relevanter Modellteile  
- Hochdichte-Deployment mit geringem Energieverbrauch pro Inferenz  
- Parallele Verarbeitung mehrerer Anfragentypen mit MoE-Spezialisierung

### Cogito 14B  
**Deep Cogito ‚Ä¢ 14B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Modell von Deep Cogito, speziell entwickelt, um sich bei tiefen Denkprozessen und feinem Kontextverstehen hervorzuheben, ideal f√ºr anspruchsvolle analytische Anwendungen.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 60 Tokens/Sekunde ‚ö°  
- **Verbrauch:** 3,05 kWh pro Million Tokens  
- **Lizenz:** [Apache 2.0](./licences/apache2.licence.md)  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Denken ‚Ä¢ ‚ùå Sicherheit  

**Anwendungsf√§lle:**  
- Semantische Analyse von Texten mit Identifizierung impliziter Implikationen  
- Strukturiertes kausales Denken mit Identifizierung von Ursache-Wirkungs-Beziehungen  
- Synthese komplexer Dokumente mit Extraktion der Schl√ºsselinformationen  
- Pr√§zise Frage-Antwort-Systeme f√ºr spezialisierte Dokumentenkorpora  
- Argumentationsanalyse mit Bewertung der St√§rke von Schlussfolgerungen

### Cogito 32B  
**Deep Cogito ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Erweiterte Version des Cogito-Modells mit erheblich verst√§rkten F√§higkeiten im Bereich des Denkens und der Analyse, konzipiert f√ºr die anspruchsvollsten Anwendungen im Bereich analytischer KI.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 32 Tokens/Sekunde  
- **Verbrauch** : 5,73 kWh/Million Tokens  
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Denken ‚Ä¢ ‚ùå Sicherheit  

**Anwendungsf√§lle:**  
- Analyse von Multi-Faktor-Szenarien mit wahrscheinlichkeitsbasierten Bewertungen der Ergebnisse  
- L√∂sung wissenschaftlicher Probleme mit formaler Darstellung der Schritte  
- Anwendungen mit hoher Kritikalit√§t, die Genauigkeit und Verifizierbarkeit der Ergebnisse erfordern  
- Expertensysteme in spezialisierten Bereichen (rechtlich, medizinisch, technisch)  
- Analyse mit mehrstufigem Denken und vollst√§ndiger Erkl√§rbarkeit der Schlussfolgerungen

### Qwen3 32B  
**Qwen Team ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 40.000 Tokens**  

Leistungsstarker Modell der neuen Qwen3-Generation mit fortgeschrittenen F√§higkeiten im Reasoning, Code und Agententechnologie, mit erweitertem Kontext.  

**Technische Spezifikationen:**  
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Anwendungsf√§lle:**  
- Fortgeschrittene conversationelle Agenten mit gro√üem Kontext und Werkzeugintegration (MCP)  
- L√∂sung komplexer Probleme (Mathematik, Code) mit dem "Thinking"-Modus  
- Analyse und Generierung umfangreicher Dokumente  
- Mehrsprachige Anwendungen (>100 Sprachen), die eine tiefe Verst√§ndnis erfordern

### QwQ-32B  
**Qwen Team ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Modell mit 32 Milliarden Parametern, verbessert durch Verst√§rkungslernen (RL), um sich in Reasoning, Codierung, Mathematik und Agentenaufgaben hervorzutun.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 35 Tokens/Sekunde  
- **Verbrauch:** 5,22 kWh/Million Tokens  
- **Lizenz:** [Apache 2.0](./licences/apache2.licence.md)  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Anwendungsf√§lle:**  
- Komplexe Probleml√∂sung mit Reasoning und Nutzung von Tools  
- Erstellung und Ausf√ºhrung von Code mit Ergebnis√ºberpr√ºfung  
- Fortgeschrittene mathematische Aufgaben mit Genauigkeitspr√ºfung  
- Agentenanwendungen, die mit der Umgebung interagieren k√∂nnen  
- Verbessertes Anweisungsbefolgen und Ausrichtung auf menschliche Pr√§ferenzen

### DeepSeek-R1 14B  
**DeepSeek AI ‚Ä¢ 14B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Kompakte und effiziente Version des DeepSeek-R1-Modells, die ein hervorragendes Gleichgewicht zwischen Leistung und Leichtigkeit bietet f√ºr Bereitstellungen mit Flexibilit√§t und Reaktionsf√§higkeit.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 60 Tokens/Sekunde ‚ö°  
- **Verbrauch:** 3,05 kWh pro Million Tokens  
- **Lizenz:** [MIT-Lizenz](./licences/deepseek-r1_14b.licence.md)  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Anwendungsf√§lle:**  
- Allgemeine Anwendungen mit Bedarf an schneller Inferenz (44 Tokens/Sekunde)  
- Bereitstellungen auf Standard-Servern ohne spezialisierte GPU (14B Parameter)  
- Textverarbeitung mit kontextueller Analyse und Antwortzeiten < 2 Sekunden  
- Bereitstellung im Edge Computing mit optimierter lokaler Inferenz  
- Schnelle Prototypenerstellung von KI-Anwendungen mit kurzen Iterationszeiten

### DeepSeek-R1 32B  
**DeepSeek AI ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Zwischenversion des DeepSeek-R1-Modells, die ein strategisches Gleichgewicht zwischen den fortgeschrittenen F√§higkeiten der 70B-Version und der Effizienz der 14B-Version bietet, f√ºr maximale Vielseitigkeit und Leistung.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 33 Tokens/Sekunde  
- **Verbrauch:** 5,54 kWh/Million Tokens  
- **Lizenz:** [MIT Lizenz](./licences/deepseek-r1_32b.licence.md)  
- **Standort:** FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit  

**Anwendungsf√§lle:**  
- Anwendungen, die ein gutes Verh√§ltnis von Leistung/Kosten ben√∂tigen (32B Parameter)  
- Professionelle Textverarbeitung mit Analyse semantischer Feinheiten  
- Automatisierte Generierung strukturierter Berichte aus Rohdaten  
- Anwendungen, die Datenanalyse und Inhaltsgenerierung kombinieren  
- Spezialisierte Assistenten f√ºr technische Branchen (rechtlich, medizinisch, technisch)

### Cogito 3B
**Deep Cogito ‚Ä¢ 3B Parameter ‚Ä¢ Kontext: 32 000 Tokens**

Kompakte Version des Cogito-Modells, optimiert f√ºr das Denken auf Ger√§ten mit begrenzten Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 63 Tokens/Sekunde ‚ö°
- **Verbrauch** : 0,86 kWh/Million Tokens üå±
- **Lizenz** : [LLAMA 3.2 Community Lizenz](./licences/cogito_3b.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Begr√ºndung ‚Ä¢ ‚ùå Sicherheit

### Granite Embedding  
**IBM ‚Ä¢ 278M Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Ultra-leichtes Embedding-Modell von IBM f√ºr semantische Suche und Klassifizierung.  

**Technische Spezifikationen:**  
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit

### Granite 3 Guardian 2B  
**IBM ‚Ä¢ 2B Parameter ‚Ä¢ Kontext: 8 192 Tokens**  

Kompakter IBM-Modell, spezialisiert auf Sicherheit und Compliance, der Risiken und unangemessene Inhalte erkennt.  

**Technische Spezifikationen:**  
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Begr√ºndung ‚Ä¢ ‚úÖ Sicherheit  

---

### Granite 3 Guardian 8B  
**IBM ‚Ä¢ 8B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

IBM-Modell spezialisiert auf Sicherheit und Compliance mit fortgeschrittenen F√§higkeiten zur Risikodetektion.  

**Technische Spezifikationen:**  
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit

### Qwen 2.5 0.5B
**Qwen Team ‚Ä¢ 0.5B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Ultraleichtes Mikromodell der Qwen 2.5-Familie, entworfen f√ºr maximale Effizienz auf Ger√§ten mit begrenzten Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 57 Tokens pro Sekunde ‚ö°
- **Verbrauch:** 0,95 kWh pro Million Tokens üå±
- **Lizenz:** [MIT Lizenz](./licences/qwen2.5_0.5b.licence.md)
- **Lokalisierung:** FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Begr√ºndung ‚Ä¢ ‚ùå Sicherheit

### Qwen 2.5 1.5B  
**Qwen-Team ‚Ä¢ 1,5B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Sehr kompakter Modell der Qwen 2.5-Familie, der ein gutes Leistungs-/Gr√∂√üengleichgewicht f√ºr leichte Bereitstellungen bietet.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 94 Tokens/Sekunde ‚ö°  
- **Verbrauch** : 0,58 kWh pro Million Tokens üå±  
- **Lizenz** : [MIT Lizenz](./licences/qwen2.5_1.5b.lizenz.md)  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚ùå Sicherheit

### Qwen 2.5 14B
**Qwen-Team ‚Ä¢ 14B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Mittelschweres Multitasking-Modell der Qwen 2.5-Familie mit gutem Leistungs-/Ressourcenverh√§ltnis.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 61 Tokens/Sekunde ‚ö°
- **Verbrauch** : 3,0 kWh pro Million Tokens
- **Lizenz** : [MIT-Lizenz](./licences/qwen2.5_14b.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit

---

### Qwen 2.5 32B
**Qwen-Team ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Leistungsstarker Modell der Qwen 2.5-Familie mit fortgeschrittenen F√§higkeiten in Verst√§ndnis und Generierung.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 32 Tokens/Sekunde
- **Verbrauch** : 5,73 kWh/million Tokens
- **Lizenz** : [MIT Lizenz](./licences/qwen2.5_32b.lizenz.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Werkzeuge/Agent ‚Ä¢ ‚ùå Bildverarbeitung ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit

### Qwen 2.5 3B
**Qwen-Team ‚Ä¢ 3B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Kompakter und effizienter Modell der Qwen 2.5-Familie, geeignet f√ºr allgemeine Aufgaben bei begrenzten Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 60 Tokens pro Sekunde ‚ö°
- **Verbrauch** : 0,9 kWh pro Million Tokens üå±
- **Lizenz** : [MIT-Lizenz](./licences/qwen2.5_3b.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit

### Qwen3 0.6b  
**Qwen-Team ‚Ä¢ 0,6B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Kompakter und effizienter Modell der Qwen3-Familie, geeignet f√ºr allgemeine Aufgaben bei begrenzten Ressourcen.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 60 Tokens/Sekunde ‚ö°  
- **Verbrauch** : 0,9 kWh pro Million Tokens üå±  
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Werkzeuge/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Begr√ºndung ‚Ä¢ ‚ùå Sicherheit

### Qwen3 1.7b  
**Qwen-Team ‚Ä¢ 1,7 Milliarden Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Sehr kompakter Modell der Qwen3-Familie, der ein gutes Leistungs-/Gr√∂√üenverh√§ltnis f√ºr leichte Bereitstellungen bietet.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 83 Tokens/Sekunde ‚ö°  
- **Verbrauch** : 0,65 kWh pro Million Tokens üå±  
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Werkzeuge/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚ùå Sicherheit

### Qwen3 4b  
**Qwen Team ‚Ä¢ 4B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Kompakter Modell der Qwen3-Familie mit hervorragenden Leistungen in einem leichtgewichtigen und wirtschaftlichen Format.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 48 Tokens/Sekunde  
- **Verbrauch** : 1,13 kWh pro Million Tokens üå±  
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Begr√ºndung ‚Ä¢ ‚ùå Sicherheit  

---

### Qwen3 8b  
**Qwen Team ‚Ä¢ 8B Parameter ‚Ä¢ Kontext: 32.000 Tokens**  

Qwen3 8B-Modell mit einem guten Gleichgewicht aus Leistung und Effizienz f√ºr allgemeine Aufgaben.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 29 Tokens pro Sekunde  
- **Verbrauch** : 1,87 kWh pro Million Tokens üå±  
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Begr√ºndung ‚Ä¢ ‚ùå Sicherheit

### Qwen2.5-VL 3B
**Qwen Team ‚Ä¢ 3,8B Parameter ‚Ä¢ Kontext: 128.000 Tokens**

Kompakter Vision-Sprach-Modell, leistungsstarke L√∂sung f√ºr Edge-Computing (Edge AI).

**Technische Spezifikationen:**
- **Geschwindigkeit** : 65 Tokens/Sekunde ‚ö°
- **Verbrauch** : 0,83 kWh pro Million Tokens üå±
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit

---

### Qwen2.5-VL 7B
**Qwen Team ‚Ä¢ 7B (8,3B) Parameter ‚Ä¢ Kontext: 128.000 Tokens**

Leistungsstarker Vision-Langage-Modell, das GPT-4o-mini in bestimmten Aufgaben √ºbertrifft.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 37 Tokens pro Sekunde
- **Verbrauch** : 1,46 kWh pro Million Tokens üå±
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit

### Foundation-Sec-8B
**Foundation AI ‚Äî Cisco ‚Ä¢ 8B Parameter ‚Ä¢ Kontext: 16.000 Tokens**

Spezialisiert auf Cybersecurity, optimiert f√ºr Effizienz.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 22 Tokens/Sekunde
- **Verbrauch** : 2,46 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚úÖ Sicherheit

---

### devstral 24B  
**Mistral AI & All Hands AI ‚Ä¢ 24B Parameter ‚Ä¢ Kontext: 120.000 Tokens**  

Devstral ist ein LLM-Agent f√ºr Software-Engineering-Aufgaben.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 53 Tokens/Sekunde ‚ö°  
- **Verbrauch** : 4,5 kWh/pro Million Tokens  
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)  
- **Standort** : FR üá´üá∑  

**F√§higkeiten:**  
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit  

**Anwendungsf√§lle:**  
- Exploration und Modifikation von Code-Basen  
- Agentic  
- Europ√§isch

## Empfohlene Anwendungsf√§lle

### Mehrsprachiger Dialog

Chatbots und Assistenten, die in der Lage sind, in mehreren Sprachen zu kommunizieren, mit automatischer Spracherkennung, Erhalt des Kontexts √ºber die gesamte Unterhaltung hinweg und Verst√§ndnis der sprachlichen Besonderheiten

**Empfohlene Modelle:**

- Llama 3.3
- Mistral Small 3.1
- Qwen 2.5
- Granite 3.3

### Analyse von langen Dokumenten

Verarbeitung von umfangreichen Dokumenten (>100 Seiten) bei Beibehaltung des Kontexts √ºber den gesamten Text hinweg, Extraktion von Schl√ºsselinformationen, Erstellung relevanter Zusammenfassungen und Beantwortung spezifischer Fragen zum Inhalt

**Empfohlene Modelle:**

- Gemma 3
- DeepSeek-R1
- Granite 3.3

### Programmierung und Entwicklung  
Erstellung und Optimierung von Code in mehreren Sprachen, Debugging, Refactoring, Entwicklung vollst√§ndiger Funktionen, Verst√§ndnis komplexer algorithmischer Implementierungen und Erstellung von Einheitstests  

**Empfohlene Modelle:**  

- DeepCoder  
- QwQ  
- DeepSeek-R1  
- Granite 3.3  
- Devstral

### Visuelle Analyse

Direkte Bildverarbeitung und Verarbeitung visueller Dokumente ohne vorherige OCR-Vorverarbeitung, Interpretation technischer Diagramme, Grafiken, Tabellen, Zeichnungen und Fotos mit der Generierung detaillierter textueller Erkl√§rungen des visuellen Inhalts

**Empfohlene Modelle:**

- Granite 3.2 Vision
- Mistral Small 3.1
- Gemma 3
- Qwen2.5-VL

### Sicherheit und Compliance

Anwendungen, die spezifische Sicherheitsfunktionen erfordern; Filterung sensibler Inhalte, Nachvollziehbarkeit der Schlussfolgerungen, DSGVO/HDS-Pr√ºfung, Risikominimierung, Schwachstellenanalyse und Einhaltung branchenspezifischer Vorschriften

**Empfohlene Modelle:**

- Granite Guardian
- Granite 3.3
- Devstral
- Mistral Small 3.1
- Foundation-Sec-8B

### Leichte und eingebettete Bereitstellungen

Anwendungen, die eine minimale Ressourcenbelastung erfordern, Bereitstellung auf Ger√§ten mit begrenzter Kapazit√§t, Echtzeit-Infereenz auf Standard-CPU und Integration in eingebettete Systeme oder IoT

**Empfohlene Modelle :**

- Gemma 3
- Granite 3.1 MoE
- Granite Guardian
- Granite 3.3