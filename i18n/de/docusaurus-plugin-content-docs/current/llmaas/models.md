---
title: Katalog der KI-Modelle
sidebar_position: 2
---

# Katalog der LLM-as-a-Service-Modelle

## √úbersicht

Cloud Temple LLMaaS bietet **36 gro√üe Sprachmodelle**, sorgf√§ltig ausgew√§hlt und optimiert, um die strengsten Anforderungen von **SecNumCloud** zu erf√ºllen. Unser Katalog umfasst das gesamte Spektrum, von ultra-effizienten Mikromodellen bis hin zu extrem gro√üen Modellen.

### Globale Statistiken

| Metrik | Wert |
|--------|------|
| **Gesamtanzahl der Modelle** | 36 Modelle |
| **Minimale Kontextl√§nge** | 8.192 Tokens |
| **Maximale Kontextl√§nge** | 120.000 Tokens |
| **Konformit√§t** | SecNumCloud ‚úÖ HDS ‚úÖ Souver√§nit√§t ‚úÖ C5 ‚úÖ |
| **Standort** | 100% Frankreich üá´üá∑ |

### Preise

| Nutzungstyp | Preis |
|-------------|-------|
| **Eingabetokens** | 0,90 ‚Ç¨ / Million Tokens |
| **Ausgabetokens** | 4,00 ‚Ç¨ / Million Tokens |
| **Erweitertes Denken** | 21,00 ‚Ç¨ / Million Tokens |

## Gro√üe Modelle

### Llama 3.3 70B
**Meta ‚Ä¢ 70B Parameter ‚Ä¢ Kontext: 60.000 Tokens**

Hochleistungs-Mehrsprachmodell von Meta, optimiert f√ºr nat√ºrliche Gespr√§che, komplexes Denken und feine Anweisungsverarbeitung.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 30 Tokens/Sekunde
- **Verbrauch** : 8,87 kWh/Million Tokens
- **Lizenz** : [LLAMA 3.3 Community Lizenz](./licences/llama3.3_70b.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Agent` `Dialog` `Mehrsprachig`

**Anwendungsf√§lle:**
- Mehrsprachige Chatbots, die 8 Sprachen gleichzeitig unterst√ºtzen
- Ausf√ºhrung komplexer, verkn√ºpfter Anweisungen (Prompt Chaining)
- Verarbeitung eines Dialogfensters mit 60K Tokens f√ºr Konversationshistorien
- Analyse umfangreicher juristischer oder technischer Dokumente (>100 Seiten)
- Generierung strukturierter Texte mit Genauigkeit bei Stilvorgaben

---

### Qwen3 235B
**Qwen Team ‚Ä¢ 235B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Neuestes, sehr gro√ües Qwen3-Modell mit erweiterten F√§higkeiten f√ºr komplexe Aufgaben.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 21 Tokens/Sekunde
- **Verbrauch** : 6,35 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Agent` `Denken` `Mehrsprachig` `Sehr gro√ü`

**Anwendungsf√§lle:**
- Sehr fortgeschrittene conversationelle Agenten mit gro√üem Kontext und Werkzeugintegration (MCP)
- L√∂sung extrem komplexer Probleme (Mathematik, Code)
- Analyse und Generierung sehr umfangreicher und technischer Dokumente
- Multisprachige Anwendungen (>100 Sprachen), die eine hochgenaue Verst√§ndnis- und Generierungsf√§higkeit erfordern

---

### DeepSeek-R1 671B
**DeepSeek AI ‚Ä¢ 671B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Extrem gro√ües Modell von DeepSeek AI, optimiert f√ºr maximale Denk- und Generierungsf√§higkeiten.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 16 Tokens/Sekunde
- **Verbrauch** : 8,33 kWh/Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/deepseek-r1_671b.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Denken` `Extrem gro√ü`

**Anwendungsf√§lle:**
- Spitzenleistungen im Denken
- Generierung von Text mit Premium-Qualit√§t
- Forschung und Entwicklung in der KI

---

### Gemma 3 27B
**Google ‚Ä¢ 27B Parameter ‚Ä¢ Kontext: 120.000 Tokens**

Revolution√§res Google-Modell mit optimaler Balance zwischen Leistung und Effizienz, mit einem au√üergew√∂hnlichen Leistungs-Kosten-Verh√§ltnis f√ºr anspruchsvolle professionelle Anwendungen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 68 Tokens/Sekunde ‚ö°
- **Verbrauch** : 3,91 kWh/Million Tokens
- **Lizenz** : [Google Gemma Nutzungsbedingungen](./licences/gemma3_27b.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Vision` `Agent` `Schnell` `Gro√üer Kontext`

**Anwendungsf√§lle:**
- Dokumentenanalyse mit erweitertem Kontext bis zu 120K Tokens (ca. 400 Seiten)
- Semantische Suche in umfangreichen Dokumentenbanken
- gleichzeitige Verarbeitung von Bildern und Texten dank multimodaler F√§higkeiten
- Strukturierte Datenextraktion aus PDFs und gescannten Dokumenten
- Integration mit externen Tools √ºber die Funktionen-API

---

### Qwen3 30B-A3B FP8
**Qwen Team ‚Ä¢ 30B-A3B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Neuestes MoE FP8-Modell (3B aktiviert) mit hybriden Denkmodi und erweiterten Agentenf√§higkeiten.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 103 Tokens/Sekunde ‚ö°
- **Verbrauch** : 2,58 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `MoE` `Agent` `Denken` `Schnell` `Mehrsprachig`

**Anwendungsf√§lle:**
- Fortgeschrittene conversationelle Agenten mit Werkzeugintegration (MCP)
- L√∂sung komplexer Probleme (Mathematik, Code) mit "Denk"-Modus
- Multisprachige Anwendungen (>100 Sprachen)
- Szenarien, die ein Kosten-Leistungs-Verh√§ltnis (MoE) auf VLLM erfordern
- Engagierte Mehr-Runden-Dialoge mit pr√§ziser Anweisungsverfolgung

---

### DeepSeek-R1 70B
**DeepSeek AI ‚Ä¢ 70B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

70B-Modell von DeepSeek AI

**Technische Spezifikationen:**
- **Geschwindigkeit** : 20 Tokens/Sekunde
- **Verbrauch** : 11,44 kWh/Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/deepseek-r1_70b.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Denken` `Gro√ü`

**Anwendungsf√§lle:**
- Komplexe Denkaufgaben
- Hochwertige Textgenerierung
- Tiefgehende Dokumentenanalyse (innerhalb des Kontexts von 27k)

---

## Spezialisierte Modelle

### Qwen3 14B
**Qwen Team ‚Ä¢ 14B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Neuestes dichtes Qwen3-Modell (14B) mit Leistungen, die denen von Qwen2.5 32B entsprechen, aber mit besserer Effizienz.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 69 Tokens/Sekunde ‚ö°
- **Verbrauch** : 2,65 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Agent` `Denken` `Schnell` `Mehrsprachig`

**Anwendungsf√§lle:**
- Allgemeine Aufgaben mit Leistung und gro√üem Kontext
- Kreative und technische Inhaltsgenerierung
- Datenanalyse und komplexes Denken
- Integration mit externen Tools √ºber Funktionenaufrufe

---

### Gemma 3 12B
**Google ‚Ä¢ 12B Parameter ‚Ä¢ Kontext: 120.000 Tokens**

Mittleres Modell der Gemma 3-Reihe mit hervorragendem Gleichgewicht zwischen Leistung und Effizienz.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 67 Tokens/Sekunde ‚ö°
- **Verbrauch** : 2,73 kWh/Million Tokens
- **Lizenz** : [Google Gemma Nutzungsbedingungen](./licences/gemma3_12b.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Vision` `Schnell` `Gro√üer Kontext`

**Anwendungsf√§lle:**
- Multimodale Anwendungen mit moderaten Ressourcenanforderungen
- Dokumentenverarbeitung mit Standard-Kontext (bis zu 100 Seiten)
- Kombinierte Textgenerierung und Bildanalyse
- Deployment auf Standard-GPUs ohne spezialisierte Infrastruktur
- Fortschrittliche Chatbots mit integrierten visuellen und textuellen F√§higkeiten

---

### Gemma 3 4B
**Google ‚Ä¢ 4B Parameter ‚Ä¢ Kontext: 120.000 Tokens**

Kompaktes Google-Modell mit hervorragenden Leistungen in einem leichtgewichtigen und wirtschaftlichen Format.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 58 Tokens/Sekunde ‚ö°
- **Verbrauch** : 0,93 kWh/Million Tokens üå±
- **Lizenz** : [Google Gemma Nutzungsbedingungen](./licences/gemma3_4b.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Vision` `Schnell` `Kompakt` `Gro√üer Kontext` `Effizient`

**Anwendungsf√§lle:**
- Eingebettete Anwendungen und Edge Computing mit Bildverarbeitung
- Reaktive multimodale Chatbots mit geringer Latenz
- Skalierbare Deployment mit visuellen und textuellen F√§higkeiten
- Mobile Anwendungen mit Bild- und Textanalyse
- Verarbeitung einfacher bis mittelkomplexer visueller Anfragen mit hoher Leistung

---

### Gemma 3 1B
**Google ‚Ä¢ 1B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Ultra-leichtes Mikromodell f√ºr Deployment auf Ger√§ten mit sehr geringen Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 41 Tokens/Sekunde
- **Verbrauch** : 1,32 kWh/Million Tokens üå±
- **Lizenz** : [Google Gemma Nutzungsbedingungen](./licences/gemma3_1b.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Ultra-kompakt` `Eingebettet` `Effizient`

**Anwendungsf√§lle:**
- Deployment auf IoT-Ger√§ten und eingebetteten Systemen mit API-Integration
- Anwendungen, die lokale Inferenz auf CPUs mit Funktionsaufrufen erfordern
- Grundlegende Textaufgaben mit sofortiger Antwortzeit und Funktionsaufrufen
- Kompakte Assistenten f√ºr Endverbraucher-Anwendungen mit Integration externer Dienste
- Intelligente Steuersysteme mit mehreren APIs/Services

---

### Lucie-7B-Instruct
**OpenLLM-France ‚Ä¢ 7B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Open-Source-Kausal-Mehrsprachmodell (7B), auf Lucie-7B fine-tuned. Optimiert f√ºr Franz√∂sisch.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 41 Tokens/Sekunde
- **Verbrauch** : 1,32 kWh/Million Tokens üå±
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort**: FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Franz√∂sisch` `Open-Source` `Effizient`

---

### Mistral Small 3.1
**Mistral AI ‚Ä¢ 24B Parameter ‚Ä¢ Kontext: 60.000 Tokens**

Kompakter und reaktiver Modell von Mistral AI, speziell f√ºr eine fl√ºssige und relevante konversationale Unterst√ºtzung mit optimaler Antwortgeschwindigkeit entwickelt.

**Technische Spezifikationen:**
- **Geschwindigkeit**: 14 Tokens pro Sekunde Tokens pro Sekunde
- **Verbrauch**: 13,06 kWh pro Million Tokens
- **Lizenz**: [Apache 2.0](./licences/apache2.licence.md)
- **Standort**: FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit

**Tags:** `Vision` `Agent` `Sicherheit`

**Anwendungsf√§lle:**
- Konversationale Anwendungen
- Virtuelle Assistenten mit Bild- und Textanalyse (26 Tokens/s)
- Technische Support-Chatbots mit Zugriff auf technische Dokumentation
- Inhalts-Create/Edit-Tools mit sofortiger Antwort (Blogs, E-Mails)
- Deployment auf Standard-Infrastrukturen (24B Parameter)

---

### DeepCoder
**Agentica x Together AI ‚Ä¢ 14B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Open-Source-IA-Modell (14B) von Together AI & Agentica, eine glaubw√ºrdige Alternative zu propriet√§ren Modellen f√ºr Code-Generierung.

**Technische Spezifikationen:**
- **Geschwindigkeit**: 62 Tokens pro Sekunde Tokens pro Sekunde ‚ö°
- **Verbrauch**: 2,95 kWh pro Million Tokens
- **Lizenz**: [Apache 2.0](./licences/apache2.licence.md)
- **Standort**: FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Programmierung` `Reasoning` `Open-Source` `Mathematik` `Schnell`

**Anwendungsf√§lle:**
- Code-Generierung in mehr als 15 Sprachen mit Leistungs-Optimierung
- Debugging und Refactoring bestehender Code-Basen mit Impact-Analyse
- Implementierung komplexer Algorithmen (Graphen, B√§ume, Heuristiken)
- Code-√úbersetzung zwischen Sprachen und Frameworks (z. B. Python zu JavaScript)
- Automatisierte Erstellung von Unit-Tests mit Code-Coverage > 80%

---

### Granite 3.2 Vision
**IBM ‚Ä¢ 2B Parameter ‚Ä¢ Kontext: 16.384 Tokens**

Revolution√§rer kompakter Modell von IBM, spezialisiert auf Computer Vision, in der Lage, direkt visuelle Dokumente zu analysieren und zu verstehen, ohne Zwischen-OCR-Technologien zu verwenden.

**Technische Spezifikationen:**
- **Geschwindigkeit**: 48 Tokens pro Sekunde Tokens pro Sekunde ‚ö°
- **Verbrauch**: 1,13 kWh pro Million Tokens üå±
- **Lizenz**: [Apache 2.0](./licences/apache2.licence.md)
- **Standort**: FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit

**Tags:** `Vision` `Sicherheit` `Schnell` `Kompakt` `Effizient`

**Anwendungsf√§lle:**
- Strukturierte Datenextraktion aus Rechnungen und Formularen ohne OCR
- Direkte Analyse von Tabellen und Grafiken mit Trend-Interpretation
- Lesen und Interpretieren technischer Diagramme (elektrisch, mechanisch)
- Verarbeitung von Handschriften mit hohem Erkennungsraten
- Leichte Computer Vision (2B Parameter) mit hoher Geschwindigkeit (79 Tokens/s)

---

### Granite 3.3 8B
**IBM ‚Ä¢ 8B Parameter ‚Ä¢ Kontext: 60.000 Tokens**

Granite 8B-Modell, feinabgestimmt von IBM f√ºr verbessertes Reasoning und Instruction-Following mit einem Kontext von 128k Tokens.

**Technische Spezifikationen:**
- **Geschwindigkeit**: 27 Tokens pro Sekunde Tokens pro Sekunde
- **Verbrauch**: 2,0 kWh pro Million Tokens üå±
- **Lizenz**: [Apache 2.0](./licences/apache2.licence.md)
- **Standort**: FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚úÖ Sicherheit

**Tags:** `Agent` `Reasoning` `Sicherheit` `Effizient`

**Anwendungsf√§lle:**
- Allgemeine Instruction-Following-Aufgaben (Klassifizierung, Extraktion, Q&A)
- Multilinguale IA-Assistenten (12 Sprachen)
- Verarbeitung sehr langer Dokumente (128k Tokens): Zusammenfassungen und Q&A
- Code-Generierung/Completions mit Fill-in-the-Middle
- Integration mit externen Tools √ºber Function Calling
- Strukturiertes Reasoning mit "Thinking"-Modus

---

### Granite 3.3 2B
**IBM ‚Ä¢ 2B Parameter ‚Ä¢ Kontext: 120.000 Tokens**

Granite 2B-Modell, feinabgestimmt von IBM, optimiert f√ºr Reasoning und Instruction-Following mit einem Kontext von 128k Tokens.

**Technische Spezifikationen:**
- **Geschwindigkeit**: 45 Tokens pro Sekunde Tokens pro Sekunde ‚ö°
- **Verbrauch**: 1,2 kWh pro Million Tokens üå±
- **Lizenz**: [Apache 2.0](./licences/apache2.licence.md)
- **Standort**: FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚úÖ Sicherheit

**Tags:** `Agent` `Reasoning` `Sicherheit` `Schnell` `Effizient`

**Anwendungsf√§lle:**
- Leichte Deployment mit gro√üem Kontext (128k Tokens)
- Allgemeine Instruction-Following-Aufgaben auf begrenzten Ressourcen
- Kompakte multilinguale IA-Assistenten
- Verarbeitung langer Dokumente auf weniger leistungsstarken Ger√§ten
- FIM-Code-Generierung/Completions auf Standard-Workstations

---

### Granite 3.1 MoE
**IBM ‚Ä¢ 3B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Innovatives IBM-Modell mit Mixture-of-Experts (MoE)-Architektur, das au√üergew√∂hnliche Leistungen bietet und gleichzeitig die Berechnungsressourcen stark optimiert.

**Technische Spezifikationen:**
- **Geschwindigkeit**: 74 Tokens pro Sekunde Tokens pro Sekunde ‚ö°
- **Verbrauch**: 0,73 kWh pro Million Tokens üå±
- **Lizenz**: [Apache 2.0](./licences/apache2.licence.md)
- **Standort**: FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit

**Tags:** `Agent` `Sicherheit` `Schnell` `MoE` `Effizienz` `Effizient`

**Anwendungsf√§lle:**
- Allgemeine Anwendungen mit optimiertem Inferenz-Kosten (42 Tokens/s)
- Dokumentenverarbeitung in CPU-Umgebungen mit begrenztem RAM
- Spezialisierte Analysen mit dynamischer Aktivierung relevanter Modellteile
- Hochdichte-Deployment mit geringem Energieverbrauch pro Inferenz
- Parallele Verarbeitung mehrerer Anfragentypen mit MoE-Spezialisierung

---

### Cogito 14B
**Deep Cogito ‚Ä¢ 14B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Deep Cogito-Modell, speziell f√ºr tiefes Reasoning und nuancierte Kontextverstehen optimiert, ideal f√ºr anspruchsvolle analytische Anwendungen.

**Technische Spezifikationen:**
- **Geschwindigkeit**: 60 Tokens pro Sekunde Tokens pro Sekunde ‚ö°
- **Verbrauch**: 3,05 kWh pro Million Tokens
- **Lizenz**: [Apache 2.0](./licences/apache2.licence.md)
- **Standort**: FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Agent` `Reasoning` `Verstehen` `Analyse` `Schnell`

**Anwendungsf√§lle:**
- Semantische Textanalyse mit Identifizierung impliziter Implikationen
- Strukturiertes kausales Reasoning mit Identifizierung von Ursache-Wirkungs-Beziehungen
- Synthese komplexer Dokumente mit Extraktion von Schl√ºsselinformationen
- Pr√§zise Q&A-Systeme auf spezialisierten Dokumentenkorpus
- Argumentationsanalyse mit Bewertung der St√§rke der Reasoning

---

### Cogito 32B
**Deep Cogito ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Erweiterte Version des Cogito-Modells mit erheblich verst√§rkten Reasoning- und Analysef√§higkeiten, konzipiert f√ºr die anspruchsvollsten Anwendungen im Bereich analytischer KI.

**Technische Spezifikationen:**
- **Geschwindigkeit**: 32 Tokens pro Sekunde Tokens pro Sekunde
- **Verbrauch**: 5,73 kWh pro Million Tokens
- **Lizenz**: [Apache 2.0](./licences/apache2.licence.md)
- **Standort**: FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Agent` `Reasoning` `Verstehen` `Analyse`

**Anwendungsf√§lle:**
- Multi-Faktor-Szenario-Analyse mit probabilistischer Ergebnisbewertung
- L√∂sung wissenschaftlicher Probleme mit formaler Schritt-Demonstration
- Hochkritische Anwendungen, die Genauigkeit und Verifizierbarkeit der Ergebnisse erfordern
- Expertensysteme in spezialisierten Bereichen (juristisch, medizinisch, technisch)
- Mehrstufiges Reasoning mit vollst√§ndiger Erkl√§rbarkeit der Schlussfolgerungen

---

### Qwen3 32B
**Qwen Team ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 40.000 Tokens**

Leistungsstarker Modell der neuen Qwen3-Generation mit erweiterten F√§higkeiten im Reasoning, Code und Agenten.

**Technische Spezifikationen:**
- **Lizenz**: [Apache 2.0](./licences/apache2.licence.md)
- **Standort**: FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Agent` `Reasoning` `Mehrsprachig` `Gro√üer Kontext`

**Anwendungsf√§lle:**
- Fortschrittliche conversationale Agenten mit gro√üem Kontext und Werkzeug-Integration (MCP)
- L√∂sung komplexer Probleme (Mathematik, Code) mit "Thinking"-Modus
- Analyse und Generierung von umfangreichen Dokumenten
- Mehrsprachige Anwendungen (>100 Sprachen) mit tiefem Verst√§ndnis

---

### QwQ-32B
**Qwen Team ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

32-Billionen-Parameter-Modell, verbessert durch Reinforcement Learning (RL), um im Reasoning, Codieren, Mathematik und Agenten-Aufgaben zu gl√§nzen.

**Technische Spezifikationen:**
- **Geschwindigkeit**: 35 Tokens pro Sekunde Tokens pro Sekunde
- **Verbrauch**: 5,22 kWh pro Million Tokens
- **Lizenz**: [Apache 2.0](./licences/apache2.licence.md)
- **Standort**: FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Agent` `Reasoning` `Codierung` `Mathematik`

**Anwendungsf√§lle:**
- L√∂sung komplexer Probleme, die Reasoning und Werkzeugnutzung erfordern
- Generierung und Ausf√ºhrung von Code mit Ergebnis-√úberpr√ºfung
- Fortschrittliche mathematische Aufgaben mit Genauigkeits-√úberpr√ºfung
- Agenten-Anwendungen, die mit der Umgebung interagieren k√∂nnen
- Verbessertes Instruction Following und Ausrichtung auf menschliche Pr√§ferenzen

---

### DeepSeek-R1 14B
**DeepSeek AI ‚Ä¢ 14B Parameter ‚Ä¢ Kontext: 32.000 Tokens**
Kompakte und effiziente Version des DeepSeek-R1-Modells, die ein hervorragendes Verh√§ltnis zwischen Leistung und Leichtigkeit bietet, ideal f√ºr Deployment-Szenarien, die Flexibilit√§t und Reaktionsf√§higkeit erfordern.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 60 Tokens pro Sekunde ‚ö°
- **Verbrauch** : 3,05 kWh pro Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/deepseek-r1_14b.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Agent` `Denken` `Kompakt` `Vielseitig` `Schnell`

**Anwendungsf√§lle:**
- Allgemeine Anwendungen mit Bedarf an schneller Inferenz (44 Tokens/s)
- Deployment auf Standard-Servern ohne spezialisierte GPU (14B Parameter)
- Textverarbeitung mit kontextueller Analyse und Antwortzeit < 2s
- Deployment im Edge Computing mit optimierter lokaler Inferenz
- Schnelle Prototypentwicklung von KI-Anwendungen mit kurzer Iterationszeit

---

### DeepSeek-R1 32B
**DeepSeek AI ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Zwischenversion des DeepSeek-R1-Modells, die ein strategisches Gleichgewicht zwischen den fortgeschrittenen F√§higkeiten der 70B-Version und der Effizienz der 14B-Version bietet, f√ºr maximale Vielseitigkeit und Leistung.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 33 Tokens pro Sekunde
- **Verbrauch** : 5,54 kWh pro Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/deepseek-r1_32b.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Agent` `Denken` `Vielseitig`

**Anwendungsf√§lle:**
- Anwendungen, die ein gutes Verh√§ltnis zwischen Leistung und Kosten ben√∂tigen (32B Parameter)
- Professionelle Textverarbeitung mit Analyse der semantischen Feinheiten
- Automatisierte Generierung strukturierter Berichte aus Rohdaten
- Anwendungen, die Datenanalyse und Inhaltsgenerierung kombinieren
- Spezialisierte Assistenten f√ºr technische Branchen (rechtlich, medizinisch, technisch)

---

### Cogito 3B
**Deep Cogito ‚Ä¢ 3B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Kompakte Version des Cogito-Modells, optimiert f√ºr das Denken auf Ger√§ten mit begrenzten Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 63 Tokens pro Sekunde ‚ö°
- **Verbrauch** : 0,86 kWh pro Million Tokens üå±
- **Lizenz** : [LLAMA 3.2 Community Lizenz](./licences/cogito_3b.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Denken` `Kompakt` `Eingebettet` `Effizient` `Schnell`

---

### Granite Embedding
**IBM ‚Ä¢ 278M Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Ultra-leichtes Embedding-Modell von IBM f√ºr semantische Suche und Klassifizierung.

**Technische Spezifikationen:**
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Embedding` `Kompakt` `Semantisch` `Effizient`

---

### Granite 3 Guardian 2B
**IBM ‚Ä¢ 2B Parameter ‚Ä¢ Kontext: 8.192 Tokens**

Kompaktes IBM-Modell, spezialisiert auf Sicherheit und Compliance, das Risiken und unangemessene Inhalte erkennt.

**Technische Spezifikationen:**
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚úÖ Sicherheit

**Tags:** `Sicherheit` `Compliance` `Kompakt` `Filterung` `Effizient`

---

### Granite 3 Guardian 8B
**IBM ‚Ä¢ 8B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

IBM-Modell, spezialisiert auf Sicherheit und Compliance, mit erweiterten F√§higkeiten zur Risikodetektion.

**Technische Spezifikationen:**
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚úÖ Sicherheit

**Tags:** `Sicherheit` `Compliance` `Filterung`

---

### Qwen 2.5 0.5B
**Qwen Team ‚Ä¢ 0.5B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Ultra-leichtes Mikro-Modell der Qwen 2.5-Familie, optimiert f√ºr maximale Effizienz auf eingeschr√§nkten Ger√§ten.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 57 Tokens pro Sekunde ‚ö°
- **Verbrauch** : 0,95 kWh pro Million Tokens üå±
- **Lizenz** : [MIT Lizenz](./licences/qwen2.5_0.5b.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Ultra-kompakt` `Schnell` `Eingebettet` `Effizient`

---

### Qwen 2.5 1.5B
**Qwen Team ‚Ä¢ 1.5B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Sehr kompaktes Modell der Qwen 2.5-Familie, das ein gutes Verh√§ltnis zwischen Leistung und Gr√∂√üe f√ºr leichte Deployment-Szenarien bietet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 94 Tokens pro Sekunde ‚ö°
- **Verbrauch** : 0,58 kWh pro Million Tokens üå±
- **Lizenz** : [MIT Lizenz](./licences/qwen2.5_1.5b.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Kompakt` `Schnell` `Eingebettet` `Effizient`

---

### Qwen 2.5 14B
**Qwen Team ‚Ä¢ 14B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Mittleres, vielseitiges Modell der Qwen 2.5-Familie mit einem guten Gleichgewicht aus Leistung und Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 61 Tokens pro Sekunde ‚ö°
- **Verbrauch** : 3,0 kWh pro Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/qwen2.5_14b.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Vielseitig` `Mehrsprachig` `Schnell`

---

### Qwen 2.5 32B
**Qwen Team ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Leistungsstarkes Modell der Qwen 2.5-Familie mit erweiterten F√§higkeiten in Verst√§ndnis und Generierung.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 32 Tokens pro Sekunde
- **Verbrauch** : 5,73 kWh pro Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/qwen2.5_32b.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Vielseitig` `Mehrsprachig` `Denken`

---

### Qwen 2.5 3B
**Qwen Team ‚Ä¢ 3B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Kompaktes und effizientes Modell der Qwen 2.5-Familie, geeignet f√ºr allgemeine Aufgaben auf begrenzten Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 60 Tokens pro Sekunde ‚ö°
- **Verbrauch** : 0,9 kWh pro Million Tokens üå±
- **Lizenz** : [MIT Lizenz](./licences/qwen2.5_3b.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Kompakt` `Schnell` `Vielseitig` `Effizient`

---

### Qwen3 0.6b
**Qwen Team ‚Ä¢ 0.6B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Kompaktes und effizientes Modell der Qwen3-Familie, geeignet f√ºr allgemeine Aufgaben auf begrenzten Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 60 Tokens pro Sekunde ‚ö°
- **Verbrauch** : 0,9 kWh pro Million Tokens üå±
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Kompakt` `Schnell` `Vielseitig` `Effizient`

---

### Qwen3 1.7b
**Qwen Team ‚Ä¢ 1.7B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Sehr kompaktes Modell der Qwen3-Familie, das ein gutes Verh√§ltnis zwischen Leistung und Gr√∂√üe f√ºr leichte Deployment-Szenarien bietet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 83 Tokens pro Sekunde ‚ö°
- **Verbrauch** : 0,65 kWh pro Million Tokens üå±
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Kompakt` `Schnell` `Eingebettet` `Effizient`

---

### Qwen3 4b
**Qwen Team ‚Ä¢ 4B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Kompaktes Modell der Qwen3-Familie mit hervorragenden Leistungen in einem leichtgewichtigen und wirtschaftlichen Format.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 48 Tokens pro Sekunde
- **Verbrauch** : 1,13 kWh pro Million Tokens üå±
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Kompakt` `Effizient`

---

### Qwen3 8b
**Qwen Team ‚Ä¢ 8B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Qwen3 8B-Modell mit einem guten Gleichgewicht zwischen Leistung und Effizienz f√ºr allgemeine Aufgaben.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 29 Tokens pro Sekunde
- **Verbrauch** : 1,87 kWh pro Million Tokens üå±
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Denken` `Agent` `Mehrsprachig` `Effizient`

---

### Qwen2.5-VL 3B
**Qwen Team ‚Ä¢ 3,8B Parameter ‚Ä¢ Kontext: 128.000 Tokens**

Kompaktes Vision-Langage-Modell, leistungsstarker L√∂sung f√ºr Edge AI (Edge-Computing).

**Technische Spezifikationen:**
- **Geschwindigkeit** : 65 Tokens pro Sekunde ‚ö°
- **Verbrauch** : 0,83 kWh pro Million Tokens üå±
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚úÖ Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Vision` `Agent` `Denken` `Schnell` `Effizient` `OCR` `Visuelle Lokalisierung` `Edge AI`

---

### Qwen2.5-VL 7B
**Qwen Team ‚Ä¢ 7B (8,3B) Parameter ‚Ä¢ Kontext: 128.000 Tokens**

Leistungsstarkes Vision-Langage-Modell, das GPT-4o-mini in bestimmten Aufgaben √ºbertrifft.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 37 Tokens pro Sekunde
- **Verbrauch** : 1,46 kWh pro Million Tokens üå±
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚úÖ Denken ‚Ä¢ ‚ùå Sicherheit

**Tags:** `Vision` `Agent` `Denken` `Effizient` `OCR` `Visuelle Lokalisierung`

---

### Foundation-Sec-8B
**Foundation AI ‚Äî Cisco ‚Ä¢ 8B Parameter ‚Ä¢ Kontext: 16.000 Tokens**

Sprachmodell spezialisiert auf Cybersicherheit, optimiert f√ºr Effizienz.
- **Geschwindigkeit** : 22 Tokens/Sekunde Tokens/Sekunde
- **Verbrauch** : 2,46 kWh/pro 1 Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten :**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚úÖ Sicherheit

**Tags :** `Sicherheit` `Kompakt`

---

### devstral 24B
**Mistral AI & All Hands AI ‚Ä¢ 24B Parameter ‚Ä¢ Kontext: 120.000 Tokens**

Devstral ist ein LLM-Agent f√ºr Software-Engineering-Aufgaben.

**Technische Spezifikationen :**
- **Geschwindigkeit** : 53 Tokens/Sekunde Tokens/Sekunde ‚ö°
- **Verbrauch** : 4,5 kWh/pro 1 Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache2.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten :**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit

**Tags :** `Agent` `Programmierung` `Open-Source` `Gro√üer Kontext`

**Anwendungsf√§lle :**
- Code-Basen erkunden und modifizieren
- Agenten-basiert
- Europ√§isch

---

## Empfohlene Anwendungsf√§lle

### Mehrsprachige Gespr√§che

Chatbots und Assistenten, die in mehreren Sprachen kommunizieren k√∂nnen mit automatischer Erkennung, Kontexterhaltung √ºber die gesamte Unterhaltung und Verst√§ndnis sprachlicher Besonderheiten

**Empfohlene Modelle :**

- Llama 3.3
- Mistral Small 3.1
- Qwen 2.5
- Granite 3.3

### Analyse von langen Dokumenten

Verarbeitung umfangreicher Dokumente (>100 Seiten) mit Kontexterhaltung √ºber den gesamten Text, Extraktion von Schl√ºsselinformationen, Generierung relevanter Zusammenfassungen und Beantwortung spezifischer Fragen zum Inhalt

**Empfohlene Modelle :**

- Gemma 3
- DeepSeek-R1
- Granite 3.3

### Programmierung und Entwicklung
Codegenerierung und -optimierung in mehreren Sprachen, Debugging, Refactoring, Entwicklung vollst√§ndiger Funktionen, Verst√§ndnis komplexer algorithmischer Implementierungen und Erstellung von Einheitstests

**Empfohlene Modelle :**

- DeepCoder
- QwQ
- DeepSeek-R1
- Granite 3.3
- Devstral

### Visuelle Analyse

Direkter Umgang mit Bildern und visuellen Dokumenten ohne OCR-Vorverarbeitung, Interpretation technischer Diagramme, Grafiken, Tabellen, Zeichnungen und Fotos mit Generierung detaillierter textueller Erkl√§rungen des visuellen Inhalts

**Empfohlene Modelle :**

- Granite 3.2 Vision
- Mistral Small 3.1
- Gemma 3
- Qwen2.5-VL

### Sicherheit und Compliance

Anwendungen, die spezifische Sicherheitsfunktionen erfordern; Inhaltsfilterung, Nachvollziehbarkeit der Schlussfolgerungen, RGPD/HDS-Pr√ºfung, Risikominimierung, Schwachstellenanalyse und Einhaltung branchenspezifischer Vorschriften

**Empfohlene Modelle :**

- Granite Guardian
- Granite 3.3
- Devstral
- Mistral Small 3.1
- Foundation-Sec-8B

### Leichte und eingebettete Deployment

Anwendungen, die eine minimale Ressourcennutzung erfordern, Deployment auf Ger√§ten mit begrenzter Kapazit√§t, Echtzeit-Inferenz auf Standard-CPU und Integration in eingebettete oder IoT-Systeme

**Empfohlene Modelle :**

- Gemma 3
- Granite 3.1 MoE
- Granite Guardian
- Granite 3.3