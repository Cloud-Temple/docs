

---
title: Katalog der LLMaaS-Modelle
sidebar_position: 2
---



# Katalog der LLM-Modelle as a Service



## Überblick

Cloud Temple LLMaaS bietet **51 sorgfältig ausgewählte und optimierte große Sprachmodelle**, die den strengsten Anforderungen von **SecNumCloud** entsprechen. Unser Katalog umfasst das gesamte Spektrum, von ultra-effizienten Mikro-Modellen bis hin zu extrem großen Modellen.



### Globale Statistiken

| Metrik | Wert |
|--------|------|
| **Gesamtanzahl der Modelle** | 51 Modelle |
| **Minimales Kontext** | 8 192 Tokens |
| **Maximales Kontext** | 262 144 Tokens |
| **Konformität** | SecNumCloud ✅ HDS ✅ Souveränität ✅ C5 ❌ |
| **Standort** | 100% Frankreich 🇫🇷 |



### Preisgestaltung

| Verwendungstyp | Preis |
|-------------------|------|
| **Eingabetokens** | 0.9€ / Million Tokens |
| **Ausgabetokens** | 4€ / Million Tokens |
| **Erweitertes Reasoning** | 21€ / Million Tokens |



## Modelle großer Größe



### gpt-oss:120b
**OpenAI • 120B Parameter • Kontext: 120.000 Tokens**

Open-Weight-Modell der Spitzenklasse von OpenAI mit starken Leistungen und einer flexiblen Apache 2.0-Lizenz.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 38 Tokens pro Sekunde
- **Verbrauch** : 3,51 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit

**Tags:** `MoE` `Agent` `Reasoning` `Open-Source` `Sehr groß`

**Anwendungsfälle:**
- Fortgeschrittene conversationelle Agenten mit komplexem Reasoning und Tool-Integration.
- Anwendungen, die eine vollständige Transparenz des Reasoning-Prozesses (Kette des Denkens) erfordern.
- Geschäftsszenarien, die eine flexible Lizenz (Apache 2.0) benötigen.
- Fine-Tuning für spezialisierte Aufgaben, die ein leistungsstarkes Grundmodell erfordern.



### llama3.3:70b
**Meta • 70B Parameter • Kontext: 120.000 Tokens**

Fortgeschrittenes Mehrsprachmodell von Meta, das für natürliche Gespräche, komplexes Denken und feine Verständnis von Anweisungen optimiert ist.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 15 Tokens pro Sekunde
- **Verbrauch** : 8,89 kWh pro Million Tokens
- **Lizenz** : LLAMA 3.3 Community Lizenz
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ❌ Begründung • ❌ Sicherheit

**Tags:** `Agent` `Dialog` `Mehrsprachig`

**Anwendungsfälle:**
- Mehrsprachige Chatbots, die 8 Sprachen gleichzeitig unterstützen
- Ausführung komplexer, verketteter Anweisungen (Prompt Chaining)
- Verarbeitung eines Dialogfensters mit 60.000 Tokens für Conversationsverläufe
- Analyse umfangreicher juristischer oder technischer Dokumente (>100 Seiten)
- Erstellung strukturierter Texte mit Treue zu stilistischen Anweisungen



### qwen3:235b
**Qwen Team • 235B Parameter • Kontext: 60.000 Token**

Ein sehr großes Modell der neuen Qwen3-Generation mit erweiterten Fähigkeiten für komplexe Aufgaben.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 17 Token pro Sekunde ⚡
- **Verbrauch:** 7,84 kWh pro Million Token
- **Lizenz:** Apache 2.0
- **Standort:** FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Begründung • ❌ Sicherheit

**Tags:** `Agent` `Begründung` `Mehrsprachig` `Sehr groß`

**Anwendungsfälle:**
- Sehr fortgeschrittene conversationelle Agenten mit großem Kontext und Integration von Tools (MCP)
- Lösung extrem komplexer Probleme (Mathematik, Code)
- Analyse und Generierung sehr umfangreicher und technischer Dokumente
- Mehrsprachige Anwendungen (>100 Sprachen), die eine sehr hohe Genauigkeit bei Verständnis und Generierung erfordern



### deepseek-r1:671b
**DeepSeek AI • 671B Parameter • Kontext: 16.000 Tokens**

Äußerst großes Modell von DeepSeek AI, entwickelt für den Höhenpunkt des Denkens und der Generierung.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 12 Tokens pro Sekunde
- **Verbrauch** : 11,11 kWh pro Million Tokens
- **Lizenz** : MIT Lizenz
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ✅ Denken • ❌ Sicherheit

**Tags:** `Denken` `Außergewöhnlich groß`

**Anwendungsfälle:**
- Höchstleistungsdenkaufgaben
- Hochwertige Textgenerierung
- AI-Forschung und -entwicklung

---



### gemma3:27b  
**Google • 27B Parameter • Kontext: 120.000 Tokens**  

Revolutionäres Modell von Google, das ein optimales Gleichgewicht zwischen Leistung und Effizienz bietet und ein außergewöhnliches Leistungs-Kosten-Verhältnis für anspruchsvolle professionelle Anwendungen aufweist.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 20 Tokens/Sekunde Tokens/Sekunde  
- **Verbrauch** : 6,67 kWh pro Million Tokens  
- **Lizenz** : Google Gemma Nutzungsbedingungen  
- **Standort** : FR 🇫🇷  

**Fähigkeiten:**  
✅ Tools/Agent • ✅ Vision • ❌ Denken • ❌ Sicherheit  

**Tags:** `Vision` `Agent` `Großer Kontext`  

**Anwendungsfälle:**  
- Dokumentanalyse mit erweitertem Kontext bis zu 120.000 Tokens (ca. 400 Seiten)  
- Semantische Indexierung und Suche in umfangreichen Dokumentenbanken  
- Bild- und Textverarbeitung gleichzeitig dank multimodaler Fähigkeiten  
- Strukturierte Datenextraktion aus PDFs und gescannten Dokumenten  
- Integration mit externen Tools über die API-Funktionaufruf



### qwen3-coder:30b
**Qwen Team • 30B Parameter • Kontext: 250.000 Tokens**

MoE-Modell optimiert für Aufgaben der Softwareentwicklung mit sehr langer Kontextlänge.

**Technische Spezifikationen :**
- **Geschwindigkeit** : 80 Tokens/Sekunde ⚡
- **Verbrauch** : 3,3 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten :**
✅ Tools/Agent • ❌ Vision • ✅ Begründung • ❌ Sicherheit

**Tags :** `Agent` `Programmierung` `Großer Kontext` `MoE`

**Anwendungsfälle :**
- Softwareentwicklungs-Agenten zur Exploration und Änderung von Code-Basen
- Erstellung komplexer Code mit Verständnis auf Repository-Ebene
- Begründungsaufgaben mit erweiterten Kontexten
- Code-Verbesserung durch Verstärkungslernen



### qwen3-2507-think:30b-a3b
**Qwen Team • 30B Parameter • Kontext: 120.000 Tokens**

Erweitertes Modell der Qwen3-Familie, optimiert für tiefes Denken und erweiterte Kontexte.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 80 Tokens/Sekunde ⚡
- **Verbrauch** : 3,3 kWh/Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Denken • ❌ Sicherheit

**Tags:** `Agent` `Denken` `Großer Kontext`

**Anwendungsfälle:**
- Analyse von sehr umfangreichen Dokumenten mit komplexem Denken.
- Konversationelle Agenten mit erweitertem Gesprächsverlauf.
- Q&A-Aufgaben auf großen Textkorpus.
- Integration mit externen Tools über Function Calling auf großen Kontexten.



### qwen3-2507:30b-a3b
**Qwen Team • 30B Parameter • Kontext: 250.000 Tokens**

Verbesserte Version des Denkmodus von Qwen3-30B mit verbesserten allgemeinen Fähigkeiten, Wissensabdeckung und Benutzeranpassung.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 90 Tokens/Sekunde ⚡
- **Verbrauch:** 2,16 kWh pro Million Tokens
- **Lizenz:** Apache 2.0
- **Standort:** FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ❌ Begründung • ❌ Sicherheit

**Tags:** `Agent` `Großer Kontext` `MoE` `Mehrsprachig`

**Anwendungsfälle:**
- Komplexe Aufgaben, die präzises Anweisungsverfolgung und logisches Denken erfordern.
- Mehrsprachige Anwendungen mit umfassender Wissensabdeckung.
- Hochwertige Textgenerierung für offene und subjektive Aufgaben.
- Analyse sehr umfangreicher Dokumente dank des 250k-Token-Kontexts.



### qwen3:30b-a3b
**Qwen Team • 30B Parameter • Kontext: 32.000 Tokens**

Die neueste Generation der Qwen-Modelle mit signifikanten Verbesserungen in Bezug auf Trainingsdaten, Architektur und Optimierung.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 50 Tokens pro Sekunde
- **Verbrauch:** 3,89 kWh pro Million Tokens
- **Lizenz:** Apache 2.0
- **Standort:** FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Begründung • ❌ Sicherheit

**Tags:** `Agent` `Programmierung` `Mehrsprachig` `MoE`

**Anwendungsfälle:**
- Komplexe Begründungsaufgaben und Codegenerierung.
- Mehrsprachige Anwendungen, die eine breite sprachliche Abdeckung erfordern.
- Szenarien, die ein gutes Gleichgewicht zwischen Leistung und Ressourceneffizienz durch die MoE-Architektur erfordern.



### deepseek-r1:70b
**DeepSeek AI • 70B Parameter • Kontext: 32.000 Tokens**

70B-Modell von DeepSeek AI

**Technische Spezifikationen :**
- **Geschwindigkeit** : 21 Tokens pro Sekunde
- **Verbrauch** : 12,56 kWh pro Million Tokens
- **Lizenz** : MIT-Lizenz
- **Standort** : FR 🇫🇷

**Fähigkeiten :**
❌ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit

**Tags :** `Reasoning` `Large`

**Anwendungsfälle :**
- Spitzenleistungen im Reasoning
- Hochwertige Textgenerierung
- AI-Forschung und -entwicklung



### qwen2.5vl:32b
**Qwen Team • 32B Parameter • Kontext: 120.000 Tokens**

Die leistungsstärkste Version der Qwen2.5-VL-Serie mit fortschrittlicher visueller Verständnisfähigkeit und avantgardistischen Agenten.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 18 Tokens/Sekunde
- **Verbrauch** : 7,41 kWh/Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ✅ Vision • ❌ Reasoning • ❌ Sicherheit

**Tags:** `Vision` `Agent` `Reasoning` `OCR` `Visuelle Lokalisierung` `Large`

**Anwendungsfälle:**
- Analyse von sehr komplexen Dokumenten und Diagrammen
- Autonome visuelle Agenten für Navigation und Interaktion mit GUIs
- Objektlokalisierungsaufgaben und hochpräzise Texterkennung
- Erstellung reicher und detaillierter Beschreibungen aus komplexen Bildern



### qwen2.5vl:72b
**Qwen Team • 72B Parameter • Kontext: 128.000 Tokens**

Die leistungsstärkste Version der Qwen2.5-VL-Serie mit fortschrittlichen visuellen Verständnis- und Agentenfähigkeiten für die anspruchsvollsten Aufgaben.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 15 Tokens/Sekunde Tokens/Sekunde
- **Verbrauch:** 8,89 kWh pro Million Tokens
- **Lizenz:** Apache 2.0
- **Lokalisierung:** FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ✅ Vision • ✅ Reasoning • ❌ Sicherheit

**Tags:** `Vision` `Agent` `Reasoning` `OCR` `Visuelle Lokalisierung` `Sehr Groß`

**Anwendungsfälle:**
- Analyse von sehr komplexen Dokumenten und Diagrammen
- Autonome visuelle Agenten für Navigation und Interaktion mit GUIs
- Objektlokalisierungsaufgaben und hochpräzise Texterkennung
- Erstellung reicher und detaillierter Beschreibungen aus sehr komplexen Bildern



## Spezialisierte Modelle



### embeddinggemma:300m  
**Google • 300 M Parameter • Kontext: 2048 Tokens**  

Topmodell für Embeddings von Google, auf seine Größe optimiert, ideal für Such- und semantische Retrieval-Aufgaben.  

**Technische Spezifikationen:**  
- **Lizenz** : Google Gemma Terms of Use  
- **Standort** : FR 🇫🇷  

**Fähigkeiten:**  
❌ Tools/Agent • ❌ Vision • ❌ Reasoning • ❌ Sicherheit  

**Tags :** `Embedding` `Compact` `Semantisch` `Effizient` `Mehrsprachig`  

**Anwendungsfälle:**  
- Suche und Informationsermittlung (Retrieval)  
- Dokumentklassifizierung und -clustering  
- Semantische Ähnlichkeitsforschung  
- Bereitstellung auf ressourcenbeschränkten Geräten (Mobile, Laptop)



### gpt-oss:20b
**OpenAI • 20B Parameter • Kontext: 120.000 Tokens**

Open-Weight-Sprachmodell von OpenAI, optimiert für Effizienz und Einsatz auf Alltagsgeräten.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 57 Tokens/Sekunde ⚡
- **Verbrauch** : 2,34 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit

**Tags :** `MoE` `Agent` `Reasoning` `Open-Source` `Kompakt` `Schnell`

**Anwendungsfälle:**
- Einsatz auf Geräten mit begrenzten Ressourcen (Edge-Geräte) oder kostengünstigen Servern.
- Anwendungen, die eine schnelle Inferenz mit guten Reasoning-Fähigkeiten erfordern.
- Agenten-Anwendungsfälle mit Funktionsaufrufen, Web-Navigation und Code-Execution.
- Fine-Tuning für spezialisierte Aufgaben auf Alltagsgeräten.



### qwen3:14b
**Qwen Team • 14B Parameter • Kontext: 32.000 Tokens**

Neues Dichtemodell der nächsten Generation Qwen3 (14B), das Leistungen bietet, die denen von Qwen2.5 32B entsprechen, mit besserer Effizienz.

**Technische Spezifikationen :**
- **Geschwindigkeit** : 40 Tokens/Sekunde ⚡
- **Verbrauch** : 3,33 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten :**
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit

**Tags :** `Agent` `Reasoning` `Schnell` `Mehrsprachig`

**Anwendungsfälle :**
- Allgemeine Aufgaben, die Leistung und einen großen Kontext erfordern
- Erstellung kreativer und technischer Inhalte
- Datenanalyse und komplexes Denken
- Integration mit externen Tools über Function Calling



### gemma3:12b  
**Google • 12B Parameter • Kontext: 120.000 Tokens**  

Mittlere Version des Gemma 3-Modells, die ein hervorragendes Gleichgewicht zwischen Leistung und Effizienz bietet.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 56 Tokens pro Sekunde ⚡  
- **Verbrauch:** 4,71 kWh pro Million Tokens  
- **Lizenz:** Google Gemma Nutzungsbedingungen  
- **Standort:** FR 🇫🇷  

**Fähigkeiten:**  
❌ Tools/Agent • ✅ Vision • ❌ Reasoning • ❌ Sicherheit  

**Tags:** `Vision` `Schnell` `Großer Kontext`  

**Anwendungsfälle:**  
- Multimodale Anwendungen mit moderaten Ressourcenbeschränkungen  
- Dokumentenverarbeitung mit Standardkontext (bis zu 100 Seiten)  
- Textinhaltsgenerierung und kombinierte Bildanalyse  
- Bereitstellung auf Standard-GPUs ohne spezialisierte Infrastruktur  
- Fortgeschrittene Chatbots mit integrierten visuellen und textuellen Fähigkeiten



### gemma3:4b  
**Google • 4B Parameter • Kontext: 120.000 Tokens**  

Kompakter Google-Modell mit hervorragenden Leistungen in einem leichtgewichtigen und kosteneffizienten Format.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 57 Tokens/Sekunde ⚡  
- **Verbrauch** : 0,58 kWh pro Million Tokens 🌱  
- **Lizenz** : Google Gemma Nutzungsbedingungen  
- **Standort** : FR 🇫🇷  

**Fähigkeiten:**  
❌ Tools/Agent • ✅ Vision • ❌ Begründung • ❌ Sicherheit  

**Tags:** `Vision` `Schnell` `Kompakt` `Großer Kontext` `Effizient`  

**Anwendungsfälle:**  
- Eingebettete Anwendungen und Edge Computing mit Bildverarbeitung  
- Multimodale Chatbots mit geringer Latenz  
- Skalierbare Deployment mit visuellen und textuellen Fähigkeiten  
- Mobile Anwendungen mit Bild- und Textanalyse  
- Verarbeitung visueller Anfragen mit mittlerer bis hoher Komplexität und hoher Leistungsfähigkeit



### gemma3:1b
**Google • 1B Parameter • Kontext: 32.000 Tokens**

Ultra-leichter Mikro-Modell für Deployment auf Geräten mit sehr geringen Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 112 Tokens/Sekunde ⚡
- **Verbrauch** : 0,15 kWh pro Million Tokens 🌱
- **Lizenz** : Google Gemma Nutzungsbedingungen
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ❌ Reasoning • ❌ Sicherheit

**Tags:** `Ultra-kompakt` `Eingebettet` `Effizient` `Schnell`

**Anwendungsfälle:**
- Deployment auf IoT-Geräten und eingebetteten Systemen mit API-Integration
- Anwendungen, die lokale Inferenz auf CPU mit Funktionsaufrufen erfordern
- Grundlegende Textaufgaben mit sofortiger Antwortzeit und Funktionsaufruf
- Kompakte Assistenten für Endverbraucher-Anwendungen mit externen Dienstintegration
- Intelligente Steuersysteme, die mehrere APIs/Dienste integrieren



### lucie-instruct:7b
**OpenLLM-France • 7B Parameter • Kontext: 32.000 Tokens**

Kausales multilinguales Open-Source-Modell (7B), fine-tuned von Lucie-7B. Optimiert für Französisch.

**Technische Spezifikationen :**
- **Geschwindigkeit** : 4 Tokens/Sekunde
- **Verbrauch** : 8,33 kWh pro Million Tokens 🌱
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten :**
❌ Tools/Agent • ❌ Vision • ❌ Reasoning • ❌ Sicherheit

**Tags :** `Französisch` `Open-Source` `Effizient`



### mistral-small3.1:24b
**Mistral AI • 24B Parameter • Kontext: 120.000 Tokens**

Kompakter und reaktiver Modell von Mistral AI, speziell entwickelt, um eine flüssige und relevante Conversationsunterstützung mit optimaler Antwortgeschwindigkeit zu bieten.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 35 Tokens pro Sekunde
- **Verbrauch** : 3,72 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ✅ Vision • ❌ Reasoning • ✅ Sicherheit

**Tags:** `Vision` `Agent` `Sicherheit`

**Anwendungsfälle:**
- Konversationale Anwendungen
- Virtuelle Assistenten mit Bild- und Textanalyse (26 Tokens/s)
- Technische Support-Chatbots mit Zugriff auf technische Dokumentation
- Tools zur Inhaltserstellung/Bearbeitung mit sofortiger Antwort (Blogs, E-Mails)
- Bereitstellung auf Standardinfrastrukturen (24B Parameter)



### mistral-small3.2:24b
**Mistral AI • 24B Parameter • Kontext: 120.000 Tokens**

Kleine Aktualisierung von Mistral Small 3.1, die die Anweisungsbefolgung, die Robustheit des Function Calls und die Wiederholungsfehler reduziert.

**Technische Spezifikationen :**
- **Geschwindigkeit** : 35 Tokens/Sekunde
- **Verbrauch** : 3,72 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten :**
✅ Tools/Agent • ✅ Vision • ❌ Reasoning • ✅ Sicherheit

**Tags :** `Vision` `Agent` `Sicherheit` `Anweisungsbefolgung`

**Anwendungsfälle :**
- Konversationelle Agenten mit verbesserter Anweisungsbefolgung
- Robuste Integration mit externen Tools über Function Calls
- Anwendungen, die eine große Zuverlässigkeit erfordern, um Wiederholungen zu vermeiden
- Identische Anwendungsfälle wie bei Mistral Small 3.1 mit verbesserten Leistungen



### deepcoder:14b  
**Agentica x Together AI • 14B Parameter • Kontext: 32.000 Tokens**  

Open-Source-IA-Modell (14B) von Together AI & Agentica, glaubwürdige Alternative zu proprietären Modellen für die Codegenerierung.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 64 Tokens/Sekunde ⚡  
- **Verbrauch** : 4,12 kWh/Million Tokens  
- **Lizenz** : Apache 2.0  
- **Standort** : FR 🇫🇷  

**Fähigkeiten:**  
❌ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit  

**Tags:** `Programmierung` `Reasoning` `Open-Source` `Mathematik` `Schnell`  

**Anwendungsfälle:**  
- Codegenerierung in mehr als 15 Sprachen mit Leistungsoptimierung  
- Debugging und Refaktorisierung bestehender Code-Basen mit Auswirkungsanalyse  
- Implementierung komplexer Algorithmen (Graphen, Bäume, Heuristiken)  
- Automatisierte Erstellung von Einheitstests mit Codeabdeckung > 80%  
- Codeübersetzung zwischen Sprachen/Frameworks (z. B. Python zu JavaScript)



### granite3.2-vision:2b
**IBM • 2B Parameter • Kontext: 16.384 Tokens**

Revolutionäres kompaktes Modell von IBM, spezialisiert auf Computer Vision, das visuelle Dokumente direkt analysieren und verstehen kann, ohne auf Zwischentechnologien wie OCR zurückzugreifen.

**Technische Spezifikationen :**
- **Geschwindigkeit** : 48 Tokens/Sekunde
- **Verbrauch** : 0,69 kWh pro Million Tokens 🌱
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten :**
✅ Tools/Agent • ✅ Vision • ❌ Reasoning • ✅ Sicherheit

**Tags :** `Vision` `Sicherheit` `Kompakt` `Effizient`

**Anwendungsfälle :**
- Strukturierte Datenextraktion aus Rechnungen und Formularen ohne OCR
- Direkte Analyse von Tabellen und Grafiken mit Trendinterpretation
- Lesen und Interpretieren technischer Diagramme (elektrisch, mechanisch)
- Verarbeitung handschriftlicher Dokumente mit hohem Erkennungsraten
- Leichte Computer Vision (2B Parameter) mit hoher Geschwindigkeit (50 Tokens/Sekunde)



### granite3.3:8b
**IBM • 8B Parameter • Kontext: 60.000 Tokens**

Granite-Modell mit 8B Parametern, feinabgestimmt von IBM für verbessertes Reasoning und Anweisungsbefolgung, mit einem Kontext von 128k Tokens.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 30 Tokens/Sekunde Tokens/Sekunde
- **Verbrauch** : 1,11 kWh pro Million Tokens 🌱
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ✅ Sicherheit

**Tags:** `Agent` `Reasoning` `Sicherheit` `Effizient`

**Anwendungsfälle:**
- Allgemeine Anweisungsbefolgungsaufgaben (Klassifizierung, Extraktion, Q&A)
- Mehrsprachige KI-Assistenten (12 Sprachen)
- Verarbeitung sehr langer Dokumente (128k Tokens) für Aufgaben wie Zusammenfassungen, Q&A,...
- Codegenerierung/Vervollständigung mit Fill-in-the-Middle
- Integration mit externen Tools über Function Calling
- Strukturierter Reasoning im "Thinking"-Modus



### granite3.3:2b
**IBM • 2B Parameter • Kontext: 128.000 Tokens**

Feinabgestimmtes Granite 2B-Modell von IBM, optimiert für Reasoning und Anweisungsbefolgung mit einem Kontext von 128k Tokens.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 45 Tokens/Sekunde
- **Verbrauch** : 0.74 kWh pro Million Tokens 🌱
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ✅ Sicherheit

**Tags:** `Agent` `Reasoning` `Sicherheit` `Effizient`

**Anwendungsfälle:**
- Leichte Deployment mit großem Kontext (128k Tokens)
- Allgemeine Anweisungsbefolgungsaufgaben auf begrenzten Ressourcen
- Kompakte multilinguale KI-Assistenten
- Verarbeitung langer Dokumente auf weniger leistungsstarken Geräten
- FIM-Codegenerierung/Completions auf Standardarbeitsplätzen



### magistral:24b  
**Mistral AI • 24B Parameter • Kontext: 40.000 Tokens**  

Das erste Reasoning-Modell von Mistral AI, das sich durch domainsspezifisches Reasoning, Transparenz und Mehrsprachigkeit auszeichnet.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 25 Tokens pro Sekunde  
- **Verbrauch** : 5,33 kWh pro Million Tokens  
- **Lizenz** : Apache 2.0  
- **Standort** : FR 🇫🇷  

**Fähigkeiten:**  
❌ Tools/Agent • ❌ Vision • ✅ Reasoning • ✅ Sicherheit  

**Tags:** `Reasoning` `Mehrsprachig`  

**Anwendungsfälle:**  
- Strategie und Geschäftsbetrieb (Risikomodellierung)  
- Regulierten Branchen (Recht, Finanzen) mit nachvollziehbarem Reasoning  
- Softwareentwicklung (Projektplanung, Architektur)  
- Inhaltserstellung und Kommunikation (kreative Schreibweise, Erzählung)



### granite3.1-moe:3b
**IBM • 3B Parameter • Kontext: 32.000 Tokens**

Innovatives Modell von IBM, das die Mixture-of-Experts-Architektur (MoE) verwendet, um außergewöhnliche Leistungen zu bieten und die Nutzung der Rechenressourcen drastisch zu optimieren.

**Technische Spezifikationen :**
- **Geschwindigkeit** : 74 Tokens/Sekunde ⚡
- **Verbrauch** : 0,45 kWh pro Million Tokens 🌱
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten :**
✅ Tools/Agent • ❌ Vision • ❌ Reasoning • ✅ Sicherheit

**Tags :** `Agent` `Sicherheit` `Schnell` `MoE` `Effizienz` `Effizient`

**Anwendungsfälle :**
- Allgemeine Anwendungen mit optimierten Inferenzkosten (42 Tokens/Sekunde)
- Dokumentenverarbeitung in CPU-Umgebungen mit begrenzter RAM-Nutzung
- Spezialanalysen mit dynamischer Aktivierung relevanter Modellteile
- Hochdichte-Deployment mit geringem Energieverbrauch pro Inferenz
- Parallele Verarbeitung mehrerer Anfragentypen mit MoE-Spezialisierung



### cogito:14b  
**Deep Cogito • 14B Parameter • Kontext: 32.000 Tokens**  

Modell von Deep Cogito, speziell für tiefes Denken und feine kontextuelle Verständnis entwickelt, ideal für anspruchsvolle analytische Anwendungen.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 60 Tokens pro Sekunde ⚡  
- **Verbrauch** : 4,4 kWh pro Million Tokens  
- **Lizenz** : LLAMA 3.2 Community Lizenz  
- **Standort** : FR 🇫🇷  

**Fähigkeiten:**  
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit  

**Tags:** `Agent` `Reasoning` `Verständnis` `Analyse` `Schnell`  

**Anwendungsfälle:**  
- Semantische Analyse von Texten mit Identifizierung impliziter Implikationen  
- Strukturierter kausaler Schlussfolgerung mit Identifizierung ursächlicher Beziehungen  
- Zusammenfassung komplexer Dokumente mit Extraktion der Schlüsselinformationen  
- Präzise Frage-Antwort-Systeme für spezialisierte Dokumentenkorpora  
- Argumentative Analyse mit Bewertung der Stärke der Schlussfolgerungen



### cogito:32b  
**Deep Cogito • 32B Parameter • Kontext: 32.000 Tokens**  

Erweiterte Version des Cogito-Modells mit erheblich verstärkten Reasoning- und Analysefähigkeiten, konzipiert für die anspruchsvollsten Anwendungen im Bereich analytischer KI.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 32 Tokens/Sekunde Tokens/Sekunde  
- **Verbrauch** : 8,25 kWh pro Million Tokens  
- **Lizenz** : LLAMA 3.2 Community Lizenz  
- **Standort** : FR 🇫🇷  

**Fähigkeiten:**  
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit  

**Tags:** `Agent` `Reasoning` `Verständnis` `Analyse`  

**Anwendungsfälle:**  
- Analyse von Multi-Faktor-Szenarien mit probabilistischer Ergebnisevaluation  
- Lösung wissenschaftlicher Probleme mit formaler Schritt-Demonstration  
- Hochkritische Anwendungen, die Genauigkeit und Verifizierbarkeit der Ergebnisse erfordern  
- Expertensysteme in spezialisierten Bereichen (rechtlich, medizinisch, technisch)  
- Analyse mit mehrstufigem Reasoning und vollständiger Erklärbarkeit der Schlussfolgerungen



### qwen3:32b
**Qwen Team • 32B Parameter • Kontext: 40.000 Tokens**

Leistungsstarker Modell der neuen Qwen3-Generation mit fortgeschrittenen Fähigkeiten im Bereich Reasoning, Code und Agententechnologie, mit erweitertem Kontext.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 18 Tokens/Sekunde
- **Verbrauch** : 7,41 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit

**Tags:** `Agent` `Reasoning` `Mehrsprachig` `Großer Kontext`

**Anwendungsfälle:**
- Fortgeschrittene conversationelle Agenten mit großem Kontext und Integration von Tools (MCP)
- Lösung komplexer Probleme (Mathematik, Code) im "Thinking"-Modus
- Analyse und Generierung umfangreicher Dokumente
- Mehrsprachige Anwendungen (>100 Sprachen), die eine tiefe Verständnisfähigkeit erfordern



### qwq:32b
**Qwen Team • 32B Parameter • Kontext: 32.000 Tokens**

Modell mit 32 Milliarden Parametern, optimiert durch Verstärkungslernen (RL), um sich in Reasoning, Codierung, Mathematik und Agent-Aufgaben hervorzutun.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 35 Tokens pro Sekunde
- **Verbrauch** : 7,54 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit

**Tags:** `Agent` `Reasoning` `Codierung` `Mathematik`

**Anwendungsfälle:**
- Lösung komplexer Probleme, die Reasoning und Nutzung von Tools erfordern
- Erstellung und Ausführung von Code mit Ergebnisprüfung
- Fortgeschrittene mathematische Aufgaben mit Genauigkeitsprüfung
- Agent-Anwendungen, die mit der Umgebung interagieren können
- Verbessertes Instruction Following und Ausrichtung auf menschliche Präferenzen



### deepseek-r1:14b
**DeepSeek AI • 14B Parameter • Kontext: 32.000 Tokens**

Kompakte und effiziente Version des DeepSeek-R1-Modells, die ein hervorragendes Gleichgewicht zwischen Leistung und Leichtigkeit bietet für Deployment, die Flexibilität und Reaktivität erfordern.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 62 Tokens/Sekunde ⚡
- **Verbrauch** : 4,26 kWh/Million Tokens
- **Lizenz** : MIT-Lizenz
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit

**Tags:** `Reasoning` `Kompakt` `Vielseitig` `Schnell`

**Anwendungsfälle:**
- Allgemeine Anwendungen mit Bedarf an schneller Inferenz (44 Tokens/s)
- Deployment auf Standard-Server ohne spezialisierte GPU (14B Parameter)
- Textverarbeitung mit kontextueller Analyse und schneller Antwortzeit
- Deployment im Edge Computing mit lokaler Optimierung der Inferenz
- Schnelle Prototypentwicklung von KI-Anwendungen mit kurzer Iterationszeit



### deepseek-r1:32b
**DeepSeek AI • 32B Parameter • Kontext: 32.000 Tokens**

Zwischenversion des DeepSeek-R1-Modells, die ein strategisches Gleichgewicht zwischen den fortgeschrittenen Fähigkeiten der 70B-Version und der Effizienz der 14B-Version bietet, für eine vielseitige und optimale Leistung.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 33 Tokens pro Sekunde
- **Verbrauch:** 7,99 kWh pro Million Tokens
- **Lizenz:** MIT-Lizenz
- **Standort:** FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit

**Tags:** `Reasoning` `Vielseitig`

**Anwendungsfälle:**
- Anwendungen, die ein gutes Leistungs-Kosten-Verhältnis benötigen (32B Parameter)
- Professionelle Textverarbeitung mit Analyse der semantischen Nuancen
- Automatisierte Generierung strukturierter Berichte aus Rohdaten
- Anwendungen, die Datenanalyse und Inhaltsgenerierung kombinieren
- Spezialisierte Assistenten für technische Bereiche (rechtlich, medizinisch, technisch)



### cogito:3b
**Deep Cogito • 3B Parameter • Kontext: 32.000 Tokens**

Kompakte Version des Cogito-Modells, optimiert für das Denken auf Geräten mit begrenzten Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 55 Tokens/Sekunde ⚡
- **Verbrauch** : 0,61 kWh pro Million Tokens 🌱
- **Lizenz** : LLAMA 3.2 Community Lizenz
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Denken • ❌ Sicherheit

**Tags:** `Denken` `Kompakt` `Eingebettet` `Effizient` `Schnell`



### granite-embedding:278m
**IBM • 278M Parameter • Kontext: 512 Tokens**

Ultraleichter IBM-Embedding-Modell für semantische Suche und Klassifizierung.

**Technische Spezifikationen:**
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ❌ Reasoning • ❌ Sicherheit

**Tags:** `Embedding` `Kompakt` `Semantisch` `Effizient`



### granite3-guardian:2b
**IBM • 2B Parameter • Kontext: 8192 Tokens**

Kompakter IBM-Modell, spezialisiert auf Sicherheit und Compliance, das Risiken und unangemessene Inhalte erkennt.

**Technische Spezifikationen:**
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ❌ Reasoning • ✅ Sicherheit

**Tags :** `Sicherheit` `Compliance` `Kompakt` `Filterung` `Effizient`



### granite3-guardian:8b  
**IBM • 8B Parameter • Kontext: 32.000 Tokens**  

IBM-Modell, spezialisiert auf Sicherheit und Compliance, mit fortgeschrittenen Fähigkeiten zur Risikodetektion.  

**Technische Spezifikationen:**  
- **Lizenz** : Apache 2.0  
- **Standort** : FR 🇫🇷  

**Fähigkeiten:**  
❌ Tools/Agent • ❌ Vision • ❌ Reasoning • ✅ Sicherheit  

**Tags :** `Sicherheit` `Compliance` `Filterung`



### qwen2.5:0.5b
**Qwen Team • 0,5 B Parameter • Kontext: 32.000 Tokens**

Ultra-leichter Mikro-Modell der Qwen 2.5-Familie, optimiert für maximale Effizienz auf eingeschränkten Geräten.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 162 Tokens/Sekunde ⚡
- **Verbrauch** : 0,1 kWh pro Million Tokens 🌱
- **Lizenz** : MIT-Lizenz
- **Lokalisierung** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ❌ Begründung • ❌ Sicherheit

**Tags:** `Ultra-kompakt` `Schnell` `Eingebettet` `Effizient`



### qwen2.5:1.5b
**Qwen Team • 1.5B Parameter • Kontext: 32.000 Tokens**

Sehr kompakter Modell der Qwen 2.5-Familie mit einem guten Leistungs-/Größengleichgewicht für leichte Bereitstellungen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 102 Tokens pro Sekunde ⚡
- **Verbrauch** : 0,33 kWh pro Million Tokens 🌱
- **Lizenz** : MIT-Lizenz
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ❌ Begründung • ❌ Sicherheit

**Tags:** `Kompakt` `Schnell` `Eingebettet` `Effizient`



### qwen2.5:14b
**Qwen Team • 14B Parameter • Kontext: 32.000 Tokens**

Vielseitiges Modell mittlerer Größe der Qwen 2.5-Familie mit einem guten Leistungs-/Ressourcenverhältnis.

**Technische Spezifikationen :**
- **Geschwindigkeit** : 61 Tokens/Sekunde ⚡
- **Verbrauch** : 4,33 kWh pro Million Tokens
- **Lizenz** : MIT-Lizenz
- **Standort** : FR 🇫🇷

**Fähigkeiten :**
✅ Tools/Agent • ❌ Vision • ❌ Begründung • ❌ Sicherheit

**Tags :** `Vielseitig` `Mehrsprachig` `Schnell`



### qwen2.5:32b
**Qwen Team • 32B Parameter • Kontext: 32.000 Tokens**

Leistungsstarker Modell der Qwen 2.5-Familie mit fortgeschrittenen Fähigkeiten in Verständnis und Generierung.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 31 Tokens/Sekunde
- **Verbrauch** : 8,51 kWh/Million Tokens
- **Lizenz** : MIT-Lizenz
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit

**Tags:** `Vielseitig` `Mehrsprachig` `Reasoning`



### qwen2.5:3b
**Qwen Team • 3B Parameter • Kontext: 32.000 Tokens**

Kompakter und effizienter Modell der Qwen 2.5-Familie, geeignet für allgemeine Aufgaben bei begrenzten Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 64 Tokens pro Sekunde ⚡
- **Verbrauch** : 0,52 kWh pro Million Tokens 🌱
- **Lizenz** : MIT-Lizenz
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ❌ Begründung • ❌ Sicherheit

**Tags:** `Kompakt` `Schnell` `Vielseitig` `Effizient`



### qwen3:0.6b
**Qwen Team • 0,6B Parameter • Kontext: 32.000 Tokens**

Kompakter und effizienter Modell der Qwen3-Familie, geeignet für allgemeine Aufgaben auf begrenzten Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 112 Tokens pro Sekunde ⚡
- **Verbrauch** : 0,15 kWh pro Million Tokens 🌱
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Werkzeuge/Agent • ❌ Vision • ❌ Begründung • ❌ Sicherheit

**Tags:** `Kompakt` `Schnell` `Vielseitig` `Effizient`



### qwen3:1.7b  
**Qwen Team • 1,7B Parameter • Kontext: 32.000 Tokens**  

Ein sehr kompakter Modell der Qwen3-Familie, der ein gutes Leistungs-/Größenverhältnis für leichte Deployment-Anwendungen bietet.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 88 Tokens pro Sekunde ⚡  
- **Verbrauch:** 0,38 kWh pro Million Tokens 🌱  
- **Lizenz:** Apache 2.0  
- **Standort:** FR 🇫🇷  

**Fähigkeiten:**  
✅ Tools/Agent • ❌ Vision • ❌ Reasoning • ❌ Sicherheit  

**Tags:** `Kompakt` `Schnell` `Eingebettet` `Effizient`



### qwen3:4b
**Qwen Team • 4B Parameter • Kontext: 32.000 Tokens**

Kompakter Modell der Qwen3-Familie mit hervorragenden Leistungen in einem leichtgewichtigen und wirtschaftlichen Format.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 49 Tokens/Sekunde
- **Verbrauch** : 0,68 kWh pro Million Tokens 🌱
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ❌ Reasoning • ❌ Sicherheit

**Tags :** `Kompakt` `Effizient`



### qwen3-2507-think:4b
**Qwen Team • 4B Parameter • Kontext: 250.000 Tokens**

Qwen3-4B-Modell optimiert für Reasoning mit verbesserten Leistungen bei logischen Aufgaben, Mathematik, Wissenschaft und Code sowie einem erweiterten Kontext von 250.000 Tokens.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 70 Tokens pro Sekunde ⚡
- **Verbrauch:** 1,9 kWh pro Million Tokens
- **Lizenz:** Apache 2.0
- **Standort:** FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit

**Tags:** `Agent` `Reasoning` `Großer Kontext` `Kompakt` `Schnell`

**Anwendungsfälle:**
- Sehr komplexe Reasoning-Aufgaben (Logik, Mathematik, Wissenschaft, Code).
- Konversationelle Agenten mit sehr umfangreichen Chat-Verläufen (256k Tokens).
- Analyse sehr umfangreicher Dokumente mit tiefem Reasoning.
- Integration mit externen Tools über Function Calling auf sehr großen Kontexten.



### qwen3-2507:4b  
**Qwen Team • 4B Parameter • Kontext: 250.000 Tokens**  

Aktualisierte Version des Nicht-denken-Modus von Qwen3-4B mit erheblichen Verbesserungen der allgemeinen Fähigkeiten, erweiterter Wissensabdeckung und besserer Ausrichtung auf Benutzerpräferenzen.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 70 Tokens pro Sekunde ⚡  
- **Verbrauch:** 1,9 kWh pro Million Tokens  
- **Lizenz:** Apache 2.0  
- **Standort:** FR 🇫🇷  

**Fähigkeiten:**  
✅ Tools/Agent • ❌ Vision • ❌ Reasoning • ❌ Sicherheit  

**Tags:** `Agent` `Großer Kontext` `Kompakt` `Schnell` `Mehrsprachig`  

**Anwendungsfälle:**  
- Allgemeine Aufgaben, die eine präzise Befolgung von Anweisungen und logisches Denken erfordern.  
- Mehrsprachige Anwendungen mit umfassender Wissensabdeckung.  
- Hochwertige Textgenerierung für offene und subjektive Aufgaben.  
- Analyse sehr umfangreicher Dokumente dank des 256k-Token-Kontexts.



### qwen3:8b
**Qwen Team • 8B Parameter • Kontext: 32.000 Tokens**

Qwen3 8B Modell, das ein gutes Gleichgewicht zwischen Leistung und Effizienz für allgemeine Aufgaben bietet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 33 Tokens/Sekunde Tokens/Sekunde
- **Verbrauch** : 1,01 kWh pro Million Tokens 🌱
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit

**Tags:** `Reasoning` `Agent` `Mehrsprachig` `Effizient`



### qwen2.5vl:3b
**Qwen Team • 3,8 Milliarden Parameter • Kontext: 128.000 Tokens**

Kompakter Vision-Text-Modell, leistungsstarke Lösung für Edge AI (Edge-Intelligenz).

**Technische Spezifikationen:**
- **Geschwindigkeit** : 65 Tokens/Sekunde ⚡
- **Verbrauch** : 0,51 kWh pro Million Tokens 🌱
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ✅ Vision • ✅ Reasoning • ❌ Sicherheit

**Tags :** `Vision` `Agent` `Reasoning` `Schnell` `Effizient` `OCR` `Visuelle Lokalisierung` `Edge AI`



### qwen2.5vl:7b
**Qwen Team • 7B (8,3B) Parameter • Kontext: 128.000 Tokens**

Leistungsstarkes Vision-Sprachmodell, das GPT-4o-mini bei bestimmten Aufgaben übertreffen kann.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 35 Tokens/Sekunde
- **Verbrauch** : 0,95 kWh pro Million Tokens 🌱
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ✅ Vision • ✅ Reasoning • ❌ Sicherheit

**Tags:** `Vision` `Agent` `Reasoning` `Effizient` `OCR` `Visuelle Lokalisierung`



### hf.co/roadus/Foundation-Sec-8B-Q4_K_M-GGUF:Q4_K_M
**Foundation AI — Cisco • 8B Parameter • Kontext: 16.384 Tokens**

Spezialmodell für Cybersecurity, optimiert für Effizienz.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 21 Tokens pro Sekunde
- **Verbrauch** : 1,59 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ✅ Reasoning • ✅ Sicherheit

**Tags:** `Sicherheit` `Kompakt`



### devstral:24b
**Mistral AI & All Hands AI • 24B Parameter • Kontext: 120.000 Tokens**

Devstral ist ein LLM-Agent für Software-Engineering-Aufgaben.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 45 Tokens pro Sekunde
- **Verbrauch** : 5,86 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ❌ Reasoning • ✅ Sicherheit

**Tags:** `Agent` `Programmierung` `Open-Source` `Großer Kontext`

**Anwendungsfälle:**
- Exploration und Änderung von Code-Basen
- Agentic
- Europäisch



### cogito:8b
**Deep Cogito • 8B Parameter • Kontext: 32.000 Tokens**

Mittleres Modell der Cogito-Familie, das ein gutes Gleichgewicht zwischen Denkfähigkeiten und Effizienz bietet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 30 Tokens/Sekunde
- **Verbrauch** : 1,11 kWh pro Million Tokens 🌱
- **Lizenz** : LLAMA 3.2 Community Lizenz
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
✅ Tools/Agent • ❌ Vision • ✅ Reasoning • ❌ Sicherheit

**Tags:** `Agent` `Reasoning` `Vielseitig` `Effizient`



### llama3.1:8b
**Meta • 8B Parameter • Kontext: 32.000 Tokens**

Grundmodell der Llama 3.1-Familie mit soliden Leistungen für seine Größe.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 31 Tokens pro Sekunde
- **Verbrauch** : 1,08 kWh pro Million Tokens 🌱
- **Lizenz** : LLAMA 3.1 Community Lizenz
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Werkzeuge/Agent • ❌ Sehen • ❌ Begründung • ❌ Sicherheit

**Tags:** `Vielseitig` `Effizient`



### phi4-reasoning:14b
**Microsoft • 14B Parameter • Kontext: 32.000 Tokens**

Modell der Phi-Familie von Microsoft, spezialisiert auf komplexes Denken und Mathematik.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 71 Tokens/Sekunde ⚡
- **Verbrauch** : 3,71 kWh pro Million Tokens
- **Lizenz** : MIT Lizenz
- **Standort** : FR 🇫🇷

**Fähigkeiten:**
❌ Tools/Agent • ❌ Vision • ✅ Denken • ❌ Sicherheit

**Tags :** `Denken` `Mathematik` `Programmierung` `Schnell`



## Empfohlene Anwendungsfälle



### Mehrsprachiger Dialog
Chatbots und Assistenten, die in mehreren Sprachen kommunizieren können, mit automatischer Spracherkennung, Erhaltung des Kontexts über die gesamte Unterhaltung hinweg und Verständnis der sprachlichen Besonderheiten

**Empfohlene Modelle:**
- Llama 3.3
- Mistral Small 3.2
- Qwen 3
- Granite 3.3



### Analyse von langen Dokumenten  
Verarbeitung von umfangreichen Dokumenten (mehr als 100 Seiten) mit Kontextbeibehaltung über den gesamten Text, Extraktion von Schlüsselinformationen, Generierung relevanter Zusammenfassungen und Beantwortung spezifischer Fragen zum Inhalt  

**Empfohlene Modelle:**  
- Gemma 3  
- Qwen3  
- Granite 3.3



### Programmierung und Entwicklung  
Erstellung und Optimierung von Code in mehreren Sprachen, Debuggen, Refactoring, Entwicklung vollständiger Funktionen, Verständnis komplexer algorithmischer Implementierungen und Erstellung von Einheitstests  

**Empfohlene Modelle:**  
- DeepCoder  
- QwQ  
- Qwen3 coder  
- Granite 3.3  
- Devstral



### Visuelle Analyse  
Direkter Umgang mit Bildern und visuellen Dokumenten ohne vorherige OCR-Verarbeitung, Interpretation technischer Diagramme, Grafiken, Tabellen, Zeichnungen und Fotos mit Erstellung detaillierter textueller Erklärungen des visuellen Inhalts  

**Empfohlene Modelle:**  
- Granite 3.2 Vision  
- Mistral Small 3.2  
- Gemma 3  
- Qwen2.5-VL



### Sicherheit und Compliance
Anwendungen, die spezifische Sicherheitsfunktionen erfordern; sensibler Inhalt filtern, Nachvollziehbarkeit der Schlussfolgerungen, GDPR/HDS-Prüfung, Risikominimierung, Schwachstellenanalyse und Einhaltung branchenspezifischer Vorschriften

**Empfohlene Modelle:**
- Granite Guardian
- Granite 3.3
- Devstral
- Mistral Small 3.1
- Magistral 24b
- Foundation-Sec-8B



### Leichte und eingebettete Bereitstellungen  
Anwendungen mit minimalem Ressourcenbedarf, Bereitstellung auf Geräten mit begrenzter Kapazität, Echtzeit-Infereenz auf Standard-CPU und Integration in eingebettete Systeme oder IoT  

**Empfohlene Modelle:**  
- Gemma 3  
- Granite 3.1 MoE  
- Granite Guardian  
- Granite 3.3