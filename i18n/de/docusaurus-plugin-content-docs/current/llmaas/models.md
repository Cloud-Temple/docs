

---
title: Katalog der LLMaaS-Modelle
sidebar_position: 2
---



# Katalog der LLM-Modelle as a Service



## Ãœberblick

Cloud Temple LLMaaS bietet **51 sorgfÃ¤ltig ausgewÃ¤hlte und optimierte groÃŸe Sprachmodelle**, die den strengsten Anforderungen von **SecNumCloud** entsprechen. Unser Katalog umfasst das gesamte Spektrum, von ultra-effizienten Mikro-Modellen bis hin zu extrem groÃŸen Modellen.



### Globale Statistiken

| Metrik | Wert |
|--------|------|
| **Gesamtanzahl der Modelle** | 51 Modelle |
| **Minimales Kontext** | 8 192 Tokens |
| **Maximales Kontext** | 262 144 Tokens |
| **KonformitÃ¤t** | SecNumCloud âœ… HDS âœ… SouverÃ¤nitÃ¤t âœ… C5 âŒ |
| **Standort** | 100% Frankreich ğŸ‡«ğŸ‡· |



### Preisgestaltung

| Verwendungstyp | Preis |
|-------------------|------|
| **Eingabetokens** | 0.9â‚¬ / Million Tokens |
| **Ausgabetokens** | 4â‚¬ / Million Tokens |
| **Erweitertes Reasoning** | 21â‚¬ / Million Tokens |



## Modelle groÃŸer GrÃ¶ÃŸe



### gpt-oss:120b
**OpenAI â€¢ 120B Parameter â€¢ Kontext: 120.000 Tokens**

Open-Weight-Modell der Spitzenklasse von OpenAI mit starken Leistungen und einer flexiblen Apache 2.0-Lizenz.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 38 Tokens pro Sekunde
- **Verbrauch** : 3,51 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âœ… Reasoning â€¢ âŒ Sicherheit

**Tags:** `MoE` `Agent` `Reasoning` `Open-Source` `Sehr groÃŸ`

**AnwendungsfÃ¤lle:**
- Fortgeschrittene conversationelle Agenten mit komplexem Reasoning und Tool-Integration.
- Anwendungen, die eine vollstÃ¤ndige Transparenz des Reasoning-Prozesses (Kette des Denkens) erfordern.
- GeschÃ¤ftsszenarien, die eine flexible Lizenz (Apache 2.0) benÃ¶tigen.
- Fine-Tuning fÃ¼r spezialisierte Aufgaben, die ein leistungsstarkes Grundmodell erfordern.



### llama3.3:70b
**Meta â€¢ 70B Parameter â€¢ Kontext: 120.000 Tokens**

Fortgeschrittenes Mehrsprachmodell von Meta, das fÃ¼r natÃ¼rliche GesprÃ¤che, komplexes Denken und feine VerstÃ¤ndnis von Anweisungen optimiert ist.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 15 Tokens pro Sekunde
- **Verbrauch** : 8,89 kWh pro Million Tokens
- **Lizenz** : LLAMA 3.3 Community Lizenz
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âŒ BegrÃ¼ndung â€¢ âŒ Sicherheit

**Tags:** `Agent` `Dialog` `Mehrsprachig`

**AnwendungsfÃ¤lle:**
- Mehrsprachige Chatbots, die 8 Sprachen gleichzeitig unterstÃ¼tzen
- AusfÃ¼hrung komplexer, verketteter Anweisungen (Prompt Chaining)
- Verarbeitung eines Dialogfensters mit 60.000 Tokens fÃ¼r ConversationsverlÃ¤ufe
- Analyse umfangreicher juristischer oder technischer Dokumente (>100 Seiten)
- Erstellung strukturierter Texte mit Treue zu stilistischen Anweisungen



### qwen3:235b
**Qwen Team â€¢ 235B Parameter â€¢ Kontext: 60.000 Token**

Ein sehr groÃŸes Modell der neuen Qwen3-Generation mit erweiterten FÃ¤higkeiten fÃ¼r komplexe Aufgaben.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 17 Token pro Sekunde âš¡
- **Verbrauch:** 7,84 kWh pro Million Token
- **Lizenz:** Apache 2.0
- **Standort:** FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âœ… BegrÃ¼ndung â€¢ âŒ Sicherheit

**Tags:** `Agent` `BegrÃ¼ndung` `Mehrsprachig` `Sehr groÃŸ`

**AnwendungsfÃ¤lle:**
- Sehr fortgeschrittene conversationelle Agenten mit groÃŸem Kontext und Integration von Tools (MCP)
- LÃ¶sung extrem komplexer Probleme (Mathematik, Code)
- Analyse und Generierung sehr umfangreicher und technischer Dokumente
- Mehrsprachige Anwendungen (>100 Sprachen), die eine sehr hohe Genauigkeit bei VerstÃ¤ndnis und Generierung erfordern



### deepseek-r1:671b
**DeepSeek AI â€¢ 671B Parameter â€¢ Kontext: 16.000 Tokens**

Ã„uÃŸerst groÃŸes Modell von DeepSeek AI, entwickelt fÃ¼r den HÃ¶henpunkt des Denkens und der Generierung.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 12 Tokens pro Sekunde
- **Verbrauch** : 11,11 kWh pro Million Tokens
- **Lizenz** : MIT Lizenz
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âŒ Tools/Agent â€¢ âŒ Vision â€¢ âœ… Denken â€¢ âŒ Sicherheit

**Tags:** `Denken` `AuÃŸergewÃ¶hnlich groÃŸ`

**AnwendungsfÃ¤lle:**
- HÃ¶chstleistungsdenkaufgaben
- Hochwertige Textgenerierung
- AI-Forschung und -entwicklung

---



### gemma3:27b  
**Google â€¢ 27B Parameter â€¢ Kontext: 120.000 Tokens**  

RevolutionÃ¤res Modell von Google, das ein optimales Gleichgewicht zwischen Leistung und Effizienz bietet und ein auÃŸergewÃ¶hnliches Leistungs-Kosten-VerhÃ¤ltnis fÃ¼r anspruchsvolle professionelle Anwendungen aufweist.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 20 Tokens/Sekunde Tokens/Sekunde  
- **Verbrauch** : 6,67 kWh pro Million Tokens  
- **Lizenz** : Google Gemma Nutzungsbedingungen  
- **Standort** : FR ğŸ‡«ğŸ‡·  

**FÃ¤higkeiten:**  
âœ… Tools/Agent â€¢ âœ… Vision â€¢ âŒ Denken â€¢ âŒ Sicherheit  

**Tags:** `Vision` `Agent` `GroÃŸer Kontext`  

**AnwendungsfÃ¤lle:**  
- Dokumentanalyse mit erweitertem Kontext bis zu 120.000 Tokens (ca. 400 Seiten)  
- Semantische Indexierung und Suche in umfangreichen Dokumentenbanken  
- Bild- und Textverarbeitung gleichzeitig dank multimodaler FÃ¤higkeiten  
- Strukturierte Datenextraktion aus PDFs und gescannten Dokumenten  
- Integration mit externen Tools Ã¼ber die API-Funktionaufruf



### qwen3-coder:30b
**Qwen Team â€¢ 30B Parameter â€¢ Kontext: 250.000 Tokens**

MoE-Modell optimiert fÃ¼r Aufgaben der Softwareentwicklung mit sehr langer KontextlÃ¤nge.

**Technische Spezifikationen :**
- **Geschwindigkeit** : 80 Tokens/Sekunde âš¡
- **Verbrauch** : 3,3 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten :**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âœ… BegrÃ¼ndung â€¢ âŒ Sicherheit

**Tags :** `Agent` `Programmierung` `GroÃŸer Kontext` `MoE`

**AnwendungsfÃ¤lle :**
- Softwareentwicklungs-Agenten zur Exploration und Ã„nderung von Code-Basen
- Erstellung komplexer Code mit VerstÃ¤ndnis auf Repository-Ebene
- BegrÃ¼ndungsaufgaben mit erweiterten Kontexten
- Code-Verbesserung durch VerstÃ¤rkungslernen



### qwen3-2507-think:30b-a3b
**Qwen Team â€¢ 30B Parameter â€¢ Kontext: 120.000 Tokens**

Erweitertes Modell der Qwen3-Familie, optimiert fÃ¼r tiefes Denken und erweiterte Kontexte.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 80 Tokens/Sekunde âš¡
- **Verbrauch** : 3,3 kWh/Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âœ… Denken â€¢ âŒ Sicherheit

**Tags:** `Agent` `Denken` `GroÃŸer Kontext`

**AnwendungsfÃ¤lle:**
- Analyse von sehr umfangreichen Dokumenten mit komplexem Denken.
- Konversationelle Agenten mit erweitertem GesprÃ¤chsverlauf.
- Q&A-Aufgaben auf groÃŸen Textkorpus.
- Integration mit externen Tools Ã¼ber Function Calling auf groÃŸen Kontexten.



### qwen3-2507:30b-a3b
**Qwen Team â€¢ 30B Parameter â€¢ Kontext: 250.000 Tokens**

Verbesserte Version des Denkmodus von Qwen3-30B mit verbesserten allgemeinen FÃ¤higkeiten, Wissensabdeckung und Benutzeranpassung.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 90 Tokens/Sekunde âš¡
- **Verbrauch:** 2,16 kWh pro Million Tokens
- **Lizenz:** Apache 2.0
- **Standort:** FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âŒ BegrÃ¼ndung â€¢ âŒ Sicherheit

**Tags:** `Agent` `GroÃŸer Kontext` `MoE` `Mehrsprachig`

**AnwendungsfÃ¤lle:**
- Komplexe Aufgaben, die prÃ¤zises Anweisungsverfolgung und logisches Denken erfordern.
- Mehrsprachige Anwendungen mit umfassender Wissensabdeckung.
- Hochwertige Textgenerierung fÃ¼r offene und subjektive Aufgaben.
- Analyse sehr umfangreicher Dokumente dank des 250k-Token-Kontexts.



### qwen3:30b-a3b
**Qwen Team â€¢ 30B Parameter â€¢ Kontext: 32.000 Tokens**

Die neueste Generation der Qwen-Modelle mit signifikanten Verbesserungen in Bezug auf Trainingsdaten, Architektur und Optimierung.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 50 Tokens pro Sekunde
- **Verbrauch:** 3,89 kWh pro Million Tokens
- **Lizenz:** Apache 2.0
- **Standort:** FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âœ… BegrÃ¼ndung â€¢ âŒ Sicherheit

**Tags:** `Agent` `Programmierung` `Mehrsprachig` `MoE`

**AnwendungsfÃ¤lle:**
- Komplexe BegrÃ¼ndungsaufgaben und Codegenerierung.
- Mehrsprachige Anwendungen, die eine breite sprachliche Abdeckung erfordern.
- Szenarien, die ein gutes Gleichgewicht zwischen Leistung und Ressourceneffizienz durch die MoE-Architektur erfordern.



### deepseek-r1:70b
**DeepSeek AI â€¢ 70B Parameter â€¢ Kontext: 32.000 Tokens**

70B-Modell von DeepSeek AI

**Technische Spezifikationen :**
- **Geschwindigkeit** : 21 Tokens pro Sekunde
- **Verbrauch** : 12,56 kWh pro Million Tokens
- **Lizenz** : MIT-Lizenz
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten :**
âŒ Tools/Agent â€¢ âŒ Vision â€¢ âœ… Reasoning â€¢ âŒ Sicherheit

**Tags :** `Reasoning` `Large`

**AnwendungsfÃ¤lle :**
- Spitzenleistungen im Reasoning
- Hochwertige Textgenerierung
- AI-Forschung und -entwicklung



### qwen2.5vl:32b
**Qwen Team â€¢ 32B Parameter â€¢ Kontext: 120.000 Tokens**

Die leistungsstÃ¤rkste Version der Qwen2.5-VL-Serie mit fortschrittlicher visueller VerstÃ¤ndnisfÃ¤higkeit und avantgardistischen Agenten.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 18 Tokens/Sekunde
- **Verbrauch** : 7,41 kWh/Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âœ… Vision â€¢ âŒ Reasoning â€¢ âŒ Sicherheit

**Tags:** `Vision` `Agent` `Reasoning` `OCR` `Visuelle Lokalisierung` `Large`

**AnwendungsfÃ¤lle:**
- Analyse von sehr komplexen Dokumenten und Diagrammen
- Autonome visuelle Agenten fÃ¼r Navigation und Interaktion mit GUIs
- Objektlokalisierungsaufgaben und hochprÃ¤zise Texterkennung
- Erstellung reicher und detaillierter Beschreibungen aus komplexen Bildern



### qwen2.5vl:72b
**Qwen Team â€¢ 72B Parameter â€¢ Kontext: 128.000 Tokens**

Die leistungsstÃ¤rkste Version der Qwen2.5-VL-Serie mit fortschrittlichen visuellen VerstÃ¤ndnis- und AgentenfÃ¤higkeiten fÃ¼r die anspruchsvollsten Aufgaben.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 15 Tokens/Sekunde Tokens/Sekunde
- **Verbrauch:** 8,89 kWh pro Million Tokens
- **Lizenz:** Apache 2.0
- **Lokalisierung:** FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âœ… Vision â€¢ âœ… Reasoning â€¢ âŒ Sicherheit

**Tags:** `Vision` `Agent` `Reasoning` `OCR` `Visuelle Lokalisierung` `Sehr GroÃŸ`

**AnwendungsfÃ¤lle:**
- Analyse von sehr komplexen Dokumenten und Diagrammen
- Autonome visuelle Agenten fÃ¼r Navigation und Interaktion mit GUIs
- Objektlokalisierungsaufgaben und hochprÃ¤zise Texterkennung
- Erstellung reicher und detaillierter Beschreibungen aus sehr komplexen Bildern



## Spezialisierte Modelle



### embeddinggemma:300m  
**Google â€¢ 300 M Parameter â€¢ Kontext: 2048 Tokens**  

Topmodell fÃ¼r Embeddings von Google, auf seine GrÃ¶ÃŸe optimiert, ideal fÃ¼r Such- und semantische Retrieval-Aufgaben.  

**Technische Spezifikationen:**  
- **Lizenz** : Google Gemma Terms of Use  
- **Standort** : FR ğŸ‡«ğŸ‡·  

**FÃ¤higkeiten:**  
âŒ Tools/Agent â€¢ âŒ Vision â€¢ âŒ Reasoning â€¢ âŒ Sicherheit  

**Tags :** `Embedding` `Compact` `Semantisch` `Effizient` `Mehrsprachig`  

**AnwendungsfÃ¤lle:**  
- Suche und Informationsermittlung (Retrieval)  
- Dokumentklassifizierung und -clustering  
- Semantische Ã„hnlichkeitsforschung  
- Bereitstellung auf ressourcenbeschrÃ¤nkten GerÃ¤ten (Mobile, Laptop)



### gpt-oss:20b
**OpenAI â€¢ 20B Parameter â€¢ Kontext: 120.000 Tokens**

Open-Weight-Sprachmodell von OpenAI, optimiert fÃ¼r Effizienz und Einsatz auf AlltagsgerÃ¤ten.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 57 Tokens/Sekunde âš¡
- **Verbrauch** : 2,34 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âœ… Reasoning â€¢ âŒ Sicherheit

**Tags :** `MoE` `Agent` `Reasoning` `Open-Source` `Kompakt` `Schnell`

**AnwendungsfÃ¤lle:**
- Einsatz auf GerÃ¤ten mit begrenzten Ressourcen (Edge-GerÃ¤te) oder kostengÃ¼nstigen Servern.
- Anwendungen, die eine schnelle Inferenz mit guten Reasoning-FÃ¤higkeiten erfordern.
- Agenten-AnwendungsfÃ¤lle mit Funktionsaufrufen, Web-Navigation und Code-Execution.
- Fine-Tuning fÃ¼r spezialisierte Aufgaben auf AlltagsgerÃ¤ten.



### qwen3:14b
**Qwen Team â€¢ 14B Parameter â€¢ Kontext: 32.000 Tokens**

Neues Dichtemodell der nÃ¤chsten Generation Qwen3 (14B), das Leistungen bietet, die denen von Qwen2.5 32B entsprechen, mit besserer Effizienz.

**Technische Spezifikationen :**
- **Geschwindigkeit** : 40 Tokens/Sekunde âš¡
- **Verbrauch** : 3,33 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten :**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âœ… Reasoning â€¢ âŒ Sicherheit

**Tags :** `Agent` `Reasoning` `Schnell` `Mehrsprachig`

**AnwendungsfÃ¤lle :**
- Allgemeine Aufgaben, die Leistung und einen groÃŸen Kontext erfordern
- Erstellung kreativer und technischer Inhalte
- Datenanalyse und komplexes Denken
- Integration mit externen Tools Ã¼ber Function Calling



### gemma3:12b  
**Google â€¢ 12B Parameter â€¢ Kontext: 120.000 Tokens**  

Mittlere Version des Gemma 3-Modells, die ein hervorragendes Gleichgewicht zwischen Leistung und Effizienz bietet.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 56 Tokens pro Sekunde âš¡  
- **Verbrauch:** 4,71 kWh pro Million Tokens  
- **Lizenz:** Google Gemma Nutzungsbedingungen  
- **Standort:** FR ğŸ‡«ğŸ‡·  

**FÃ¤higkeiten:**  
âŒ Tools/Agent â€¢ âœ… Vision â€¢ âŒ Reasoning â€¢ âŒ Sicherheit  

**Tags:** `Vision` `Schnell` `GroÃŸer Kontext`  

**AnwendungsfÃ¤lle:**  
- Multimodale Anwendungen mit moderaten RessourcenbeschrÃ¤nkungen  
- Dokumentenverarbeitung mit Standardkontext (bis zu 100 Seiten)  
- Textinhaltsgenerierung und kombinierte Bildanalyse  
- Bereitstellung auf Standard-GPUs ohne spezialisierte Infrastruktur  
- Fortgeschrittene Chatbots mit integrierten visuellen und textuellen FÃ¤higkeiten



### gemma3:4b  
**Google â€¢ 4B Parameter â€¢ Kontext: 120.000 Tokens**  

Kompakter Google-Modell mit hervorragenden Leistungen in einem leichtgewichtigen und kosteneffizienten Format.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 57 Tokens/Sekunde âš¡  
- **Verbrauch** : 0,58 kWh pro Million Tokens ğŸŒ±  
- **Lizenz** : Google Gemma Nutzungsbedingungen  
- **Standort** : FR ğŸ‡«ğŸ‡·  

**FÃ¤higkeiten:**  
âŒ Tools/Agent â€¢ âœ… Vision â€¢ âŒ BegrÃ¼ndung â€¢ âŒ Sicherheit  

**Tags:** `Vision` `Schnell` `Kompakt` `GroÃŸer Kontext` `Effizient`  

**AnwendungsfÃ¤lle:**  
- Eingebettete Anwendungen und Edge Computing mit Bildverarbeitung  
- Multimodale Chatbots mit geringer Latenz  
- Skalierbare Deployment mit visuellen und textuellen FÃ¤higkeiten  
- Mobile Anwendungen mit Bild- und Textanalyse  
- Verarbeitung visueller Anfragen mit mittlerer bis hoher KomplexitÃ¤t und hoher LeistungsfÃ¤higkeit



### gemma3:1b
**Google â€¢ 1B Parameter â€¢ Kontext: 32.000 Tokens**

Ultra-leichter Mikro-Modell fÃ¼r Deployment auf GerÃ¤ten mit sehr geringen Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 112 Tokens/Sekunde âš¡
- **Verbrauch** : 0,15 kWh pro Million Tokens ğŸŒ±
- **Lizenz** : Google Gemma Nutzungsbedingungen
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âŒ Tools/Agent â€¢ âŒ Vision â€¢ âŒ Reasoning â€¢ âŒ Sicherheit

**Tags:** `Ultra-kompakt` `Eingebettet` `Effizient` `Schnell`

**AnwendungsfÃ¤lle:**
- Deployment auf IoT-GerÃ¤ten und eingebetteten Systemen mit API-Integration
- Anwendungen, die lokale Inferenz auf CPU mit Funktionsaufrufen erfordern
- Grundlegende Textaufgaben mit sofortiger Antwortzeit und Funktionsaufruf
- Kompakte Assistenten fÃ¼r Endverbraucher-Anwendungen mit externen Dienstintegration
- Intelligente Steuersysteme, die mehrere APIs/Dienste integrieren



### lucie-instruct:7b
**OpenLLM-France â€¢ 7B Parameter â€¢ Kontext: 32.000 Tokens**

Kausales multilinguales Open-Source-Modell (7B), fine-tuned von Lucie-7B. Optimiert fÃ¼r FranzÃ¶sisch.

**Technische Spezifikationen :**
- **Geschwindigkeit** : 4 Tokens/Sekunde
- **Verbrauch** : 8,33 kWh pro Million Tokens ğŸŒ±
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten :**
âŒ Tools/Agent â€¢ âŒ Vision â€¢ âŒ Reasoning â€¢ âŒ Sicherheit

**Tags :** `FranzÃ¶sisch` `Open-Source` `Effizient`



### mistral-small3.1:24b
**Mistral AI â€¢ 24B Parameter â€¢ Kontext: 120.000 Tokens**

Kompakter und reaktiver Modell von Mistral AI, speziell entwickelt, um eine flÃ¼ssige und relevante ConversationsunterstÃ¼tzung mit optimaler Antwortgeschwindigkeit zu bieten.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 35 Tokens pro Sekunde
- **Verbrauch** : 3,72 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âœ… Vision â€¢ âŒ Reasoning â€¢ âœ… Sicherheit

**Tags:** `Vision` `Agent` `Sicherheit`

**AnwendungsfÃ¤lle:**
- Konversationale Anwendungen
- Virtuelle Assistenten mit Bild- und Textanalyse (26 Tokens/s)
- Technische Support-Chatbots mit Zugriff auf technische Dokumentation
- Tools zur Inhaltserstellung/Bearbeitung mit sofortiger Antwort (Blogs, E-Mails)
- Bereitstellung auf Standardinfrastrukturen (24B Parameter)



### mistral-small3.2:24b
**Mistral AI â€¢ 24B Parameter â€¢ Kontext: 120.000 Tokens**

Kleine Aktualisierung von Mistral Small 3.1, die die Anweisungsbefolgung, die Robustheit des Function Calls und die Wiederholungsfehler reduziert.

**Technische Spezifikationen :**
- **Geschwindigkeit** : 35 Tokens/Sekunde
- **Verbrauch** : 3,72 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten :**
âœ… Tools/Agent â€¢ âœ… Vision â€¢ âŒ Reasoning â€¢ âœ… Sicherheit

**Tags :** `Vision` `Agent` `Sicherheit` `Anweisungsbefolgung`

**AnwendungsfÃ¤lle :**
- Konversationelle Agenten mit verbesserter Anweisungsbefolgung
- Robuste Integration mit externen Tools Ã¼ber Function Calls
- Anwendungen, die eine groÃŸe ZuverlÃ¤ssigkeit erfordern, um Wiederholungen zu vermeiden
- Identische AnwendungsfÃ¤lle wie bei Mistral Small 3.1 mit verbesserten Leistungen



### deepcoder:14b  
**Agentica x Together AI â€¢ 14B Parameter â€¢ Kontext: 32.000 Tokens**  

Open-Source-IA-Modell (14B) von Together AI & Agentica, glaubwÃ¼rdige Alternative zu proprietÃ¤ren Modellen fÃ¼r die Codegenerierung.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 64 Tokens/Sekunde âš¡  
- **Verbrauch** : 4,12 kWh/Million Tokens  
- **Lizenz** : Apache 2.0  
- **Standort** : FR ğŸ‡«ğŸ‡·  

**FÃ¤higkeiten:**  
âŒ Tools/Agent â€¢ âŒ Vision â€¢ âœ… Reasoning â€¢ âŒ Sicherheit  

**Tags:** `Programmierung` `Reasoning` `Open-Source` `Mathematik` `Schnell`  

**AnwendungsfÃ¤lle:**  
- Codegenerierung in mehr als 15 Sprachen mit Leistungsoptimierung  
- Debugging und Refaktorisierung bestehender Code-Basen mit Auswirkungsanalyse  
- Implementierung komplexer Algorithmen (Graphen, BÃ¤ume, Heuristiken)  
- Automatisierte Erstellung von Einheitstests mit Codeabdeckung > 80%  
- CodeÃ¼bersetzung zwischen Sprachen/Frameworks (z. B. Python zu JavaScript)



### granite3.2-vision:2b
**IBM â€¢ 2B Parameter â€¢ Kontext: 16.384 Tokens**

RevolutionÃ¤res kompaktes Modell von IBM, spezialisiert auf Computer Vision, das visuelle Dokumente direkt analysieren und verstehen kann, ohne auf Zwischentechnologien wie OCR zurÃ¼ckzugreifen.

**Technische Spezifikationen :**
- **Geschwindigkeit** : 48 Tokens/Sekunde
- **Verbrauch** : 0,69 kWh pro Million Tokens ğŸŒ±
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten :**
âœ… Tools/Agent â€¢ âœ… Vision â€¢ âŒ Reasoning â€¢ âœ… Sicherheit

**Tags :** `Vision` `Sicherheit` `Kompakt` `Effizient`

**AnwendungsfÃ¤lle :**
- Strukturierte Datenextraktion aus Rechnungen und Formularen ohne OCR
- Direkte Analyse von Tabellen und Grafiken mit Trendinterpretation
- Lesen und Interpretieren technischer Diagramme (elektrisch, mechanisch)
- Verarbeitung handschriftlicher Dokumente mit hohem Erkennungsraten
- Leichte Computer Vision (2B Parameter) mit hoher Geschwindigkeit (50 Tokens/Sekunde)



### granite3.3:8b
**IBM â€¢ 8B Parameter â€¢ Kontext: 60.000 Tokens**

Granite-Modell mit 8B Parametern, feinabgestimmt von IBM fÃ¼r verbessertes Reasoning und Anweisungsbefolgung, mit einem Kontext von 128k Tokens.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 30 Tokens/Sekunde Tokens/Sekunde
- **Verbrauch** : 1,11 kWh pro Million Tokens ğŸŒ±
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âœ… Reasoning â€¢ âœ… Sicherheit

**Tags:** `Agent` `Reasoning` `Sicherheit` `Effizient`

**AnwendungsfÃ¤lle:**
- Allgemeine Anweisungsbefolgungsaufgaben (Klassifizierung, Extraktion, Q&A)
- Mehrsprachige KI-Assistenten (12 Sprachen)
- Verarbeitung sehr langer Dokumente (128k Tokens) fÃ¼r Aufgaben wie Zusammenfassungen, Q&A,...
- Codegenerierung/VervollstÃ¤ndigung mit Fill-in-the-Middle
- Integration mit externen Tools Ã¼ber Function Calling
- Strukturierter Reasoning im "Thinking"-Modus



### granite3.3:2b
**IBM â€¢ 2B Parameter â€¢ Kontext: 128.000 Tokens**

Feinabgestimmtes Granite 2B-Modell von IBM, optimiert fÃ¼r Reasoning und Anweisungsbefolgung mit einem Kontext von 128k Tokens.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 45 Tokens/Sekunde
- **Verbrauch** : 0.74 kWh pro Million Tokens ğŸŒ±
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âœ… Reasoning â€¢ âœ… Sicherheit

**Tags:** `Agent` `Reasoning` `Sicherheit` `Effizient`

**AnwendungsfÃ¤lle:**
- Leichte Deployment mit groÃŸem Kontext (128k Tokens)
- Allgemeine Anweisungsbefolgungsaufgaben auf begrenzten Ressourcen
- Kompakte multilinguale KI-Assistenten
- Verarbeitung langer Dokumente auf weniger leistungsstarken GerÃ¤ten
- FIM-Codegenerierung/Completions auf StandardarbeitsplÃ¤tzen



### magistral:24b  
**Mistral AI â€¢ 24B Parameter â€¢ Kontext: 40.000 Tokens**  

Das erste Reasoning-Modell von Mistral AI, das sich durch domainsspezifisches Reasoning, Transparenz und Mehrsprachigkeit auszeichnet.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 25 Tokens pro Sekunde  
- **Verbrauch** : 5,33 kWh pro Million Tokens  
- **Lizenz** : Apache 2.0  
- **Standort** : FR ğŸ‡«ğŸ‡·  

**FÃ¤higkeiten:**  
âŒ Tools/Agent â€¢ âŒ Vision â€¢ âœ… Reasoning â€¢ âœ… Sicherheit  

**Tags:** `Reasoning` `Mehrsprachig`  

**AnwendungsfÃ¤lle:**  
- Strategie und GeschÃ¤ftsbetrieb (Risikomodellierung)  
- Regulierten Branchen (Recht, Finanzen) mit nachvollziehbarem Reasoning  
- Softwareentwicklung (Projektplanung, Architektur)  
- Inhaltserstellung und Kommunikation (kreative Schreibweise, ErzÃ¤hlung)



### granite3.1-moe:3b
**IBM â€¢ 3B Parameter â€¢ Kontext: 32.000 Tokens**

Innovatives Modell von IBM, das die Mixture-of-Experts-Architektur (MoE) verwendet, um auÃŸergewÃ¶hnliche Leistungen zu bieten und die Nutzung der Rechenressourcen drastisch zu optimieren.

**Technische Spezifikationen :**
- **Geschwindigkeit** : 74 Tokens/Sekunde âš¡
- **Verbrauch** : 0,45 kWh pro Million Tokens ğŸŒ±
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten :**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âŒ Reasoning â€¢ âœ… Sicherheit

**Tags :** `Agent` `Sicherheit` `Schnell` `MoE` `Effizienz` `Effizient`

**AnwendungsfÃ¤lle :**
- Allgemeine Anwendungen mit optimierten Inferenzkosten (42 Tokens/Sekunde)
- Dokumentenverarbeitung in CPU-Umgebungen mit begrenzter RAM-Nutzung
- Spezialanalysen mit dynamischer Aktivierung relevanter Modellteile
- Hochdichte-Deployment mit geringem Energieverbrauch pro Inferenz
- Parallele Verarbeitung mehrerer Anfragentypen mit MoE-Spezialisierung



### cogito:14b  
**Deep Cogito â€¢ 14B Parameter â€¢ Kontext: 32.000 Tokens**  

Modell von Deep Cogito, speziell fÃ¼r tiefes Denken und feine kontextuelle VerstÃ¤ndnis entwickelt, ideal fÃ¼r anspruchsvolle analytische Anwendungen.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 60 Tokens pro Sekunde âš¡  
- **Verbrauch** : 4,4 kWh pro Million Tokens  
- **Lizenz** : LLAMA 3.2 Community Lizenz  
- **Standort** : FR ğŸ‡«ğŸ‡·  

**FÃ¤higkeiten:**  
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âœ… Reasoning â€¢ âŒ Sicherheit  

**Tags:** `Agent` `Reasoning` `VerstÃ¤ndnis` `Analyse` `Schnell`  

**AnwendungsfÃ¤lle:**  
- Semantische Analyse von Texten mit Identifizierung impliziter Implikationen  
- Strukturierter kausaler Schlussfolgerung mit Identifizierung ursÃ¤chlicher Beziehungen  
- Zusammenfassung komplexer Dokumente mit Extraktion der SchlÃ¼sselinformationen  
- PrÃ¤zise Frage-Antwort-Systeme fÃ¼r spezialisierte Dokumentenkorpora  
- Argumentative Analyse mit Bewertung der StÃ¤rke der Schlussfolgerungen



### cogito:32b  
**Deep Cogito â€¢ 32B Parameter â€¢ Kontext: 32.000 Tokens**  

Erweiterte Version des Cogito-Modells mit erheblich verstÃ¤rkten Reasoning- und AnalysefÃ¤higkeiten, konzipiert fÃ¼r die anspruchsvollsten Anwendungen im Bereich analytischer KI.  

**Technische Spezifikationen:**  
- **Geschwindigkeit** : 32 Tokens/Sekunde Tokens/Sekunde  
- **Verbrauch** : 8,25 kWh pro Million Tokens  
- **Lizenz** : LLAMA 3.2 Community Lizenz  
- **Standort** : FR ğŸ‡«ğŸ‡·  

**FÃ¤higkeiten:**  
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âœ… Reasoning â€¢ âŒ Sicherheit  

**Tags:** `Agent` `Reasoning` `VerstÃ¤ndnis` `Analyse`  

**AnwendungsfÃ¤lle:**  
- Analyse von Multi-Faktor-Szenarien mit probabilistischer Ergebnisevaluation  
- LÃ¶sung wissenschaftlicher Probleme mit formaler Schritt-Demonstration  
- Hochkritische Anwendungen, die Genauigkeit und Verifizierbarkeit der Ergebnisse erfordern  
- Expertensysteme in spezialisierten Bereichen (rechtlich, medizinisch, technisch)  
- Analyse mit mehrstufigem Reasoning und vollstÃ¤ndiger ErklÃ¤rbarkeit der Schlussfolgerungen



### qwen3:32b
**Qwen Team â€¢ 32B Parameter â€¢ Kontext: 40.000 Tokens**

Leistungsstarker Modell der neuen Qwen3-Generation mit fortgeschrittenen FÃ¤higkeiten im Bereich Reasoning, Code und Agententechnologie, mit erweitertem Kontext.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 18 Tokens/Sekunde
- **Verbrauch** : 7,41 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âœ… Reasoning â€¢ âŒ Sicherheit

**Tags:** `Agent` `Reasoning` `Mehrsprachig` `GroÃŸer Kontext`

**AnwendungsfÃ¤lle:**
- Fortgeschrittene conversationelle Agenten mit groÃŸem Kontext und Integration von Tools (MCP)
- LÃ¶sung komplexer Probleme (Mathematik, Code) im "Thinking"-Modus
- Analyse und Generierung umfangreicher Dokumente
- Mehrsprachige Anwendungen (>100 Sprachen), die eine tiefe VerstÃ¤ndnisfÃ¤higkeit erfordern



### qwq:32b
**Qwen Team â€¢ 32B Parameter â€¢ Kontext: 32.000 Tokens**

Modell mit 32 Milliarden Parametern, optimiert durch VerstÃ¤rkungslernen (RL), um sich in Reasoning, Codierung, Mathematik und Agent-Aufgaben hervorzutun.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 35 Tokens pro Sekunde
- **Verbrauch** : 7,54 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âœ… Reasoning â€¢ âŒ Sicherheit

**Tags:** `Agent` `Reasoning` `Codierung` `Mathematik`

**AnwendungsfÃ¤lle:**
- LÃ¶sung komplexer Probleme, die Reasoning und Nutzung von Tools erfordern
- Erstellung und AusfÃ¼hrung von Code mit ErgebnisprÃ¼fung
- Fortgeschrittene mathematische Aufgaben mit GenauigkeitsprÃ¼fung
- Agent-Anwendungen, die mit der Umgebung interagieren kÃ¶nnen
- Verbessertes Instruction Following und Ausrichtung auf menschliche PrÃ¤ferenzen



### deepseek-r1:14b
**DeepSeek AI â€¢ 14B Parameter â€¢ Kontext: 32.000 Tokens**

Kompakte und effiziente Version des DeepSeek-R1-Modells, die ein hervorragendes Gleichgewicht zwischen Leistung und Leichtigkeit bietet fÃ¼r Deployment, die FlexibilitÃ¤t und ReaktivitÃ¤t erfordern.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 62 Tokens/Sekunde âš¡
- **Verbrauch** : 4,26 kWh/Million Tokens
- **Lizenz** : MIT-Lizenz
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âŒ Tools/Agent â€¢ âŒ Vision â€¢ âœ… Reasoning â€¢ âŒ Sicherheit

**Tags:** `Reasoning` `Kompakt` `Vielseitig` `Schnell`

**AnwendungsfÃ¤lle:**
- Allgemeine Anwendungen mit Bedarf an schneller Inferenz (44 Tokens/s)
- Deployment auf Standard-Server ohne spezialisierte GPU (14B Parameter)
- Textverarbeitung mit kontextueller Analyse und schneller Antwortzeit
- Deployment im Edge Computing mit lokaler Optimierung der Inferenz
- Schnelle Prototypentwicklung von KI-Anwendungen mit kurzer Iterationszeit



### deepseek-r1:32b
**DeepSeek AI â€¢ 32B Parameter â€¢ Kontext: 32.000 Tokens**

Zwischenversion des DeepSeek-R1-Modells, die ein strategisches Gleichgewicht zwischen den fortgeschrittenen FÃ¤higkeiten der 70B-Version und der Effizienz der 14B-Version bietet, fÃ¼r eine vielseitige und optimale Leistung.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 33 Tokens pro Sekunde
- **Verbrauch:** 7,99 kWh pro Million Tokens
- **Lizenz:** MIT-Lizenz
- **Standort:** FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âŒ Tools/Agent â€¢ âŒ Vision â€¢ âœ… Reasoning â€¢ âŒ Sicherheit

**Tags:** `Reasoning` `Vielseitig`

**AnwendungsfÃ¤lle:**
- Anwendungen, die ein gutes Leistungs-Kosten-VerhÃ¤ltnis benÃ¶tigen (32B Parameter)
- Professionelle Textverarbeitung mit Analyse der semantischen Nuancen
- Automatisierte Generierung strukturierter Berichte aus Rohdaten
- Anwendungen, die Datenanalyse und Inhaltsgenerierung kombinieren
- Spezialisierte Assistenten fÃ¼r technische Bereiche (rechtlich, medizinisch, technisch)



### cogito:3b
**Deep Cogito â€¢ 3B Parameter â€¢ Kontext: 32.000 Tokens**

Kompakte Version des Cogito-Modells, optimiert fÃ¼r das Denken auf GerÃ¤ten mit begrenzten Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 55 Tokens/Sekunde âš¡
- **Verbrauch** : 0,61 kWh pro Million Tokens ğŸŒ±
- **Lizenz** : LLAMA 3.2 Community Lizenz
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âœ… Denken â€¢ âŒ Sicherheit

**Tags:** `Denken` `Kompakt` `Eingebettet` `Effizient` `Schnell`



### granite-embedding:278m
**IBM â€¢ 278M Parameter â€¢ Kontext: 512 Tokens**

Ultraleichter IBM-Embedding-Modell fÃ¼r semantische Suche und Klassifizierung.

**Technische Spezifikationen:**
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âŒ Tools/Agent â€¢ âŒ Vision â€¢ âŒ Reasoning â€¢ âŒ Sicherheit

**Tags:** `Embedding` `Kompakt` `Semantisch` `Effizient`



### granite3-guardian:2b
**IBM â€¢ 2B Parameter â€¢ Kontext: 8192 Tokens**

Kompakter IBM-Modell, spezialisiert auf Sicherheit und Compliance, das Risiken und unangemessene Inhalte erkennt.

**Technische Spezifikationen:**
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âŒ Tools/Agent â€¢ âŒ Vision â€¢ âŒ Reasoning â€¢ âœ… Sicherheit

**Tags :** `Sicherheit` `Compliance` `Kompakt` `Filterung` `Effizient`



### granite3-guardian:8b  
**IBM â€¢ 8B Parameter â€¢ Kontext: 32.000 Tokens**  

IBM-Modell, spezialisiert auf Sicherheit und Compliance, mit fortgeschrittenen FÃ¤higkeiten zur Risikodetektion.  

**Technische Spezifikationen:**  
- **Lizenz** : Apache 2.0  
- **Standort** : FR ğŸ‡«ğŸ‡·  

**FÃ¤higkeiten:**  
âŒ Tools/Agent â€¢ âŒ Vision â€¢ âŒ Reasoning â€¢ âœ… Sicherheit  

**Tags :** `Sicherheit` `Compliance` `Filterung`



### qwen2.5:0.5b
**Qwen Team â€¢ 0,5 B Parameter â€¢ Kontext: 32.000 Tokens**

Ultra-leichter Mikro-Modell der Qwen 2.5-Familie, optimiert fÃ¼r maximale Effizienz auf eingeschrÃ¤nkten GerÃ¤ten.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 162 Tokens/Sekunde âš¡
- **Verbrauch** : 0,1 kWh pro Million Tokens ğŸŒ±
- **Lizenz** : MIT-Lizenz
- **Lokalisierung** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âŒ BegrÃ¼ndung â€¢ âŒ Sicherheit

**Tags:** `Ultra-kompakt` `Schnell` `Eingebettet` `Effizient`



### qwen2.5:1.5b
**Qwen Team â€¢ 1.5B Parameter â€¢ Kontext: 32.000 Tokens**

Sehr kompakter Modell der Qwen 2.5-Familie mit einem guten Leistungs-/GrÃ¶ÃŸengleichgewicht fÃ¼r leichte Bereitstellungen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 102 Tokens pro Sekunde âš¡
- **Verbrauch** : 0,33 kWh pro Million Tokens ğŸŒ±
- **Lizenz** : MIT-Lizenz
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âŒ BegrÃ¼ndung â€¢ âŒ Sicherheit

**Tags:** `Kompakt` `Schnell` `Eingebettet` `Effizient`



### qwen2.5:14b
**Qwen Team â€¢ 14B Parameter â€¢ Kontext: 32.000 Tokens**

Vielseitiges Modell mittlerer GrÃ¶ÃŸe der Qwen 2.5-Familie mit einem guten Leistungs-/RessourcenverhÃ¤ltnis.

**Technische Spezifikationen :**
- **Geschwindigkeit** : 61 Tokens/Sekunde âš¡
- **Verbrauch** : 4,33 kWh pro Million Tokens
- **Lizenz** : MIT-Lizenz
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten :**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âŒ BegrÃ¼ndung â€¢ âŒ Sicherheit

**Tags :** `Vielseitig` `Mehrsprachig` `Schnell`



### qwen2.5:32b
**Qwen Team â€¢ 32B Parameter â€¢ Kontext: 32.000 Tokens**

Leistungsstarker Modell der Qwen 2.5-Familie mit fortgeschrittenen FÃ¤higkeiten in VerstÃ¤ndnis und Generierung.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 31 Tokens/Sekunde
- **Verbrauch** : 8,51 kWh/Million Tokens
- **Lizenz** : MIT-Lizenz
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âœ… Reasoning â€¢ âŒ Sicherheit

**Tags:** `Vielseitig` `Mehrsprachig` `Reasoning`



### qwen2.5:3b
**Qwen Team â€¢ 3B Parameter â€¢ Kontext: 32.000 Tokens**

Kompakter und effizienter Modell der Qwen 2.5-Familie, geeignet fÃ¼r allgemeine Aufgaben bei begrenzten Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 64 Tokens pro Sekunde âš¡
- **Verbrauch** : 0,52 kWh pro Million Tokens ğŸŒ±
- **Lizenz** : MIT-Lizenz
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âŒ BegrÃ¼ndung â€¢ âŒ Sicherheit

**Tags:** `Kompakt` `Schnell` `Vielseitig` `Effizient`



### qwen3:0.6b
**Qwen Team â€¢ 0,6B Parameter â€¢ Kontext: 32.000 Tokens**

Kompakter und effizienter Modell der Qwen3-Familie, geeignet fÃ¼r allgemeine Aufgaben auf begrenzten Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 112 Tokens pro Sekunde âš¡
- **Verbrauch** : 0,15 kWh pro Million Tokens ğŸŒ±
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Werkzeuge/Agent â€¢ âŒ Vision â€¢ âŒ BegrÃ¼ndung â€¢ âŒ Sicherheit

**Tags:** `Kompakt` `Schnell` `Vielseitig` `Effizient`



### qwen3:1.7b  
**Qwen Team â€¢ 1,7B Parameter â€¢ Kontext: 32.000 Tokens**  

Ein sehr kompakter Modell der Qwen3-Familie, der ein gutes Leistungs-/GrÃ¶ÃŸenverhÃ¤ltnis fÃ¼r leichte Deployment-Anwendungen bietet.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 88 Tokens pro Sekunde âš¡  
- **Verbrauch:** 0,38 kWh pro Million Tokens ğŸŒ±  
- **Lizenz:** Apache 2.0  
- **Standort:** FR ğŸ‡«ğŸ‡·  

**FÃ¤higkeiten:**  
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âŒ Reasoning â€¢ âŒ Sicherheit  

**Tags:** `Kompakt` `Schnell` `Eingebettet` `Effizient`



### qwen3:4b
**Qwen Team â€¢ 4B Parameter â€¢ Kontext: 32.000 Tokens**

Kompakter Modell der Qwen3-Familie mit hervorragenden Leistungen in einem leichtgewichtigen und wirtschaftlichen Format.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 49 Tokens/Sekunde
- **Verbrauch** : 0,68 kWh pro Million Tokens ğŸŒ±
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âŒ Reasoning â€¢ âŒ Sicherheit

**Tags :** `Kompakt` `Effizient`



### qwen3-2507-think:4b
**Qwen Team â€¢ 4B Parameter â€¢ Kontext: 250.000 Tokens**

Qwen3-4B-Modell optimiert fÃ¼r Reasoning mit verbesserten Leistungen bei logischen Aufgaben, Mathematik, Wissenschaft und Code sowie einem erweiterten Kontext von 250.000 Tokens.

**Technische Spezifikationen:**
- **Geschwindigkeit:** 70 Tokens pro Sekunde âš¡
- **Verbrauch:** 1,9 kWh pro Million Tokens
- **Lizenz:** Apache 2.0
- **Standort:** FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âœ… Reasoning â€¢ âŒ Sicherheit

**Tags:** `Agent` `Reasoning` `GroÃŸer Kontext` `Kompakt` `Schnell`

**AnwendungsfÃ¤lle:**
- Sehr komplexe Reasoning-Aufgaben (Logik, Mathematik, Wissenschaft, Code).
- Konversationelle Agenten mit sehr umfangreichen Chat-VerlÃ¤ufen (256k Tokens).
- Analyse sehr umfangreicher Dokumente mit tiefem Reasoning.
- Integration mit externen Tools Ã¼ber Function Calling auf sehr groÃŸen Kontexten.



### qwen3-2507:4b  
**Qwen Team â€¢ 4B Parameter â€¢ Kontext: 250.000 Tokens**  

Aktualisierte Version des Nicht-denken-Modus von Qwen3-4B mit erheblichen Verbesserungen der allgemeinen FÃ¤higkeiten, erweiterter Wissensabdeckung und besserer Ausrichtung auf BenutzerprÃ¤ferenzen.  

**Technische Spezifikationen:**  
- **Geschwindigkeit:** 70 Tokens pro Sekunde âš¡  
- **Verbrauch:** 1,9 kWh pro Million Tokens  
- **Lizenz:** Apache 2.0  
- **Standort:** FR ğŸ‡«ğŸ‡·  

**FÃ¤higkeiten:**  
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âŒ Reasoning â€¢ âŒ Sicherheit  

**Tags:** `Agent` `GroÃŸer Kontext` `Kompakt` `Schnell` `Mehrsprachig`  

**AnwendungsfÃ¤lle:**  
- Allgemeine Aufgaben, die eine prÃ¤zise Befolgung von Anweisungen und logisches Denken erfordern.  
- Mehrsprachige Anwendungen mit umfassender Wissensabdeckung.  
- Hochwertige Textgenerierung fÃ¼r offene und subjektive Aufgaben.  
- Analyse sehr umfangreicher Dokumente dank des 256k-Token-Kontexts.



### qwen3:8b
**Qwen Team â€¢ 8B Parameter â€¢ Kontext: 32.000 Tokens**

Qwen3 8B Modell, das ein gutes Gleichgewicht zwischen Leistung und Effizienz fÃ¼r allgemeine Aufgaben bietet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 33 Tokens/Sekunde Tokens/Sekunde
- **Verbrauch** : 1,01 kWh pro Million Tokens ğŸŒ±
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âœ… Reasoning â€¢ âŒ Sicherheit

**Tags:** `Reasoning` `Agent` `Mehrsprachig` `Effizient`



### qwen2.5vl:3b
**Qwen Team â€¢ 3,8 Milliarden Parameter â€¢ Kontext: 128.000 Tokens**

Kompakter Vision-Text-Modell, leistungsstarke LÃ¶sung fÃ¼r Edge AI (Edge-Intelligenz).

**Technische Spezifikationen:**
- **Geschwindigkeit** : 65 Tokens/Sekunde âš¡
- **Verbrauch** : 0,51 kWh pro Million Tokens ğŸŒ±
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âœ… Vision â€¢ âœ… Reasoning â€¢ âŒ Sicherheit

**Tags :** `Vision` `Agent` `Reasoning` `Schnell` `Effizient` `OCR` `Visuelle Lokalisierung` `Edge AI`



### qwen2.5vl:7b
**Qwen Team â€¢ 7B (8,3B) Parameter â€¢ Kontext: 128.000 Tokens**

Leistungsstarkes Vision-Sprachmodell, das GPT-4o-mini bei bestimmten Aufgaben Ã¼bertreffen kann.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 35 Tokens/Sekunde
- **Verbrauch** : 0,95 kWh pro Million Tokens ğŸŒ±
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âœ… Vision â€¢ âœ… Reasoning â€¢ âŒ Sicherheit

**Tags:** `Vision` `Agent` `Reasoning` `Effizient` `OCR` `Visuelle Lokalisierung`



### hf.co/roadus/Foundation-Sec-8B-Q4_K_M-GGUF:Q4_K_M
**Foundation AI â€” Cisco â€¢ 8B Parameter â€¢ Kontext: 16.384 Tokens**

Spezialmodell fÃ¼r Cybersecurity, optimiert fÃ¼r Effizienz.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 21 Tokens pro Sekunde
- **Verbrauch** : 1,59 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âŒ Tools/Agent â€¢ âŒ Vision â€¢ âœ… Reasoning â€¢ âœ… Sicherheit

**Tags:** `Sicherheit` `Kompakt`



### devstral:24b
**Mistral AI & All Hands AI â€¢ 24B Parameter â€¢ Kontext: 120.000 Tokens**

Devstral ist ein LLM-Agent fÃ¼r Software-Engineering-Aufgaben.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 45 Tokens pro Sekunde
- **Verbrauch** : 5,86 kWh pro Million Tokens
- **Lizenz** : Apache 2.0
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âŒ Reasoning â€¢ âœ… Sicherheit

**Tags:** `Agent` `Programmierung` `Open-Source` `GroÃŸer Kontext`

**AnwendungsfÃ¤lle:**
- Exploration und Ã„nderung von Code-Basen
- Agentic
- EuropÃ¤isch



### cogito:8b
**Deep Cogito â€¢ 8B Parameter â€¢ Kontext: 32.000 Tokens**

Mittleres Modell der Cogito-Familie, das ein gutes Gleichgewicht zwischen DenkfÃ¤higkeiten und Effizienz bietet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 30 Tokens/Sekunde
- **Verbrauch** : 1,11 kWh pro Million Tokens ğŸŒ±
- **Lizenz** : LLAMA 3.2 Community Lizenz
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âœ… Tools/Agent â€¢ âŒ Vision â€¢ âœ… Reasoning â€¢ âŒ Sicherheit

**Tags:** `Agent` `Reasoning` `Vielseitig` `Effizient`



### llama3.1:8b
**Meta â€¢ 8B Parameter â€¢ Kontext: 32.000 Tokens**

Grundmodell der Llama 3.1-Familie mit soliden Leistungen fÃ¼r seine GrÃ¶ÃŸe.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 31 Tokens pro Sekunde
- **Verbrauch** : 1,08 kWh pro Million Tokens ğŸŒ±
- **Lizenz** : LLAMA 3.1 Community Lizenz
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âŒ Werkzeuge/Agent â€¢ âŒ Sehen â€¢ âŒ BegrÃ¼ndung â€¢ âŒ Sicherheit

**Tags:** `Vielseitig` `Effizient`



### phi4-reasoning:14b
**Microsoft â€¢ 14B Parameter â€¢ Kontext: 32.000 Tokens**

Modell der Phi-Familie von Microsoft, spezialisiert auf komplexes Denken und Mathematik.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 71 Tokens/Sekunde âš¡
- **Verbrauch** : 3,71 kWh pro Million Tokens
- **Lizenz** : MIT Lizenz
- **Standort** : FR ğŸ‡«ğŸ‡·

**FÃ¤higkeiten:**
âŒ Tools/Agent â€¢ âŒ Vision â€¢ âœ… Denken â€¢ âŒ Sicherheit

**Tags :** `Denken` `Mathematik` `Programmierung` `Schnell`



## Empfohlene AnwendungsfÃ¤lle



### Mehrsprachiger Dialog
Chatbots und Assistenten, die in mehreren Sprachen kommunizieren kÃ¶nnen, mit automatischer Spracherkennung, Erhaltung des Kontexts Ã¼ber die gesamte Unterhaltung hinweg und VerstÃ¤ndnis der sprachlichen Besonderheiten

**Empfohlene Modelle:**
- Llama 3.3
- Mistral Small 3.2
- Qwen 3
- Granite 3.3



### Analyse von langen Dokumenten  
Verarbeitung von umfangreichen Dokumenten (mehr als 100 Seiten) mit Kontextbeibehaltung Ã¼ber den gesamten Text, Extraktion von SchlÃ¼sselinformationen, Generierung relevanter Zusammenfassungen und Beantwortung spezifischer Fragen zum Inhalt  

**Empfohlene Modelle:**  
- Gemma 3  
- Qwen3  
- Granite 3.3



### Programmierung und Entwicklung  
Erstellung und Optimierung von Code in mehreren Sprachen, Debuggen, Refactoring, Entwicklung vollstÃ¤ndiger Funktionen, VerstÃ¤ndnis komplexer algorithmischer Implementierungen und Erstellung von Einheitstests  

**Empfohlene Modelle:**  
- DeepCoder  
- QwQ  
- Qwen3 coder  
- Granite 3.3  
- Devstral



### Visuelle Analyse  
Direkter Umgang mit Bildern und visuellen Dokumenten ohne vorherige OCR-Verarbeitung, Interpretation technischer Diagramme, Grafiken, Tabellen, Zeichnungen und Fotos mit Erstellung detaillierter textueller ErklÃ¤rungen des visuellen Inhalts  

**Empfohlene Modelle:**  
- Granite 3.2 Vision  
- Mistral Small 3.2  
- Gemma 3  
- Qwen2.5-VL



### Sicherheit und Compliance
Anwendungen, die spezifische Sicherheitsfunktionen erfordern; sensibler Inhalt filtern, Nachvollziehbarkeit der Schlussfolgerungen, GDPR/HDS-PrÃ¼fung, Risikominimierung, Schwachstellenanalyse und Einhaltung branchenspezifischer Vorschriften

**Empfohlene Modelle:**
- Granite Guardian
- Granite 3.3
- Devstral
- Mistral Small 3.1
- Magistral 24b
- Foundation-Sec-8B



### Leichte und eingebettete Bereitstellungen  
Anwendungen mit minimalem Ressourcenbedarf, Bereitstellung auf GerÃ¤ten mit begrenzter KapazitÃ¤t, Echtzeit-Infereenz auf Standard-CPU und Integration in eingebettete Systeme oder IoT  

**Empfohlene Modelle:**  
- Gemma 3  
- Granite 3.1 MoE  
- Granite Guardian  
- Granite 3.3