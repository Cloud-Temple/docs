---
title: Katalog der KI-Modelle
sidebar_position: 2
---

# Katalog der LLM as a Service-Modelle

## √úbersicht

Cloud Temple LLMaaS bietet **44 ausgew√§hlte und optimierte Sprachmodelle**, die den strengsten **SecNumCloud**-Anforderungen entsprechen. Unser Katalog umfasst das gesamte Spektrum, von ultra-effizienten Mikromodellen bis hin zu extrem gro√üen Modellen.

### Globale Statistiken

| Metrik | Wert |
|----------|--------|
| **Gesamtanzahl der Modelle** | 44 Modelle |
| **Minimale Kontextl√§nge** | 8.192 Tokens |
| **Maximale Kontextl√§nge** | 128.000 Tokens |
| **Konformit√§t** | SecNumCloud ‚úÖ HDS ‚úÖ Souver√§nit√§t ‚úÖ C5 ‚úÖ |
| **Standort** | 100 % Frankreich üá´üá∑ |

### Preise

| Typ der Nutzung | Preis |
|-------------------|------|
| **Eingabetokens** | 0,90 ‚Ç¨ / Million Tokens |
| **Ausgabetokens** | 4,00 ‚Ç¨ / Million Tokens |
| **Erweitertes Reasoning** | 21,00 ‚Ç¨ / Million Tokens |

## Gro√üe Modelle

### DeepSeek-R1 671B
**DeepSeek AI ‚Ä¢ 671B Parameter ‚Ä¢ Kontext: 16.000 Tokens**

Extrem gro√ües Modell von DeepSeek AI, optimiert f√ºr maximales Reasoning und Generierung.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 12 Tokens/Sekunde
- **Verbrauch** : 11,11 kWh/Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Werkzeuge/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit


**Anwendungsf√§lle:**
- Hochleistungs-Reasoning-Aufgaben
- Hochwertige Textgenerierung
- Forschung und Entwicklung in der KI

---

### DeepSeek-R1 70B
**DeepSeek AI ‚Ä¢ 70B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

70B-Modell von DeepSeek AI

**Technische Spezifikationen:**
- **Geschwindigkeit** : 21 Tokens/Sekunde
- **Verbrauch** : 12,56 kWh/Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Werkzeuge/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit


**Anwendungsf√§lle:**
- Hochleistungs-Reasoning-Aufgaben
- Hochwertige Textgenerierung
- Forschung und Entwicklung in der KI

---

### Gemma 3 27B
**Google ‚Ä¢ 27B Parameter ‚Ä¢ Kontext: 120.000 Tokens**

Revolution√§res Modell von Google mit optimaler Balance zwischen Leistung und Effizienz, mit einem au√üergew√∂hnlichen Leistungs-Kosten-Verh√§ltnis f√ºr anspruchsvolle professionelle Anwendungen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 20 Tokens/Sekunde
- **Verbrauch** : 6,67 kWh/Million Tokens
- **Lizenz** : [Google Gemma Nutzungsbedingungen](./licences/google_gemma_terms_of_use.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Werkzeuge/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit


**Anwendungsf√§lle:**
- Dokumentenanalyse mit erweitertem Kontext bis zu 120K Tokens (ca. 400 Seiten)
- Semantische Suche in umfangreichen Dokumentenbanken
- Bild- und Textverarbeitung gleichzeitig dank multimodaler F√§higkeiten
- Strukturierte Datenextraktion aus PDFs und gescannten Dokumenten
- Integration mit externen Tools √ºber die API-Funktionaufruf

---

### Llama 3.3 70B
**Meta ‚Ä¢ 70B Parameter ‚Ä¢ Kontext: 60.000 Tokens**

Multisprachiges Spitzenmodell von Meta, optimiert f√ºr nat√ºrliche Gespr√§che, komplexes Reasoning und feine Anweisungsverstehen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 26 Tokens/Sekunde
- **Verbrauch** : 11,75 kWh/Million Tokens
- **Lizenz** : [LLAMA 3.3 Community Lizenz](./licences/llama_3.3_community_licence.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Werkzeuge/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit


**Anwendungsf√§lle:**
- Multisprachige Chatbots, die 8 Sprachen gleichzeitig unterst√ºtzen
- Ausf√ºhrung komplexer, verketteter Anweisungen (Prompt-Chaining)
- Verarbeitung einer Gespr√§chsfenster von 60K Tokens f√ºr Konversationshistorien
- Analyse umfangreicher juristischer oder technischer Dokumente (>100 Seiten)
- Generierung strukturierter Texte mit Stilvorgaben

---

### Qwen2.5-VL 32B
**Qwen Team ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 120.000 Tokens**

St√§rkste Version der Qwen2.5-VL-Serie mit fortschrittlichen visuellen und Agentenf√§higkeiten.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 18 Tokens/Sekunde
- **Verbrauch** : 7,41 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Werkzeuge/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit


**Anwendungsf√§lle:**
- Analyse sehr komplexer Dokumente und Diagramme
- Autonome visuelle Agenten f√ºr Navigation und GUI-Interaktion
- Objekterkennung und Texterkennung mit hoher Pr√§zision
- Generierung reicher und detaillierter Beschreibungen aus komplexen Bildern

---

### Qwen2.5-VL 72B
**Qwen Team ‚Ä¢ 72B Parameter ‚Ä¢ Kontext: 128.000 Tokens**

St√§rkste Version der Qwen2.5-VL-Serie mit fortschrittlichen visuellen und Agentenf√§higkeiten f√ºr anspruchsvollste Aufgaben.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 15 Tokens/Sekunde
- **Verbrauch** : 8,89 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Werkzeuge/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit


**Anwendungsf√§lle:**
- Analyse sehr komplexer Dokumente und Diagramme
- Autonome visuelle Agenten f√ºr Navigation und GUI-Interaktion
- Objekterkennung und Texterkennung mit sehr hoher Pr√§zision
- Generierung reicher und detaillierter Beschreibungen aus sehr komplexen Bildern

---

### Qwen3 235B
**Qwen Team ‚Ä¢ 235B Parameter ‚Ä¢ Kontext: 60.000 Tokens**

Sehr gro√ües Modell der neuen Qwen3-Serie mit erweiterten F√§higkeiten f√ºr anspruchsvollste Aufgaben.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 17 Tokens/Sekunde
- **Verbrauch** : 7,84 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Werkzeuge/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit


**Anwendungsf√§lle:**
- Sehr fortgeschrittene conversationelle Agenten mit gro√üem Kontext und Werkzeugintegration (MCP)
- L√∂sung extrem komplexer Probleme (Mathematik, Code)
- Analyse und Generierung sehr umfangreicher und technischer Dokumente
- Multisprachige Anwendungen (>100 Sprachen) mit hoher Genauigkeit

---

### Qwen3 30B-A3B FP8
**Qwen Team ‚Ä¢ 30B-A3B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Neue Generation MoE FP8-Modell (3B aktiviert) mit hybriden Denkmodi und fortgeschrittenen Agentenf√§higkeiten.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 106 Tokens/Sekunde
- **Verbrauch** : 2,88 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Werkzeuge/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit


**Anwendungsf√§lle:**
- Fortgeschrittene conversationelle Agenten mit Werkzeugintegration (MCP)
- L√∂sung komplexer Probleme (Mathematik, Code) mit "Thinking"-Modus
- Multisprachige Anwendungen (>100 Sprachen)
- Szenarien mit Kosten-Leistungs-Optimierung (MoE) auf VLLM
- Engagierende Multi-Turn-Dialoge mit pr√§ziser Anweisungsverfolgung

---

## Spezialisierte Modelle

### Cogito 14B
**Deep Cogito ‚Ä¢ 14B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Modell von Deep Cogito, speziell f√ºr tiefes Reasoning und nuancierte Kontextverstehen optimiert, ideal f√ºr anspruchsvolle analytische Anwendungen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 60 Tokens/Sekunde
- **Verbrauch** : 4,40 kWh/Million Tokens
- **Lizenz** : [LLAMA 3.2 Community Lizenz](./licences/llama_3.2_community_licence.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Werkzeuge/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit


**Anwendungsf√§lle:**
- Semantische Textanalyse mit Identifizierung impliziter Implikationen
- Strukturiertes kausales Reasoning mit Identifizierung von Ursache-Wirkungs-Beziehungen
- Synthese komplexer Dokumente mit Extraktion der Schl√ºsselinformationen
- Pr√§zise Frage-Antwort-Systeme auf spezialisierten Dokumentenkorpora
- Argumentationsanalyse mit Bewertung der St√§rke der Reasoning-Strukturen

---

### Cogito 32B
**Deep Cogito ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Erweiterte Version des Cogito-Modells mit erheblich verst√§rkten Reasoning- und Analysef√§higkeiten, konzipiert f√ºr anspruchsvollste Anwendungen im Bereich analytischer KI.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 32 Tokens/Sekunde
- **Verbrauch** : 8,25 kWh/Million Tokens
- **Lizenz** : [LLAMA 3.2 Community Lizenz](./licences/llama_3.2_community_licence.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Werkzeuge/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit


**Anwendungsf√§lle:**
- Analyse multi-faktorieller Szenarien mit probabilistischer Ergebniseinsch√§tzung
- L√∂sung wissenschaftlicher Probleme mit formaler Beweisf√ºhrung
- Hochkritische Anwendungen mit Pr√§zision und Nachvollziehbarkeit der Ergebnisse
- Expertensysteme in spezialisierten Bereichen (juristisch, medizinisch, technisch)
- Analyse mit mehrstufigem Reasoning und vollst√§ndiger Erkl√§rbarkeit der Schlussfolgerungen

---

### Cogito 3B
**Deep Cogito ‚Ä¢ 3B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Kompakte Version des Cogito-Modells, optimiert f√ºr Reasoning auf Ger√§ten mit begrenzten Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 55 Tokens/Sekunde
- **Verbrauch** : 0,61 kWh/Million Tokens
- **Lizenz** : [LLAMA 3.2 Community Lizenz](./licences/llama_3.2_community_licence.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Werkzeuge/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit



---

### Cogito 8B
**Deep Cogito ‚Ä¢ 8B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

...
Mittleres Modell der Cogito-Familie mit einem guten Gleichgewicht zwischen Rechenkapazit√§ten und Effizienz.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 30 Tokens/Sekunde
- **Verbrauch** : 1,11 kWh pro Million Tokens
- **Lizenz** : [LLAMA 3.2 Community Lizenz](./licences/llama_3.2_community_licence.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit



---

### DeepCoder
**Agentica x Together AI ‚Ä¢ 14B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Open-Source-IA-Modell (14B) von Together AI & Agentica, eine glaubw√ºrdige Alternative zu propriet√§ren Modellen f√ºr die Codegenerierung.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 64 Tokens/Sekunde
- **Verbrauch** : 4,12 kWh pro Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit


**Anwendungsf√§lle:**
- Codegenerierung in mehr als 15 Sprachen mit Leistungsoptimierung
- Debugging und Refactoring von Code-Basen mit Auswirkungsanalyse
- Implementierung komplexer Algorithmen (Graphen, B√§ume, Heuristiken)
- {'Code-√úbertragung zwischen Sprachen/Frameworks (z. B. 'Python zu JavaScript)'}
- Automatisierte Erstellung von Einheitstests mit Codeabdeckung > 80%


---

### DeepSeek-R1 14B
**DeepSeek AI ‚Ä¢ 14B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Kompakte und effiziente Version des DeepSeek-R1-Modells, die ein hervorragendes Verh√§ltnis zwischen Leistung und Leichtigkeit f√ºr Deployment-Anforderungen bietet, die Flexibilit√§t und Reaktivit√§t erfordern.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 62 Tokens/Sekunde
- **Verbrauch** : 4,26 kWh pro Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit


**Anwendungsf√§lle:**
- Allgemeine Anwendungen mit Bedarf an schneller Inferenz (44 Tokens/s)
- Deployment auf Standardservern ohne spezialisierte GPU (14B Parameter)
- Textverarbeitung mit kontextueller Analyse und Antwortzeit < 2s
- Deployment auf Edge Computing mit optimierter lokaler Inferenz
- Schnelles Prototyping von IA-Anwendungen mit kurzer Iterationszeit


---

### DeepSeek-R1 32B
**DeepSeek AI ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Mittlere Version des DeepSeek-R1-Modells, die ein strategisches Gleichgewicht zwischen den fortgeschrittenen F√§higkeiten der 70B-Version und der Effizienz der 14B-Version bietet, f√ºr maximale Vielseitigkeit und Leistung.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 33 Tokens/Sekunde
- **Verbrauch** : 7,99 kWh pro Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit


**Anwendungsf√§lle:**
- Anwendungen, die ein gutes Gleichgewicht zwischen Leistung und Kosten ben√∂tigen (32B Parameter)
- Professionelle Textverarbeitung mit Analyse der semantischen Feinheiten
- Automatisierte Generierung strukturierter Berichte aus Rohdaten
- Anwendungen, die Datenanalyse und Inhaltsgenerierung kombinieren
- Spezialisierte Assistenten f√ºr technische Branchen (Recht, Medizin, Technik)


---

### Foundation-Sec-8B
**Foundation AI ‚Äî Cisco ‚Ä¢ 8B Parameter ‚Ä¢ Kontext: 16.384 Tokens**

Sprachmodell f√ºr Cybersecurity, optimiert f√ºr Effizienz.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 21 Tokens/Sekunde
- **Verbrauch** : 1,59 kWh pro Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚úÖ Sicherheit



---

### Gemma 3 12B
**Google ‚Ä¢ 12B Parameter ‚Ä¢ Kontext: 120.000 Tokens**

Mittlere Version des Gemma 3-Modells mit einem hervorragenden Gleichgewicht zwischen Leistung und Effizienz.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 56 Tokens/Sekunde
- **Verbrauch** : 4,71 kWh pro Million Tokens
- **Lizenz** : [Google Gemma Nutzungsbedingungen](./licences/google_gemma_terms_of_use.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit


**Anwendungsf√§lle:**
- Multimodale Anwendungen mit moderaten Ressourcenanforderungen
- Dokumentenverarbeitung mit Standardkontext (bis zu 100 Seiten)
- Generierung von Textinhalt und kombinierte Bildanalyse
- Deployment auf Standard-GPUs ohne spezialisierte Infrastruktur
- Fortschrittliche Chatbots mit integrierten visuellen und textuellen F√§higkeiten


---

### Gemma 3 1B
**Google ‚Ä¢ 1B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Ultra-leichtes Mikro-Modell f√ºr Deployment auf Ger√§ten mit sehr geringen Ressourcen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 112 Tokens/Sekunde
- **Verbrauch** : 0,15 kWh pro Million Tokens
- **Lizenz** : [Google Gemma Nutzungsbedingungen](./licences/google_gemma_terms_of_use.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit


**Anwendungsf√§lle:**
- Deployment auf IoT-Ger√§ten und eingebetteten Systemen mit API-Integration
- Anwendungen, die lokale Inferenz auf CPU mit Funktionsaufrufen ben√∂tigen
- Grundlegende Textaufgaben mit sofortiger Antwortzeit und Funktionsaufruf
- Kompakte Assistenten f√ºr Massenanwendungen mit externen Dienstintegration
- Intelligente Steuersysteme mit mehreren APIs/Services


---

### Gemma 3 4B
**Google ‚Ä¢ 4B Parameter ‚Ä¢ Kontext: 120.000 Tokens**

Kompaktes Google-Modell mit hervorragenden Leistungen in einem leichtgewichtigen und wirtschaftlichen Format.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 57 Tokens/Sekunde
- **Verbrauch** : 0,58 kWh pro Million Tokens
- **Lizenz** : [Google Gemma Nutzungsbedingungen](./licences/google_gemma_terms_of_use.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit


**Anwendungsf√§lle:**
- Eingebettete Anwendungen und Edge Computing mit Bildverarbeitung
- Reaktive multimodale Chatbots mit geringer Latenz (<50ms)
- Skalierbare Deployment mit visuellen und textuellen F√§higkeiten
- Mobile Anwendungen mit Bild- und Textanalyse
- Verarbeitung einfacher bis mittelkomplexer visueller Anfragen mit hoher Leistung


---

### Granite 3 Guardian 2B
**IBM ‚Ä¢ 2B Parameter ‚Ä¢ Kontext: 8.192 Tokens**

Kompaktes IBM-Modell spezialisiert auf Sicherheit und Compliance, das Risiken und unangemessene Inhalte erkennt.

**Technische Spezifikationen:**
- **Geschwindigkeit** : N/A
- **Verbrauch** : N/A
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit



---

### Granite 3 Guardian 8B
**IBM ‚Ä¢ 8B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

IBM-Modell spezialisiert auf Sicherheit und Compliance, mit erweiterten F√§higkeiten zur Risikodetektion.

**Technische Spezifikationen:**
- **Geschwindigkeit** : N/A
- **Verbrauch** : N/A
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit



---

### Granite 3.1 MoE
**IBM ‚Ä¢ 3B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Innovatives IBM-Modell mit Mixture-of-Experts (MoE)-Architektur, das hervorragende Leistungen bietet und die Berechnungsressourcen stark optimiert.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 74 Tokens/Sekunde
- **Verbrauch** : 0,45 kWh pro Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit


**Anwendungsf√§lle:**
- Allgemeine Anwendungen mit optimiertem Inferenzkosten (42 Tokens/Sekunde)
- Dokumentenverarbeitung in CPU-Umgebungen mit begrenztem RAM
- Spezialisierte Analysen mit dynamischer Aktivierung relevanter Modellteile
- Hochdichte Deployment mit geringem Energieverbrauch pro Inferenz
- Parallele Verarbeitung mehrerer Anfragentypen mit MoE-Spezialisierung


---

### Granite 3.2 Vision
**IBM ‚Ä¢ 2B Parameter ‚Ä¢ Kontext: 16.384 Tokens**

Revolution√§res, kompaktes IBM-Modell spezialisiert auf Computer Vision, das visuelle Dokumente direkt analysieren und verstehen kann, ohne Zwischentechnologien wie OCR zu verwenden.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 48 Tokens/Sekunde
- **Verbrauch** : 0,69 kWh pro Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit


**Anwendungsf√§lle:**
- Strukturierte Datenextraktion aus Rechnungen und Formularen ohne OCR
- Direkte Analyse von Tabellen und Grafiken mit Trendinterpretation
- Lesen und Interpretieren technischer Diagramme (elektrisch, mechanisch)
- Verarbeitung manueller Dokumente mit hohem Erkennungsrhythmus
- Leichte Computer Vision (2B Parameter) mit hoher Geschwindigkeit (50 Tokens/s)


---

### Granite 3.3 2B
**IBM ‚Ä¢ 2B Parameter ‚Ä¢ Kontext: 120.000 Tokens**

Granite 2B-Modell, feinabgestimmt von IBM, optimiert f√ºr Reasoning und Anweisungsfolge mit einem Kontext von 128k Tokens.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 45 Tokens/Sekunde
- **Verbrauch** : 0,74 kWh pro Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚úÖ Sicherheit


**Anwendungsf√§lle:**
- Leichte Deployment mit gro√üem Kontext (128k Tokens)
- Allgemeine Anweisungsfolgeaufgaben auf begrenzten Ressourcen
- Kompakte multilinguale IA-Assistenten
- Verarbeitung langer Dokumente auf weniger leistungsstarken Ger√§ten
- Codegenerierung/Code-Vervollst√§ndigung (FIM) auf Standardarbeitspl√§tzen


---

### Granite 3.3 8B
**IBM ‚Ä¢ 8B Parameter ‚Ä¢ Kontext: 60.000 Tokens**
Granite 8B-Modell, feingetuntet von IBM f√ºr verbessertes Reasoning und Instruction Following, mit einem Kontext von 128k Tokens.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 30 Tokens/Sekunde
- **Verbrauch** : 1,11 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚úÖ Sicherheit


**Anwendungsf√§lle:**
- Allgemeine Instruction-following-Aufgaben (Klassifizierung, Extraktion, Q&A)
- Multisprachige IA-Assistenten (12 Sprachen)
- {'Verarbeitung sehr langer Dokumente (128k Tokens)': 'Zusammenfassungen, Q&A'}
- Codegenerierung/Code-Vervollst√§ndigung mit Fill-in-the-Middle
- Integration mit externen Tools √ºber Function Calling
- Strukturiertes Reasoning mit dem Modus "Thinking"

---

### Granite Embedding
**IBM ‚Ä¢ 278M Parameter ‚Ä¢ Kontext : 512 Tokens**

Ultra-leichtes Embedding-Modell von IBM f√ºr semantische Suche und Klassifizierung.

**Technische Spezifikationen:**
- **Geschwindigkeit** : N/A
- **Verbrauch** : N/A
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit



---

### Llama 3.1 8B
**Meta ‚Ä¢ 8B Parameter ‚Ä¢ Kontext : 32.000 Tokens**

Grundmodell der Llama 3.1-Familie mit soliden Leistungen f√ºr seine Gr√∂√üe.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 31 Tokens/Sekunde
- **Verbrauch** : 1,08 kWh/Million Tokens
- **Lizenz** : [LLAMA 3.1 Community Lizenz](./licences/llama_3.1_community_licence.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit



---

### Lucie-7B-Instruct
**OpenLLM-France ‚Ä¢ 7B Parameter ‚Ä¢ Kontext : 32.000 Tokens**

Open-Source-Kausal-Modell (7B), feingetuntet von Lucie-7B. Optimiert f√ºr Franz√∂sisch.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 4 Tokens/Sekunde
- **Verbrauch** : 8,33 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit



---

### Magistral 24B
**Mistral AI ‚Ä¢ 24B Parameter ‚Ä¢ Kontext : 40.000 Tokens**

Das erste Reasoning-Modell von Mistral AI, das sich durch spezifisches Domain-Reasoning, Transparenz und Mehrsprachigkeit auszeichnet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 25 Tokens/Sekunde
- **Verbrauch** : 5,33 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚úÖ Sicherheit


**Anwendungsf√§lle:**
- Strategie und Gesch√§ftsbetrieb (Risikomodellierung)
- Regulierten Branchen (Recht, Finanzen) mit nachvollziehbarem Reasoning
- Software-Engineering (Projektplanung, Architektur)
- Inhaltscreation und Kommunikation (kreative Schreibweise, Erz√§hlung)

---

### Mistral Small 3.1
**Mistral AI ‚Ä¢ 24B Parameter ‚Ä¢ Kontext : 60.000 Tokens**

Kompaktes und reaktives Modell von Mistral AI, speziell f√ºr fl√ºssige und relevante Konversationen mit optimaler Antwortgeschwindigkeit konzipiert.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 48 Tokens/Sekunde
- **Verbrauch** : 5,50 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit


**Anwendungsf√§lle:**
- Konversationelle Anwendungen
- Virtuelle Assistenten mit Bild- und Textanalyse (26 Tokens/s)
- Technische Support-Chatbots mit Zugriff auf technische Dokumentation
- Inhalts-Editoren mit sofortiger Antwort (Blogs, E-Mails)
- Deployment auf Standard-Infrastrukturen (24B Parameter)

---

### Phi-4 Reasoning 14B
**Microsoft ‚Ä¢ 14B Parameter ‚Ä¢ Kontext : 32.000 Tokens**

Modell der Phi-Familie von Microsoft, spezialisiert auf komplexes Reasoning und Mathematik.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 71 Tokens/Sekunde
- **Verbrauch** : 3,71 kWh/Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚ùå Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit



---

### QwQ-32B
**Qwen Team ‚Ä¢ 32B Parameter ‚Ä¢ Kontext : 32.000 Tokens**

32 Milliarden Parameter umfassendes Modell, verbessert durch Verst√§rkungslernen (RL), um sich in Reasoning, Code, Mathematik und Agent-Aufgaben auszuzeichnen.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 35 Tokens/Sekunde
- **Verbrauch** : 7,54 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit


**Anwendungsf√§lle:**
- L√∂sung komplexer Probleme mit Reasoning und Werkzeugnutzung
- Codegenerierung und -ausf√ºhrung mit Ergebnisverifikation
- Fortschrittliche mathematische Aufgaben mit Genauigkeitspr√ºfung
- Agenten-Anwendungen, die mit der Umgebung interagieren
- Verbessertes Instruction Following und menschliche Pr√§ferenzausrichtung

---

### Qwen 2.5 0.5B
**Qwen Team ‚Ä¢ 0.5B Parameter ‚Ä¢ Kontext : 32.000 Tokens**

Ultra-leichtes Mikro-Modell der Qwen 2.5-Familie, f√ºr maximale Effizienz auf eingeschr√§nkten Ger√§ten konzipiert.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 162 Tokens/Sekunde
- **Verbrauch** : 0,10 kWh/Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit



---

### Qwen 2.5 1.5B
**Qwen Team ‚Ä¢ 1.5B Parameter ‚Ä¢ Kontext : 32.000 Tokens**

Sehr kompaktes Modell der Qwen 2.5-Familie, das ein gutes Leistungs-/Gr√∂√üenverh√§ltnis f√ºr leichte Deployment-Optionen bietet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 102 Tokens/Sekunde
- **Verbrauch** : 0,33 kWh/Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit



---

### Qwen 2.5 14B
**Qwen Team ‚Ä¢ 14B Parameter ‚Ä¢ Kontext : 32.000 Tokens**

Vielseitiges mittelgro√ües Modell der Qwen 2.5-Familie mit gutem Leistungs-/Ressourcenverh√§ltnis.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 61 Tokens/Sekunde
- **Verbrauch** : 4,33 kWh/Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit



---

### Qwen 2.5 32B
**Qwen Team ‚Ä¢ 32B Parameter ‚Ä¢ Kontext : 32.000 Tokens**

Leistungsstarkes Modell der Qwen 2.5-Familie mit fortgeschrittenen F√§higkeiten in Verst√§ndnis und Generierung.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 31 Tokens/Sekunde
- **Verbrauch** : 8,51 kWh/Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit



---

### Qwen 2.5 3B
**Qwen Team ‚Ä¢ 3B Parameter ‚Ä¢ Kontext : 32.000 Tokens**

Kompaktes und effizientes Modell der Qwen 2.5-Familie, f√ºr allgemeine Aufgaben auf begrenzten Ressourcen geeignet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 64 Tokens/Sekunde
- **Verbrauch** : 0,52 kWh/Million Tokens
- **Lizenz** : [MIT Lizenz](./licences/mit_licence.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit



---

### Qwen2.5-VL 3B
**Qwen Team ‚Ä¢ 3,8B Parameter ‚Ä¢ Kontext : 128.000 Tokens**

Kompaktes Vision-Langage-Modell, leistungsstarker L√∂sung f√ºr Edge AI (Kanten-IA).

**Technische Spezifikationen:**
- **Geschwindigkeit** : 65 Tokens/Sekunde
- **Verbrauch** : 0,51 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit



---

### Qwen2.5-VL 7B
**Qwen Team ‚Ä¢ 7B (8,3B) Parameter ‚Ä¢ Kontext : 128.000 Tokens**

Leistungsstarkes Vision-Langage-Modell, das GPT-4o-mini in bestimmten Aufgaben √ºbertrifft.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 35 Tokens/Sekunde
- **Verbrauch** : 0,95 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚úÖ Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit



---

### Qwen3 0,6b
**Qwen Team ‚Ä¢ 0,6B Parameter ‚Ä¢ Kontext : 32.000 Tokens**

Kompaktes und effizientes Modell der Qwen3-Familie, f√ºr allgemeine Aufgaben auf begrenzten Ressourcen geeignet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 112 Tokens/Sekunde
- **Verbrauch** : 0,15 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit



---

### Qwen3 1,7b
**Qwen Team ‚Ä¢ 1,7B Parameter ‚Ä¢ Kontext : 32.000 Tokens**

Sehr kompaktes Modell der Qwen3-Familie, das ein gutes Leistungs-/Gr√∂√üenverh√§ltnis f√ºr leichte Deployment-Optionen bietet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 88 Tokens/Sekunde
- **Verbrauch** : 0,38 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit



---

### Qwen3 14B
**Qwen Team ‚Ä¢ 14B Parameter ‚Ä¢ Kontext : 32.000 Tokens**

Neue Generation Qwen3-Modell (14B), das mit besserer Effizienz vergleichbare Leistungen wie Qwen2.5 32B bietet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 68 Tokens/Sekunde
- **Verbrauch** : 3,88 kWh/Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit


**Anwendungsf√§lle:**
- Allgemeine Aufgaben mit Leistung und gro√üem Kontext
- Kreative und technische Inhaltsgenerierung
- Datenanalyse und komplexes Reasoning
- Integration mit externen Tools √ºber Function Calling

---

### Qwen3 32B
**Qwen Team ‚Ä¢ 32B Parameter ‚Ä¢ Kontext: 40.000 Tokens**

Leistungsstarker Modell der neuen Generation Qwen3 mit fortgeschrittenen F√§higkeiten im Bereich Reasoning, Code und Agentik, mit erweitertem Kontext.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 18 Tokens pro Sekunde
- **Verbrauch** : 7,41 kWh pro Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit


**Anwendungsf√§lle:**
- Fortgeschrittene conversationale Agenten mit gro√üem Kontext und Integration von Tools (MCP)
- L√∂sung komplexer Probleme (Mathematik, Code) im "Thinking"-Modus
- Analyse und Generierung umfangreicher Dokumente
- Mehrsprachige Anwendungen (>100 Sprachen), die eine tiefe Verst√§ndnisf√§higkeit erfordern

---

### Qwen3 4b
**Qwen Team ‚Ä¢ 4B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Kompakter Modell der Qwen3-Familie mit hervorragenden Leistungen in einem leichtgewichtigen und wirtschaftlichen Format.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 49 Tokens pro Sekunde
- **Verbrauch** : 0,68 kWh pro Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚ùå Sicherheit



---

### Qwen3 8b
**Qwen Team ‚Ä¢ 8B Parameter ‚Ä¢ Kontext: 32.000 Tokens**

Qwen3 8B-Modell, das ein gutes Gleichgewicht zwischen Leistung und Effizienz f√ºr allgemeine Aufgaben bietet.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 33 Tokens pro Sekunde
- **Verbrauch** : 1,01 kWh pro Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚úÖ Reasoning ‚Ä¢ ‚ùå Sicherheit



---

### devstral 24B
**Mistral AI & All Hands AI ‚Ä¢ 24B Parameter ‚Ä¢ Kontext: 120.000 Tokens**

Devstral ist ein agentisches LLM f√ºr Software-Engineering-Aufgaben.

**Technische Spezifikationen:**
- **Geschwindigkeit** : 45 Tokens pro Sekunde
- **Verbrauch** : 5,86 kWh pro Million Tokens
- **Lizenz** : [Apache 2.0](./licences/apache_2.0.licence.md)
- **Standort** : FR üá´üá∑

**F√§higkeiten:**
‚úÖ Tools/Agent ‚Ä¢ ‚ùå Vision ‚Ä¢ ‚ùå Reasoning ‚Ä¢ ‚úÖ Sicherheit


**Anwendungsf√§lle:**
- Exploration und Modifikation von Code-Basen
- Agentic
- Europ√§isch

---

## Empfohlene Anwendungsf√§lle

### Mehrsprachige Gespr√§che

Chatbots und Assistenten, die in mehreren Sprachen kommunizieren k√∂nnen mit automatischer Erkennung, Aufrechterhaltung des Kontexts √ºber die gesamte Unterhaltung und Verst√§ndnis sprachlicher Besonderheiten

**Empfohlene Modelle:**

- Llama 3.3
- Mistral Small 3.1
- Qwen 2.5
- Granite 3.3

### Analyse von langen Dokumenten

Verarbeitung umfangreicher Dokumente (>100 Seiten) mit Aufrechterhaltung des Kontexts √ºber den gesamten Text, Extraktion von Schl√ºsselinformationen, Generierung relevanter Zusammenfassungen und Beantwortung spezifischer Fragen zum Inhalt

**Empfohlene Modelle:**

- Gemma 3
- DeepSeek-R1
- Granite 3.3

### Programmierung und Entwicklung

Generierung und Optimierung von Code in mehreren Sprachen, Debugging, Refactoring, Entwicklung vollst√§ndiger Funktionen, Verst√§ndnis komplexer algorithmischer Implementierungen und Erstellung von Einheitstests

**Empfohlene Modelle:**

- DeepCoder
- QwQ
- DeepSeek-R1
- Granite 3.3
- Devstral

### Visuelle Analyse

Direkte Verarbeitung von Bildern und visuellen Dokumenten ohne OCR-Vorverarbeitung, Interpretation technischer Diagramme, Grafiken, Tabellen, Zeichnungen und Fotos mit Generierung detaillierter textueller Erkl√§rungen des visuellen Inhalts

**Empfohlene Modelle:**

- Granite 3.2 Vision
- Mistral Small 3.1
- Gemma 3
- Qwen2.5-VL

### Sicherheit und Compliance

Anwendungen, die spezifische Sicherheitsfunktionen erfordern; Inhaltsschutz, Nachverfolgbarkeit der Schlussfolgerungen, RGPD/HDS-√úberpr√ºfung, Risikominimierung, Schwachstellenanalyse und Einhaltung branchenspezifischer Vorschriften

**Empfohlene Modelle:**

- Granite Guardian
- Granite 3.3
- Devstral
- Mistral Small 3.1
- Magistral 24b
- Foundation-Sec-8B

### Leichte und eingebettete Deployment

Anwendungen, die eine minimale Ressourcenbelastung erfordern, Deployment auf Ger√§ten mit begrenzter Kapazit√§t, Echtzeit-Infereenz auf Standard-CPU und Integration in eingebettete oder IoT-Systeme

**Empfohlene Modelle:**

- Gemma 3
- Granite 3.1 MoE
- Granite Guardian
- Granite 3.3