---
title: Cat√°logo de Modelos de IA
sidebar_position: 2
---

# Cat√°logo de Modelos LLM como Servicio

## Visi√≥n general

Cloud Temple LLMaaS ofrece **modelos de lenguaje grandes** cuidadosamente seleccionados y optimizados. Nuestro cat√°logo cubre todo el espectro, desde modelos micro ultraeficientes hasta modelos extremadamente grandes.

### Nota sobre las medidas de rendimiento
Los valores de velocidad (tokens/s) representan objetivos de rendimiento en condiciones reales. El consumo energ√©tico (kWh/Mtoken) se calcula dividiendo la potencia estimada del servidor de inferencia (en vatios) por la velocidad medida del modelo (en tokens por segundo), y luego se convierte en kilovatios hora por mill√≥n de tokens. Este m√©todo ofrece una comparaci√≥n pr√°ctica de la eficiencia energ√©tica de los diferentes modelos, que debe usarse como indicador relativo en lugar de una medida absoluta del consumo el√©ctrico.

### Estad√≠sticas Globales

| M√©trica | Valor |
|----------|--------|
| **N√∫mero total de modelos** | 36 modelos |
| **Contexto m√≠nimo** | 8 192 tokens |
| **Contexto m√°ximo** | 120 000 tokens |
| **Conformidad** | SecNumCloud ‚úÖ HDS ‚úÖ Soberan√≠a ‚úÖ C5 ‚úÖ |
| **Localizaci√≥n** | 100% Francia üá´üá∑ |

### Tarifas

| Tipo de uso | Precio |
|-------------------|------|
| **Tokens de entrada** | 0.9‚Ç¨ / mill√≥n de tokens |
| **Tokens de salida** | 4‚Ç¨ / mill√≥n de tokens |
| **Razonamiento avanzado** | 21‚Ç¨ / mill√≥n de tokens |

## Modelos de Gran Tama√±o

### Llama 3.3 70B
**Meta ‚Ä¢ 70B par√°metros ‚Ä¢ Contexto: 60 000 tokens**

Modelo multiling√ºe de vanguardia desarrollado por Meta, dise√±ado para destacar en di√°logos naturales, razonamiento complejo y comprensi√≥n sutil de instrucciones.

**Especificaciones t√©cnicas:**
- **Velocidad** : 30 tokens por segundo tokens por segundo
- **Consumo** : 8.87 kWh/mill√≥n de tokens
- **Licencia** : [Licencia Comunitaria Llama 3.3](./licencias/llama3.3_70b.licencia.md)
- **Localizaci√≥n** : FR üá´üá∑

**Capacidades:**
‚ùå Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚ùå Seguridad

**Casos de uso:**
- Chatbots multiling√ºes que admiten 8 idiomas simult√°neamente
- Ejecuci√≥n de instrucciones complejas encadenadas (cadena de prompts)
- Procesamiento de una ventana de di√°logo de 60K tokens para historial conversacional
- An√°lisis de documentos legales o t√©cnicos voluminosos (>100 p√°ginas)
- Generaci√≥n de textos estructurados con fidelidad a las instrucciones estil√≠sticas

---

### Qwen3 235B
**Equipo Qwen ‚Ä¢ 235B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo muy grande de la nueva generaci√≥n Qwen3, ofreciendo capacidades ampliadas para tareas muy complejas.

**Especificaciones t√©cnicas:**
- **Velocidad** : 21 tokens por segundo
- **Consumo** : 6.35 kWh/mill√≥n de tokens
- **Licencia** : [Apache 2.0](./licencias/apache2.licencia.md)
- **Localizaci√≥n** : FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚ùå Seguridad

**Casos de uso:**
- Agentes conversacionales muy avanzados con gran contexto e integraci√≥n de herramientas (MCP)
- Resoluci√≥n de problemas extremadamente complejos (matem√°ticas, c√≥digo)
- An√°lisis y generaci√≥n de documentos muy voluminosos y t√©cnicos
- Aplicaciones multiling√ºes (>100 idiomas) que requieren comprensi√≥n y generaci√≥n de alta fidelidad

---

### DeepSeek-R1 671B
**DeepSeek AI ‚Ä¢ 671B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo extremadamente grande de DeepSeek AI, dise√±ado para el m√°ximo de razonamiento y generaci√≥n.

**Especificaciones t√©cnicas:**
- **Velocidad** : 16 tokens por segundo tokens por segundo
- **Consumo** : 8.33 kWh/mill√≥n de tokens
- **Licencia** : [Licencia MIT](./licencias/deepseek-r1_671b.licencia.md)
- **Localizaci√≥n** : FR üá´üá∑

**Capacidades:**
‚ùå Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚ùå Seguridad

**Casos de uso:**
- Tareas de razonamiento de vanguardia
- Generaci√≥n de texto de alta calidad
- Investigaci√≥n y desarrollo en IA

---

### Gemma 3 27B
**Google ‚Ä¢ 27B par√°metros ‚Ä¢ Contexto: 120 000 tokens**

Modelo revolucionario de Google que ofrece un equilibrio √≥ptimo entre potencia y eficiencia, con una relaci√≥n rendimiento/costo excepcional para aplicaciones profesionales exigentes.

**Especificaciones t√©cnicas:**
- **Velocidad** : 68 tokens por segundo tokens por segundo ‚ö°
- **Consumo** : 3.91 kWh/mill√≥n de tokens
- **Licencia** : [T√©rminos de uso de Google Gemma](./licencias/gemma3_27b.licencia.md)
- **Localizaci√≥n** : FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚úÖ Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚ùå Seguridad

**Casos de uso:**
- An√°lisis de documentos con contexto extendido hasta 120K tokens (aproximadamente 400 p√°ginas)
- Indexaci√≥n y b√∫squeda sem√°ntica en bases documentales voluminosas
- Procesamiento de im√°genes y texto simult√°neamente gracias a capacidades multimodales
- Extracci√≥n estructurada de datos a partir de PDF y documentos escaneados
- Integraci√≥n con herramientas externas a trav√©s de la API de llamada a funciones

---

### Qwen3 30B-A3B FP8
**Equipo Qwen ‚Ä¢ 30B-A3B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo MoE FP8 (3B activados) de nueva generaci√≥n, con modos de pensamiento h√≠bridos y capacidades avanzadas de agente.

**Especificaciones t√©cnicas:**
- **Velocidad** : 103 tokens por segundo tokens por segundo ‚ö°
- **Consumo** : 2.58 kWh/mill√≥n de tokens
- **Licencia** : [Apache 2.0](./licencias/apache2.licencia.md)
- **Localizaci√≥n** : FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚ùå Seguridad

**Casos de uso:**
- Agentes conversacionales avanzados con integraci√≥n de herramientas (MCP)
- Resoluci√≥n de problemas complejos (matem√°ticas, c√≥digo) con modo "Pensando"
- Aplicaciones multiling√ºes (>100 idiomas)
- Escenarios que requieren un equilibrio costo/rendimiento (MoE) en VLLM
- Di√°logos de m√∫ltiples rondas atractivos y seguimiento preciso de instrucciones

---

### DeepSeek-R1 70B
**DeepSeek AI ‚Ä¢ 70B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo de 70B de DeepSeek AI

**Especificaciones t√©cnicas:**
- **Velocidad** : 20 tokens por segundo tokens por segundo
- **Consumo** : 11.44 kWh/mill√≥n de tokens
- **Licencia** : [Licencia MIT](./licencias/deepseek-r1_70b.licencia.md)
- **Localizaci√≥n** : FR üá´üá∑

**Capacidades:**
‚ùå Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚ùå Seguridad

**Casos de uso:**
- Tareas de razonamiento complejo
- Generaci√≥n de texto de alta calidad
- An√°lisis profundo de documentos (dentro del l√≠mite del contexto de 27k)

---

## Modelos Especializados

### Qwen3 14B
**Equipo Qwen ‚Ä¢ 14B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo denso de nueva generaci√≥n Qwen3 (14B), ofreciendo rendimiento equivalente a Qwen2.5 32B con mejor eficiencia.

**Especificaciones t√©cnicas:**
- **Velocidad** : 69 tokens por segundo tokens por segundo ‚ö°
- **Consumo** : 2.65 kWh/mill√≥n de tokens
- **Licencia** : [Apache 2.0](./licencias/apache2.licencia.md)
- **Localizaci√≥n** : FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚ùå Seguridad

**Casos de uso:**
- Tareas generales que requieren rendimiento y gran contexto
- Generaci√≥n de contenido creativo y t√©cnico
- An√°lisis de datos y razonamiento complejo
- Integraci√≥n con herramientas externas a trav√©s de llamada a funciones

---

### Gemma 3 12B
**Google ‚Ä¢ 12B par√°metros ‚Ä¢ Contexto: 120 000 tokens**

Versi√≥n intermedia del modelo Gemma 3 ofreciendo un excelente equilibrio entre rendimiento y eficiencia.

**Especificaciones t√©cnicas:**
- **Velocidad** : 67 tokens por segundo tokens por segundo ‚ö°
- **Consumo** : 2.73 kWh/mill√≥n de tokens
- **Licencia** : [T√©rminos de uso de Google Gemma](./licencias/gemma3_12b.licencia.md)
- **Localizaci√≥n** : FR üá´üá∑

**Capacidades:**
‚ùå Herramientas/Agente ‚Ä¢ ‚úÖ Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚ùå Seguridad

**Casos de uso:**
- Aplicaciones multimodales con restricciones de recursos moderadas
- Procesamiento de documentos con contexto est√°ndar (hasta 100 p√°ginas)
- Generaci√≥n de contenido textual y an√°lisis de im√°genes combinados
- Despliegues en GPU est√°ndar sin infraestructura especializada
- Chatbots avanzados con capacidades visuales y textuales integradas

---

### Gemma 3 4B
**Google ‚Ä¢ 4B par√°metros ‚Ä¢ Contexto: 120 000 tokens**

Modelo compacto de Google ofreciendo excelentes rendimientos en un formato ligero y econ√≥mico.

**Especificaciones t√©cnicas:**
- **Velocidad** : 58 tokens por segundo tokens por segundo ‚ö°
- **Consumo** : 0.93 kWh/mill√≥n de tokens üå±
- **Licencia** : [T√©rminos de uso de Google Gemma](./licencias/gemma3_4b.licencia.md)
- **Localizaci√≥n** : FR üá´üá∑

**Capacidades:**
‚ùå Herramientas/Agente ‚Ä¢ ‚úÖ Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚ùå Seguridad

**Casos de uso:**
- Aplicaciones embebidas y edge computing con procesamiento de im√°genes
- Chatbots multimodales reactivos que requieren baja latencia
- Despliegues a gran escala con capacidades visuales y textuales
- Aplicaciones m√≥viles con an√°lisis de im√°genes y textos
- Procesamiento de consultas visuales simples a moderadamente complejas con alta rendimiento

---

### Gemma 3 1B
**Google ‚Ä¢ 1B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Micromodelo ultra-ligero dise√±ado para despliegues en dispositivos con recursos muy limitados.

**Especificaciones t√©cnicas:**
- **Velocidad** : 41 tokens por segundo tokens por segundo
- **Consumo** : 1.32 kWh/mill√≥n de tokens üå±
- **Licencia** : [T√©rminos de uso de Google Gemma](./licencias/gemma3_1b.licencia.md)
- **Localizaci√≥n** : FR üá´üá∑

**Capacidades:**
‚ùå Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚ùå Seguridad

**Casos de uso:**
- Despliegue en dispositivos IoT y sistemas embebidos con integraci√≥n de API
- Aplicaciones que requieren inferencia local en CPU con llamadas a funciones
- Tareas textuales b√°sicas con respuesta instant√°nea y llamada a funciones
- Asistentes compactos para aplicaciones de uso general con integraci√≥n de servicios externos
- Sistemas de control inteligente que integran varias APIs/servicios

---

### Lucie-7B-Instruct
**OpenLLM-France ‚Ä¢ 7B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo causal multiling√ºe de c√≥digo abierto (7B), fine-tuned desde Lucie-7B. Optimizado para el franc√©s.

**Especificaciones t√©cnicas:**
- **Velocidad** : 41 tokens por segundo tokens por segundo
- **Consumo** : 1.32 kWh/mill√≥n de tokens üå±
- **Licencia** : [Apache 2.0](./licencias/apache2.licencia.md)
- **Localizaci√≥n** : FR üá´üá∑

**Capacidades:**
‚ùå Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚ùå Seguridad

---

### Mistral Small 3.1
**Mistral AI ‚Ä¢ 24B par√°metros ‚Ä¢ Contexto: 60 000 tokens**

Modelo compacto y reactivo de Mistral AI, especialmente dise√±ado para ofrecer asistencia conversacional fluida y pertinente con una velocidad de respuesta √≥ptima.

**Especificaciones t√©cnicas:**
- **Velocidad**: 14 tokens/segundo
- **Consumo**: 13,06 kWh/mill√≥n de tokens
- **Licencia**: [Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚úÖ Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚úÖ Seguridad

**Casos de uso:**
- Aplicaciones conversacionales
- Asistentes virtuales que combinan an√°lisis de im√°genes y texto (26 tokens/s)
- Chatbots de soporte t√©cnico con acceso a documentaci√≥n t√©cnica
- Herramientas de creaci√≥n/edici√≥n de contenido con respuesta inmediata (blogs, correos electr√≥nicos)
- Despliegue en infraestructuras est√°ndar (24B de par√°metros)

---

### DeepCoder
**Agentica x Together AI ‚Ä¢ 14B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo de IA de c√≥digo abierto (14B) de Together AI & Agentica, alternativa cre√≠ble a los modelos propietarios para la generaci√≥n de c√≥digo.

**Especificaciones t√©cnicas:**
- **Velocidad**: 62 tokens/segundo ‚ö°
- **Consumo**: 2,95 kWh/mill√≥n de tokens
- **Licencia**: [Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚ùå Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚ùå Seguridad

**Casos de uso:**
- Generaci√≥n de c√≥digo en m√°s de 15 lenguajes con optimizaci√≥n de rendimiento
- Depuraci√≥n y refactorizaci√≥n de bases de c√≥digo existentes con an√°lisis de impacto
- Implementaci√≥n de algoritmos complejos (grafos, √°rboles, heur√≠sticas)
- Transposici√≥n de c√≥digo entre lenguajes y frameworks (por ejemplo Python a JavaScript)
- Creaci√≥n automatizada de pruebas unitarias con cobertura de c√≥digo > 80%

---

### Granite 3.2 Vision
**IBM ‚Ä¢ 2B par√°metros ‚Ä¢ Contexto: 16 384 tokens**

Modelo compacto revolucionario de IBM especializado en visi√≥n por computadora, capaz de analizar y comprender directamente documentos visuales sin recurrir a tecnolog√≠as OCR intermedias.

**Especificaciones t√©cnicas:**
- **Velocidad**: 48 tokens/segundo ‚ö°
- **Consumo**: 1,13 kWh/mill√≥n de tokens üå±
- **Licencia**: [Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚úÖ Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚úÖ Seguridad

**Casos de uso:**
- Extracci√≥n de datos estructurados a partir de facturas y formularios sin OCR
- An√°lisis directo de tablas y gr√°ficos con interpretaci√≥n de tendencias
- Lectura e interpretaci√≥n de diagramas t√©cnicos (el√©ctricos, mec√°nicos)
- Procesamiento de documentos manuscritos con alto √≠ndice de reconocimiento
- Visi√≥n por computadora ligera (2B par√°metros) con alta velocidad (79 tokens/s)

---

### Granite 3.3 8B
**IBM ‚Ä¢ 8B par√°metros ‚Ä¢ Contexto: 60 000 tokens**

Modelo Granite 8B afinado por IBM para un razonamiento y seguimiento de instrucciones mejorados, con un contexto de 128k tokens.

**Especificaciones t√©cnicas:**
- **Velocidad**: 27 tokens/segundo
- **Consumo**: 2,0 kWh/mill√≥n de tokens üå±
- **Licencia**: [Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚úÖ Seguridad

**Casos de uso:**
- Tareas generales de seguimiento de instrucciones (clasificaci√≥n, extracci√≥n, Preguntas y Respuestas)
- Asistentes IA multiling√ºes (12 idiomas)
- Procesamiento de documentos muy largos (128k tokens): res√∫menes y preguntas-respuestas
- Generaci√≥n/completi√≥n de c√≥digo con Fill-in-the-Middle
- Integraci√≥n con herramientas externas mediante function calling
- Razonamiento estructurado con el modo "Thinking"

---

### Granite 3.3 2B
**IBM ‚Ä¢ 2B par√°metros ‚Ä¢ Contexto: 120 000 tokens**

Modelo Granite 2B afinado por IBM, optimizado para el razonamiento y seguimiento de instrucciones, con un contexto de 128k tokens.

**Especificaciones t√©cnicas:**
- **Velocidad**: 45 tokens/segundo ‚ö°
- **Consumo**: 1,2 kWh/mill√≥n de tokens üå±
- **Licencia**: [Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚úÖ Seguridad

**Casos de uso:**
- Despliegues ligeros con gran contexto (128k tokens)
- Tareas generales de seguimiento de instrucciones en recursos limitados
- Asistentes IA multiling√ºes compactos
- Procesamiento de documentos largos en dispositivos menos potentes
- Generaci√≥n/completi√≥n de c√≥digo FIM en estaciones de trabajo est√°ndar

---

### Granite 3.1 MoE
**IBM ‚Ä¢ 3B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo innovador de IBM que utiliza la arquitectura Mixture-of-Experts (MoE) para ofrecer rendimiento excepcional y optimizar dr√°sticamente el uso de recursos computacionales.

**Especificaciones t√©cnicas:**
- **Velocidad**: 74 tokens/segundo ‚ö°
- **Consumo**: 0,73 kWh/mill√≥n de tokens üå±
- **Licencia**: [Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚úÖ Seguridad

**Casos de uso:**
- Aplicaciones generalistas con costo de inferencia optimizado (42 tokens/segundo)
- Procesamiento de documentos en entornos CPU con uso de RAM limitado
- An√°lisis especializados con activaci√≥n din√°mica de las partes pertinentes del modelo
- Despliegues de alta densidad con bajo consumo energ√©tico por inferencia
- Procesamiento paralelo de varios tipos de consultas con especializaci√≥n MoE

---

### Cogito 14B
**Deep Cogito ‚Ä¢ 14B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo de Deep Cogito especialmente dise√±ado para destacar en tareas de razonamiento profundo y comprensi√≥n contextual sutil, ideal para aplicaciones anal√≠ticas sofisticadas.

**Especificaciones t√©cnicas:**
- **Velocidad**: 60 tokens/segundo ‚ö°
- **Consumo**: 3,05 kWh/mill√≥n de tokens
- **Licencia**: [Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚ùå Seguridad

**Casos de uso:**
- An√°lisis sem√°ntico de textos con identificaci√≥n de implicaciones no expl√≠citas
- Razonamiento causal estructurado con identificaci√≥n de relaciones causa-efecto
- S√≠ntesis de documentos complejos con extracci√≥n de informaci√≥n clave
- Sistemas de preguntas-respuestas precisos sobre corpus documentales especializados
- An√°lisis argumentativo con evaluaci√≥n de la solidez de los razonamientos

---

### Cogito 32B
**Deep Cogito ‚Ä¢ 32B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Versi√≥n avanzada del modelo Cogito que ofrece capacidades de razonamiento y an√°lisis considerablemente ampliadas, dise√±ada para aplicaciones m√°s exigentes en inteligencia artificial anal√≠tica.

**Especificaciones t√©cnicas:**
- **Velocidad**: 32 tokens/segundo
- **Consumo**: 5,73 kWh/mill√≥n de tokens
- **Licencia**: [Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚ùå Seguridad

**Casos de uso:**
- An√°lisis de escenarios multi-factoriales con evaluaci√≥n probabil√≠stica de resultados
- Resoluci√≥n de problemas cient√≠ficos con demostraci√≥n formal de los pasos
- Aplicaciones de alta criticidad que requieren precisi√≥n y verificabilidad de resultados
- Sistemas expertos en dominios especializados (jur√≠dico, m√©dico, t√©cnico)
- An√°lisis con razonamiento multi-etapas y explicabilidad completa de las conclusiones

---

### Qwen3 32B
**Qwen Team ‚Ä¢ 32B par√°metros ‚Ä¢ Contexto: 40 000 tokens**

Modelo potente de la nueva generaci√≥n Qwen3, que ofrece capacidades avanzadas en razonamiento, c√≥digo y agentes, con un contexto ampliado.

**Especificaciones t√©cnicas:**
- **Licencia**: [Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚ùå Seguridad

**Casos de uso:**
- Agentes conversacionales avanzados con gran contexto e integraci√≥n de herramientas (MCP)
- Resoluci√≥n de problemas complejos (matem√°ticas, c√≥digo) con modo "Thinking"
- An√°lisis y generaci√≥n de documentos voluminosos
- Aplicaciones multiling√ºes (>100 idiomas) que requieren comprensi√≥n profunda

---

### QwQ-32B
**Qwen Team ‚Ä¢ 32B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo de 32 mil millones de par√°metros mejorado mediante aprendizaje por refuerzo (RL) para destacar en razonamiento, codificaci√≥n, matem√°ticas y tareas de agente.

**Especificaciones t√©cnicas:**
- **Velocidad**: 35 tokens/segundo
- **Consumo**: 5,22 kWh/mill√≥n de tokens
- **Licencia**: [Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚ùå Seguridad

**Casos de uso:**
- Resoluci√≥n de problemas complejos que requieren razonamiento y uso de herramientas
- Generaci√≥n y ejecuci√≥n de c√≥digo con verificaci√≥n de resultados
- Tareas matem√°ticas avanzadas con verificaci√≥n de exactitud
- Aplicaciones de agente capaces de interactuar con el entorno
- Seguimiento de instrucciones mejorado y alineaci√≥n con preferencias humanas

---

### DeepSeek-R1 14B
**DeepSeek AI ‚Ä¢ 14B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Versi√≥n compacta y eficiente del modelo DeepSeek-R1, que ofrece un excelente equilibrio entre rendimiento y ligereza para despliegues que requieren flexibilidad y reactividad.

**Especificaciones t√©cnicas:**
- **Velocidad**: 60 tokens/segundo ‚ö°
- **Consumo**: 3,05 kWh/mill√≥n de tokens
- **Licencia**: [MIT licence](./licences/deepseek-r1_14b.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚ùå Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚ùå Seguridad

**Casos de uso:**
- Aplicaciones generalistas con necesidades de inferencia r√°pida (44 tokens/s)
- Despliegues en servidores est√°ndar sin GPU especializada (14B par√°metros)
- Procesamiento de texto con an√°lisis contextual y tiempo de respuesta < 2s
- Despliegue en edge computing con inferencia local optimizada
- Prototipo r√°pido de aplicaciones de IA con tiempo de iteraci√≥n corto

---

### DeepSeek-R1 32B
**DeepSeek AI ‚Ä¢ 32B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Versi√≥n intermedia del modelo DeepSeek-R1 que ofrece un equilibrio estrat√©gico entre las capacidades avanzadas de la versi√≥n 70B y la eficiencia de la versi√≥n 14B, para una versatilidad y rendimiento √≥ptimos.

**Especificaciones t√©cnicas:**
- **Velocidad**: 33 tokens/segundo tokens/segundo
- **Consumo**: 5,54 kWh/mill√≥n de tokens
- **Licencia**: [Licencia MIT](./licences/deepseek-r1_32b.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚ùå Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚ùå Seguridad

**Casos de uso:**
- Aplicaciones que requieren un buen equilibrio entre potencia y costo (32B par√°metros)
- Procesamiento de texto profesional con an√°lisis de sutilezas sem√°nticas
- Generaci√≥n automatizada de informes estructurados a partir de datos brutos
- Aplicaciones que combinan an√°lisis de datos y generaci√≥n de contenido
- Asistentes especializados para sectores t√©cnicos (jur√≠dico, m√©dico, t√©cnico)

---

### Cogito 3B
**Deep Cogito ‚Ä¢ 3B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Versi√≥n compacta del modelo Cogito, optimizada para el razonamiento en dispositivos con recursos limitados.

**Especificaciones t√©cnicas:**
- **Velocidad**: 63 tokens/segundo tokens/segundo ‚ö°
- **Consumo**: 0,86 kWh/mill√≥n de tokens üå±
- **Licencia**: [Licencia Comunitaria LLAMA 3.2](./licences/cogito_3b.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚ùå Seguridad

---

### Granite Embedding
**IBM ‚Ä¢ 278M par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo de embebido ultra-ligero de IBM para b√∫squeda sem√°ntica y clasificaci√≥n.

**Especificaciones t√©cnicas:**
- **Licencia**: [Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚ùå Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚ùå Seguridad

---

### Granite 3 Guardian 2B
**IBM ‚Ä¢ 2B par√°metros ‚Ä¢ Contexto: 8 192 tokens**

Modelo compacto de IBM especializado en seguridad y cumplimiento, detectando riesgos y contenido inapropiado.

**Especificaciones t√©cnicas:**
- **Licencia**: [Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚ùå Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚úÖ Seguridad

---

### Granite 3 Guardian 8B
**IBM ‚Ä¢ 8B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo de IBM especializado en seguridad y cumplimiento, ofreciendo capacidades avanzadas de detecci√≥n de riesgos.

**Especificaciones t√©cnicas:**
- **Licencia**: [Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚ùå Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚úÖ Seguridad

---

### Qwen 2.5 0.5B
**Equipo Qwen ‚Ä¢ 0.5B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Micromodelo ultra-ligero de la familia Qwen 2.5, dise√±ado para m√°xima eficiencia en dispositivos limitados.

**Especificaciones t√©cnicas:**
- **Velocidad**: 57 tokens/segundo tokens/segundo ‚ö°
- **Consumo**: 0,95 kWh/mill√≥n de tokens üå±
- **Licencia**: [Licencia MIT](./licences/qwen2.5_0.5b.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚ùå Seguridad

---

### Qwen 2.5 1.5B
**Equipo Qwen ‚Ä¢ 1.5B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo muy compacto de la familia Qwen 2.5, ofreciendo un buen equilibrio entre rendimiento y tama√±o para despliegues ligeros.

**Especificaciones t√©cnicas:**
- **Velocidad**: 94 tokens/segundo tokens/segundo ‚ö°
- **Consumo**: 0,58 kWh/mill√≥n de tokens üå±
- **Licencia**: [Licencia MIT](./licences/qwen2.5_1.5b.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚ùå Seguridad

---

### Qwen 2.5 14B
**Equipo Qwen ‚Ä¢ 14B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo vers√°til de tama√±o medio de la familia Qwen 2.5, buen equilibrio entre rendimiento y recursos.

**Especificaciones t√©cnicas:**
- **Velocidad**: 61 tokens/segundo tokens/segundo ‚ö°
- **Consumo**: 3,0 kWh/mill√≥n de tokens
- **Licencia**: [Licencia MIT](./licences/qwen2.5_14b.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚ùå Seguridad

---

### Qwen 2.5 32B
**Equipo Qwen ‚Ä¢ 32B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo potente de la familia Qwen 2.5, ofreciendo capacidades avanzadas en comprensi√≥n y generaci√≥n.

**Especificaciones t√©cnicas:**
- **Velocidad**: 32 tokens/segundo tokens/segundo
- **Consumo**: 5,73 kWh/mill√≥n de tokens
- **Licencia**: [Licencia MIT](./licences/qwen2.5_32b.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚ùå Seguridad

---

### Qwen 2.5 3B
**Equipo Qwen ‚Ä¢ 3B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo compacto y eficiente de la familia Qwen 2.5, adaptado para tareas generales en recursos limitados.

**Especificaciones t√©cnicas:**
- **Velocidad**: 60 tokens/segundo tokens/segundo ‚ö°
- **Consumo**: 0,9 kWh/mill√≥n de tokens üå±
- **Licencia**: [Licencia MIT](./licences/qwen2.5_3b.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚ùå Seguridad

---

### Qwen3 0.6b
**Equipo Qwen ‚Ä¢ 0.6B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo compacto y eficiente de la familia Qwen3, adaptado para tareas generales en recursos limitados.

**Especificaciones t√©cnicas:**
- **Velocidad**: 60 tokens/segundo tokens/segundo ‚ö°
- **Consumo**: 0,9 kWh/mill√≥n de tokens üå±
- **Licencia**: [Licencia Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚ùå Seguridad

---

### Qwen3 1.7b
**Equipo Qwen ‚Ä¢ 1.7B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo muy compacto de la familia Qwen3, ofreciendo un buen equilibrio entre rendimiento y tama√±o para despliegues ligeros.

**Especificaciones t√©cnicas:**
- **Velocidad**: 83 tokens/segundo tokens/segundo ‚ö°
- **Consumo**: 0,65 kWh/mill√≥n de tokens üå±
- **Licencia**: [Licencia Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚ùå Seguridad

---

### Qwen3 4b
**Equipo Qwen ‚Ä¢ 4B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo compacto de la familia Qwen3 que ofrece excelentes rendimientos en un formato ligero y econ√≥mico.

**Especificaciones t√©cnicas:**
- **Velocidad**: 48 tokens/segundo tokens/segundo
- **Consumo**: 1,13 kWh/mill√≥n de tokens üå±
- **Licencia**: [Licencia Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚ùå Seguridad

---

### Qwen3 8b
**Equipo Qwen ‚Ä¢ 8B par√°metros ‚Ä¢ Contexto: 32 000 tokens**

Modelo Qwen3 8B que ofrece un buen equilibrio entre rendimiento y eficiencia para tareas generales.

**Especificaciones t√©cnicas:**
- **Velocidad**: 29 tokens/segundo tokens/segundo
- **Consumo**: 1,87 kWh/mill√≥n de tokens üå±
- **Licencia**: [Licencia Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚ùå Seguridad

---

### Qwen2.5-VL 3B
**Equipo Qwen ‚Ä¢ 3.8B par√°metros ‚Ä¢ Contexto: 128 000 tokens**

Modelo Vision-Lenguaje compacto, soluci√≥n eficiente para IA en el borde (edge AI).

**Especificaciones t√©cnicas:**
- **Velocidad**: 65 tokens/segundo tokens/segundo ‚ö°
- **Consumo**: 0,83 kWh/mill√≥n de tokens üå±
- **Licencia**: [Licencia Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚úÖ Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚ùå Seguridad

---

### Qwen2.5-VL 7B
**Equipo Qwen ‚Ä¢ 7B (8.3B) par√°metros ‚Ä¢ Contexto: 128 000 tokens**

Modelo Vision-Lenguaje eficiente, superando a GPT-4o-mini en ciertas tareas.

**Especificaciones t√©cnicas:**
- **Velocidad**: 37 tokens/segundo tokens/segundo
- **Consumo**: 1,46 kWh/mill√≥n de tokens üå±
- **Licencia**: [Licencia Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚úÖ Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚ùå Seguridad

---

### Foundation-Sec-8B
**Foundation AI ‚Äî Cisco ‚Ä¢ 8B par√°metros ‚Ä¢ Contexto: 16 000 tokens**

Modelo de lenguaje especializado en ciberseguridad, optimizado para eficiencia.

**Especificaciones t√©cnicas:**
- **Velocidad**: 22 tokens/segundo tokens/segundo
- **Consumo**: 2,46 kWh/mill√≥n de tokens
- **Licencia**: [Licencia Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚ùå Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚úÖ Razonamiento ‚Ä¢ ‚úÖ Seguridad

---

### devstral 24B
**Mistral AI & All Hands AI ‚Ä¢ 24B par√°metros ‚Ä¢ Contexto: 120 000 tokens**

Devstral es un LLM agente para tareas de ingenier√≠a de software.

**Especificaciones t√©cnicas:**
- **Velocidad**: 53 tokens/segundo tokens/segundo ‚ö°
- **Consumo**: 4,5 kWh/mill√≥n de tokens
- **Licencia**: [Licencia Apache 2.0](./licences/apache2.licence.md)
- **Localizaci√≥n**: FR üá´üá∑

**Capacidades:**
‚úÖ Herramientas/Agente ‚Ä¢ ‚ùå Visi√≥n ‚Ä¢ ‚ùå Razonamiento ‚Ä¢ ‚úÖ Seguridad

**Casos de uso:**
- Exploraci√≥n y modificaci√≥n de bases de c√≥digo
- Agentic
- Europeo

---

## Casos de uso recomendados

### Di√°logo multiling√ºe

Chatbots y asistentes capaces de comunicarse en varios idiomas con detecci√≥n autom√°tica, mantenimiento del contexto a lo largo de la conversaci√≥n y comprensi√≥n de las especificidades ling√º√≠sticas

**Modelos recomendados:**

- Llama 3.3
- Mistral Small 3.1
- Qwen 2.5
- Granite 3.3

### An√°lisis de documentos largos

Procesamiento de documentos voluminosos (>100 p√°ginas) con mantenimiento del contexto a lo largo del texto, extracci√≥n de informaci√≥n clave, generaci√≥n de res√∫menes pertinentes y respuesta a preguntas espec√≠ficas sobre el contenido

**Modelos recomendados:**

- Gemma 3
- DeepSeek-R1
- Granite 3.3

### Programaci√≥n y desarrollo
Generaci√≥n y optimizaci√≥n de c√≥digo en m√∫ltiples lenguajes, depuraci√≥n, refactorizaci√≥n, desarrollo de funciones completas, comprensi√≥n de implementaciones algor√≠tmicas complejas y creaci√≥n de pruebas unitarias

**Modelos recomendados:**

- DeepCoder
- QwQ
- DeepSeek-R1
- Granite 3.3
- Devstral

### An√°lisis visual
Procesamiento directo de im√°genes y documentos visuales sin preprocesamiento OCR, interpretaci√≥n de diagramas t√©cnicos, gr√°ficos, tablas, dibujos y fotos con generaci√≥n de explicaciones textuales detalladas del contenido visual

**Modelos recomendados:**

- Granite 3.2 Vision
- Mistral Small 3.1
- Gemma 3
- Qwen2.5-VL

### Seguridad y cumplimiento

Aplicaciones que requieren capacidades espec√≠ficas en materia de seguridad; filtrado de contenido sensible, trazabilidad de los razonamientos, verificaci√≥n RGPD/HDS, minimizaci√≥n de riesgos, an√°lisis de vulnerabilidades y cumplimiento de regulaciones sectoriales

**Modelos recomendados:**

- Granite Guardian
- Granite 3.3
- Devstral
- Mistral Small 3.1
- Foundation-Sec-8B

### Despliegues ligeros y embebidos

Aplicaciones que requieren una huella m√≠nima en recursos, despliegue en dispositivos con capacidad limitada, inferencia en tiempo real en CPU est√°ndar e integraci√≥n en sistemas embebidos o IoT

**Modelos recomendados:**

- Gemma 3
- Granite 3.1 MoE
- Granite Guardian
- Granite 3.3