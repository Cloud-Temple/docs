# Contexte LLMaaS - LLM as a Service Cloud Temple

## Service Overview

**LLMaaS (Large Language Model as a Service)** est l'offre Cloud Temple d√©di√©e √† l'intelligence artificielle g√©n√©rative, proposant **40 mod√®les** de langage large en conformit√© **SecNumCloud + HDS + Souverainet√© + C5**.

### Positionnement Strat√©gique
- **Premier cloud souverain fran√ßais** proposant des LLM SecNumCloud
- **40 mod√®les** : du micro-mod√®le (278M) au mod√®le extr√™mement large (235B)
- **Localisation 100% France** üá´üá∑
- **Conformit√© maximale** : SecNumCloud ‚úÖ HDS ‚úÖ Souverainet√© ‚úÖ C5 ‚ùå

## Architecture Documentation

### Structure `docs/llmaas/`
```
docs/llmaas/
‚îú‚îÄ‚îÄ llmaas.md              # Vue d'ensemble service
‚îú‚îÄ‚îÄ models.md              # Catalogue des mod√®les
‚îú‚îÄ‚îÄ api.md                 # Documentation API REST (Tiers, Endpoints, Facturation)
‚îú‚îÄ‚îÄ concepts.md            # Architecture technique, Tokens, S√©curit√©
‚îú‚îÄ‚îÄ quickstart.md          # Guide de d√©marrage (cURL, Python, Tool Calling, Vision)
‚îú‚îÄ‚îÄ tutorials.md           # Guides avanc√©s (LangChain, RAG, Qdrant, Agents)
‚îú‚îÄ‚îÄ ocr.md                 # [NOUVEAU] Guide DeepSeek-OCR
‚îú‚îÄ‚îÄ rag_explained.md       # [NOUVEAU] Explication d√©taill√©e du RAG
‚îú‚îÄ‚îÄ faq.md                 # Foire aux questions
‚îú‚îÄ‚îÄ images/                # Screenshots et sch√©mas
‚îî‚îÄ‚îÄ licences/              # Licences des mod√®les
```

## Mod√®le √âconomique et Tiers

### Le Principe des Tiers
L'offre est structur√©e en 4 tiers d√©finissant un √©quilibre entre :
1.  **Cr√©dit d'Achat (Upfront)** : Montant √† r√©gler pour activer le service.
2.  **Limite Mensuelle** : Plafond de consommation pour ma√Ætriser les co√ªts.
3.  **Capacit√© Technique** : Limites de d√©bit (tokens/jour et tokens/heure).

| Tier | Cr√©dit d'Achat | Limite Mensuelle | Tokens Output/Heure | Tokens Output/Jour | Description |
|------|----------------|-------------------|---------------------|--------------------|-----------|
| **Tier 1** | 200 ‚Ç¨ | 1 000 ‚Ç¨ | 150 000 | 3 600 000 | Utilisation standard |
| **Tier 2** | 500 ‚Ç¨ | 3 000 ‚Ç¨ | 300 000 | 7 200 000 | Usage professionnel |
| **Tier 3** | 1 000 ‚Ç¨ | 5 000 ‚Ç¨ | 450 000 | 10 800 000 | Volume √©lev√© |
| **Tier 4** | 4 000 ‚Ç¨ | 10 000 ‚Ç¨ | 600 000 | 14 400 000 | Entreprise |

### Tarification √† l'Usage
- **Tokens d'entr√©e** : 0.90 ‚Ç¨ / million
- **Tokens de sortie (standard)** : 4.00 ‚Ç¨ / million
- **Tokens de sortie (raisonneur)** : 21.00 ‚Ç¨ / million
- **Transcription Audio** : 0.01 ‚Ç¨ / minute

## Fonctionnalit√©s Techniques

### Endpoints API
- **Chat Completions** (`POST /v1/chat/completions`) : G√©n√©ration de texte, compatible OpenAI. Supporte le mode "Tool Calling" et le Streaming (SSE).
- **Completions** (`POST /v1/completions`) : Compl√©tion de texte simple.
- **Embeddings** (`POST /v1/embeddings`) : Vectorisation de texte (mod√®le `granite-embedding:278m`).
- **Audio Transcription** (`POST /v1/audio/transcriptions`) : Speech-to-Text (Whisper).
- **Vision Multimodale** : Support de l'analyse d'images via `image_url` dans les messages.
- **OCR Avanc√©** : Support sp√©cifique via DeepSeek-OCR pour l'analyse de documents complexes (tableaux, formules).

### S√©curit√© et Conformit√©
- **Protection des Donn√©es** : Chiffrement TLS 1.3 (transit) et AES-256 (repos).
- **Analyse des Prompts** : Syst√®me natif de d√©tection d'injections de prompts (analyse structurelle, patterns suspects, comportementale).
- **Non-conservation** : Pas de stockage des prompts/r√©ponses (traitement volatile).
- **Authentification** : Bearer tokens avec rotation automatique.

### Int√©grations
- **Compatible OpenAI** : Drop-in replacement pour les SDKs existants.
- **Frameworks support√©s** : LangChain, LlamaIndex, Haystack, Semantic Kernel.
- **Outils** : Jupyter, Streamlit, Gradio.

## Catalogue de Mod√®les

### R√©sum√© du Catalogue (40 mod√®les)
- **Grande Taille** : Llama 3.3 70B, Qwen3 235B, Qwen2.5-VL 72B.
- **Interm√©diaire** : Gemma 3 27B, Qwen3 32B, DeepSeek-R1 32B, Cogito 32B.
- **Code & Raisonnement** : QwQ 32B, Qwen3-Coder 30B, DeepCoder 14B, Magistral 24B.
- **Compact & Efficient** : Gemma 3 4B/1B, Granite 3.3 8B/2B, Qwen3 4B/1.7B/0.6B.
- **Vision** : Qwen2.5-VL, Granite 3.2 Vision, Mistral Small 3.2.
- **S√©curit√©** : Granite Guardian.
- **Embedding** : Granite Embedding 278m.

### Cycle de Vie
- **DMP (Mise en Production)** et **DSP (Fin de Support)** clairement d√©finies.
- Politique de d√©pr√©ciation avec pr√©avis de 3 mois.
- Mod√®les d√©pr√©ci√©s list√©s (ex: Llama 3.1, Qwen 2.5 anciens).

## Architecture Technique

### Infrastructure
- **Localisation** : 100% France (Datacenters Cloud Temple).
- **Mat√©riel** : 12 machines GPU, Load Balancing intelligent.
- **API Gateway** : Gestion du Rate Limiting, Auth, Monitoring.

### Sch√©ma de Flux
[Client] -> [API Gateway (Auth, RateLimit, Security Check)] -> [Load Balancer] -> [GPU Cluster (Inf√©rence)]

## Workflows et Processus

### G√©n√©ration Documentation
La documentation des mod√®les est g√©n√©r√©e automatiquement √† partir de `memory-bank/models_config.yaml` via le script `scripts/generate_models_doc/generate_models_doc.py`.

### RAG Pipeline
Documentation compl√®te sur l'impl√©mentation de RAG (Retrieval-Augmented Generation) :
- Explication conceptuelle (Embeddings, Recherche vectorielle).
- Tutoriels pratiques avec LangChain (FAISS, Qdrant).

---

*Contexte LLMaaS Cloud Temple - Documentation technique compl√®te*
*Derni√®re mise √† jour : 22/11/2025 - Int√©gration Tiers, OCR, RAG et mise √† jour catalogue.*

## Mod√®les D√©pr√©ci√©s (mise √† jour)

| Mod√®le | √âditeur | Phase | Date de D√©pr√©ciation |
| :--- | :--- | :--- | :--- |
| qwen3:235b |  | D√©pr√©ci√© | 22/11/2025 |
| qwen3-2507-think:30b-a3b |  | D√©pr√©ci√© | 14/11/2025 |
| gemma3:12b |  | D√©pr√©ci√© | 21/11/2025 |
