# Configuration des mod√®les Cloud Temple MaaS
# Ce fichier d√©crit tous les mod√®les disponibles dans l'offre LLM as a Service

# Statistiques globales
stats:
  total_models: 41 # Mis √† jour
  min_context: 8192 # Granite Guardian 2B
  max_context: 262144 # Qwen3 4B
  pricing_input: 0.9
  pricing_output: 4
  pricing_reasoning: 21
  pricing_audio: 0.01 # Par minutes
  secnumcloud: true
  hds: true
  sovereign: true

# Mod√®les de grande taille
large_models:
  - name: gpt-oss:120b
    editor: OpenAI
    location: FR üá´üá∑
    parameters: 120
    parameters_string: 120B
    context_size: 120000
    speed: 140 tokens/seconde
    energy_per_million_tokens: 1.69
    licence: Apache 2.0
    description: Mod√®le de langage open-weight de pointe d'OpenAI, offrant de solides performances avec une licence flexible Apache 2.0.
    details: Un mod√®le Mixture-of-Experts (MoE) de 120 milliards de param√®tres avec environ 5.1 milliards de param√®tres actifs. Il offre un effort de raisonnement configurable et un acc√®s complet √† la cha√Æne de pens√©e.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - MoE
      - Agent
      - Raisonnement
      - Open-Source
      - Tr√®s Large
    use_cases:
      - Agents conversationnels avanc√©s avec raisonnement complexe et int√©gration d'outils.
      - Applications n√©cessitant une transparence totale du processus de raisonnement (chain-of-thought).
      - Sc√©narios commerciaux n√©cessitant une licence permissive (Apache 2.0).
      - Fine-tuning pour des t√¢ches sp√©cialis√©es n√©cessitant un mod√®le de base puissant.

  - name: llama3.3:70b
    editor: Meta
    dsp: 31/12/2026
    location: FR üá´üá∑
    parameters: 70
    parameters_string: 70B
    context_size: 132000
    speed: 31 tokens/seconde
    energy_per_million_tokens: 8.58
    licence: LLAMA 3.3 Community Licence
    description: Mod√®le multilingue de pointe d√©velopp√© par Meta, con√ßu pour exceller dans le dialogue naturel, le raisonnement complexe et la compr√©hension nuanc√©e des instructions.
    details: Combinant une efficacit√© remarquable avec des ressources computationnelles r√©duites, ce mod√®le offre des capacit√©s multilingues √©tendues couvrant 8 langues majeures (anglais, fran√ßais, allemand, espagnol, italien, portugais, hindi et tha√Ø). Sa fen√™tre contextuelle de 132 000 tokens permet l'analyse approfondie de documents complexes et de conversations longues, tout en maintenant une coh√©rence globale exceptionnelle. Optimis√© pour minimiser les biais et les r√©ponses probl√©matiques.
    supports_tools: true
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: false
    tags:
      - Agent
      - Dialogue
      - Multilingue
    use_cases:
      - Chatbots multilingues prenant en charge 8 langues simultan√©ment
      - Ex√©cution d'instructions complexes encha√Æn√©es (prompt chaining)
      - Traitement d'une fen√™tre de dialogue de 60K tokens pour historique conversationnel
      - Analyse de documents juridiques ou techniques volumineux (>100 pages)
      - G√©n√©ration de textes structur√©s avec fid√©lit√© aux consignes stylistiques

  - name: gemma3:27b
    editor: Google
    dsp: 30/03/2026
    location: FR üá´üá∑
    parameters: 27
    parameters_string: 27B
    context_size: 120000
    speed: 24 tokens/seconde
    energy_per_million_tokens: 5.56
    licence: Google Gemma Terms of Use
    description: Mod√®le r√©volutionnaire de Google offrant un √©quilibre optimal entre puissance et efficacit√©, avec un rapport performance/co√ªt exceptionnel pour les applications professionnelles exigeantes.
    details: Dot√© d'une efficacit√© mat√©rielle in√©gal√©e, ce mod√®le int√®gre des capacit√©s multimodales natives et excelle dans la performance multilingue sur plus de 140 langues. Sa fen√™tre contextuelle impressionnante de 120 000 tokens en fait le choix id√©al pour l'analyse de documents tr√®s volumineux, la recherche documentaire, et toute application n√©cessitant la compr√©hension de contextes √©tendus. Son architecture optimis√©e permet un d√©ploiement flexible sans compromettre la qualit√© des r√©sultats.
    supports_tools: true
    supports_vision: true
    supports_reasoning: false
    supports_security: false
    is_fast: false
    tags:
      - Vision
      - Agent
      - Grand contexte
    use_cases:
      - Analyse de documents avec contexte √©tendu jusqu'√† 120K tokens (environ 400 pages)
      - Indexation et recherche s√©mantique dans des bases documentaires volumineuses
      - Traitement d'images et texte en simultan√© gr√¢ce aux capacit√©s multimodales
      - Extraction structur√©e de donn√©es √† partir de PDF et documents scann√©s
      - Int√©gration avec des outils externes via l'API function calling

  - name: qwen3-coder:30b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 30
    parameters_string: 30B
    context_size: 250000
    speed: 84 tokens/seconde
    energy_per_million_tokens: 3.14
    licence: Apache 2.0
    description: Mod√®le MoE optimis√© pour les t√¢ches d'ing√©nierie logicielle, avec un contexte tr√®s long.
    details: Capacit√©s agentiques avanc√©es pour les t√¢ches de g√©nie logiciel, support natif d'un contexte de 250K tokens, pr√©-entra√Æn√© sur 7.5T tokens avec un fort ratio de code, et optimis√© par apprentissage par renforcement pour am√©liorer les taux d'ex√©cution de code.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - Agent
      - Programmation
      - Grand Contexte
      - MoE
    use_cases:
      - Agents d'ing√©nierie logicielle pour explorer et modifier des bases de code
      - G√©n√©ration de code complexe avec compr√©hension √† l'√©chelle du d√©p√¥t (repository-scale)
      - T√¢ches de raisonnement sur des contextes √©tendus
      - Am√©lioration de code via apprentissage par renforcement

  - name: qwen3-2507:30b-a3b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 30
    parameters_string: 30B
    context_size: 250000
    speed: 118 tokens/seconde
    energy_per_million_tokens: 1.65
    licence: Apache 2.0
    description: Version am√©lior√©e du mode non-pens√©e de Qwen3-30B, avec des capacit√©s g√©n√©rales, une couverture de connaissances et un alignement utilisateur am√©lior√©s.
    details: Am√©liorations significatives du suivi d'instructions, du raisonnement, de la compr√©hension de texte, des math√©matiques, du codage et de l'utilisation d'outils. Contexte natif de 250k tokens. 
    supports_tools: true
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Agent
      - Grand Contexte
      - MoE
      - Multilingue
    use_cases:
      - T√¢ches complexes n√©cessitant un suivi d'instructions pr√©cis et un raisonnement logique.
      - Applications multilingues avec une large couverture de connaissances.
      - G√©n√©ration de texte de haute qualit√© pour des t√¢ches ouvertes et subjectives.
      - Analyse de documents tr√®s volumineux gr√¢ce au contexte de 250k tokens.

  - name: qwen3:30b-a3b
    editor: Qwen Team
    dsp: 31/12/2026
    location: FR üá´üá∑
    parameters: 30
    parameters_string: 30B
    context_size: 32000
    speed: 118 tokens/seconde
    energy_per_million_tokens: 1.65
    licence: Apache 2.0
    description: Derni√®re g√©n√©ration des mod√®les Qwen, offrant des am√©liorations significatives en termes de donn√©es d'entra√Ænement, d'architecture et d'optimisation.
    details: Pr√©-entra√Æn√© sur 36T de tokens dans 119 langues. Mod√®le MoE (Mixture-of-Experts) avec 128 experts dont 8 activ√©s par token. 
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Agent
      - Programmation
      - Multilingue
      - MoE
    use_cases:
      - T√¢ches de raisonnement complexes et g√©n√©ration de code.
      - Applications multilingues n√©cessitant une large couverture linguistique.
      - Sc√©narios n√©cessitant un bon √©quilibre entre performance et efficacit√© des ressources gr√¢ce √† l'architecture MoE.

  - name: qwen2.5vl:32b
    editor: Qwen Team
    dsp: 31/12/2025
    location: FR üá´üá∑
    parameters: 32
    parameters_string: 32B
    context_size: 120000
    speed: 22 tokens/seconde
    energy_per_million_tokens: 6.06
    licence: Apache 2.0
    description: Version la plus puissante de la s√©rie Qwen2.5-VL, offrant des capacit√©s de compr√©hension visuelle et d'agentique de pointe.
    details: Ce mod√®le vision-langage de 32 milliards de param√®tres est con√ßu pour les t√¢ches les plus exigeantes, combinant une compr√©hension visuelle profonde avec des capacit√©s de raisonnement avanc√©es pour interagir avec des interfaces graphiques et analyser des documents complexes.
    supports_tools: true
    supports_vision: true
    supports_reasoning: false
    supports_security: false
    is_fast: false
    tags:
      - Vision
      - Agent
      - Raisonnement
      - OCR
      - Localisation Visuelle
      - Large
    use_cases:
      - Analyse de documents et de diagrammes tr√®s complexes
      - Agents visuels autonomes pour la navigation et l'interaction avec des GUI
      - T√¢ches de localisation d'objets et de reconnaissance de texte de haute pr√©cision
      - G√©n√©ration de descriptions riches et d√©taill√©es √† partir d'images complexes

  - name: qwen2.5vl:72b
    editor: Qwen Team
    dsp: 31/12/2025
    location: FR üá´üá∑
    parameters: 72
    parameters_string: 72B
    context_size: 128000
    speed: 13 tokens/seconde
    energy_per_million_tokens: 10.26
    licence: Apache 2.0
    description: Version la plus puissante de la s√©rie Qwen2.5-VL, offrant des capacit√©s de compr√©hension visuelle et d'agentique de pointe pour les t√¢ches les plus exigeantes.
    details: Ce mod√®le vision-langage de 72 milliards de param√®tres est con√ßu pour les t√¢ches les plus exigeantes, combinant une compr√©hension visuelle profonde avec des capacit√©s de raisonnement avanc√©es pour interagir avec des interfaces graphiques et analyser des documents complexes.
    supports_tools: true
    supports_vision: true
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Vision
      - Agent
      - Raisonnement
      - OCR
      - Localisation Visuelle
      - Tr√®s Large
    use_cases:
      - Analyse de documents et de diagrammes tr√®s complexes
      - Agents visuels autonomes pour la navigation et l'interaction avec des GUI
      - T√¢ches de localisation d'objets et de reconnaissance de texte de tr√®s haute pr√©cision
      - G√©n√©ration de descriptions riches et d√©taill√©es √† partir d'images tr√®s complexes

  - name: qwen3-next:80b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 80
    parameters_string: 80B
    context_size: 262144
    speed: 59 tokens/seconde
    energy_per_million_tokens: 3.30
    licence: Apache 2.0
    description: Mod√®le Next 80B FP8 de Qwen, optimis√© pour les grands contextes et le raisonnement, servi via vLLM (A100).
    details: Variante A3B-Instruct en FP8, configur√©e avec un contexte jusqu'√† 262k tokens, prise en charge du function calling, guided decoding (xgrammar) et sp√©culative (qwen3_next_mtp). D√©ploy√© sur 2√óA100 avec vLLM.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - Agent
      - Raisonnement
      - Grand Contexte
      - MoE
    use_cases:
      - Agents conversationnels avanc√©s avec int√©gration d'outils
      - Analyse de documents tr√®s volumineux (jusqu'√† 260k tokens)
      - G√©n√©ration de code et t√¢ches complexes n√©cessitant raisonnement structur√©

# Mod√®les sp√©cialis√©s
specialized_models:
  - name: embeddinggemma:300m
    editor: Google
    location: FR üá´üá∑
    parameters: 0.3
    parameters_string: 300M
    context_size: 2048
    licence: Google Gemma Terms of Use
    description: Mod√®le d'embedding de pointe de Google, optimis√© pour sa taille, id√©al pour les t√¢ches de recherche et de r√©cup√©ration s√©mantique.
    details: Construit sur Gemma 3, ce mod√®le produit des repr√©sentations vectorielles de texte pour la classification, le clustering et la recherche de similarit√©. Entra√Æn√© sur plus de 100 langues, sa petite taille le rend parfait pour les environnements √† ressources limit√©es.
    supports_tools: false
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Embedding
      - Compact
      - S√©mantique
      - Efficient
      - Multilingue
    use_cases:
      - Recherche et r√©cup√©ration d'informations (Retrieval)
      - Classification et clustering de documents
      - Recherche de similarit√© s√©mantique
      - D√©ploiement sur des appareils √† ressources limit√©es (mobile, laptop)

  - name: gpt-oss:20b
    editor: OpenAI
    location: FR üá´üá∑
    parameters: 20
    parameters_string: 20B
    context_size: 120000
    speed: 85 tokens/seconde
    energy_per_million_tokens: 1.57
    licence: Apache 2.0
    description: Mod√®le de langage open-weight d'OpenAI, optimis√© pour l'efficacit√© et le d√©ploiement sur du mat√©riel grand public.
    details: Un mod√®le Mixture-of-Experts (MoE) de 21 milliards de param√®tres avec 3.6 milliards de param√®tres actifs. Il offre un effort de raisonnement configurable et des capacit√©s d'agent.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - MoE
      - Agent
      - Raisonnement
      - Open-Source
      - Compact
      - Rapide
    use_cases:
      - D√©ploiements sur des appareils √† ressources limit√©es (edge devices) ou des serveurs √† faible co√ªt.
      - Applications n√©cessitant une inf√©rence rapide avec de bonnes capacit√©s de raisonnement.
      - Cas d'usage agentiques avec appel de fonctions, navigation web et ex√©cution de code.
      - Fine-tuning pour des t√¢ches sp√©cialis√©es sur du mat√©riel grand public.

  - name: qwen3:14b
    editor: Qwen Team
    dsp: 31/12/2025
    location: FR üá´üá∑
    parameters: 14
    parameters_string: 14B
    context_size: 32000
    speed: 44 tokens/seconde
    energy_per_million_tokens: 3.03
    licence: Apache 2.0
    description: Mod√®le dense nouvelle g√©n√©ration Qwen3 (14B), offrant des performances √©quivalentes √† Qwen2.5 32B avec une meilleure efficacit√©.
    details: Fait partie de la s√©rie Qwen3, entra√Æn√© sur ~36T tokens. Capacit√©s am√©lior√©es en raisonnement, code, maths et agent (outils/MCP). Supporte plus de 100 langues et les modes de pens√©e hybrides.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - Agent
      - Raisonnement
      - Rapide
      - Multilingue
    use_cases:
      - T√¢ches g√©n√©rales n√©cessitant performance et grand contexte
      - G√©n√©ration de contenu cr√©atif et technique
      - Analyse de donn√©es et raisonnement complexe
      - Int√©gration avec des outils externes via function calling

  - name: gemma3:4b
    editor: Google
    dsp: 31/12/2025
    location: FR üá´üá∑
    parameters: 4
    parameters_string: 4B
    context_size: 120000
    speed: 60 tokens/seconde
    energy_per_million_tokens: 0.55
    licence: Google Gemma Terms of Use
    description: Mod√®le compact de Google offrant d'excellentes performances dans un format l√©ger et √©conomique.
    details: Cette version compacte du mod√®le Gemma 3 est optimis√©e pour les d√©ploiements avec contraintes de ressources tout en maintenant des performances remarquables pour sa taille. Son architecture efficiente permet une inf√©rence rapide sur du mat√©riel standard, id√©ale pour les applications n√©cessitant r√©activit√© et d√©ploiement √† grande √©chelle. Malgr√© sa taille r√©duite, il maintient des capacit√©s multimodales pour traiter √† la fois texte et images.
    supports_tools: false
    supports_vision: true
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Vision
      - Rapide
      - Compact
      - Grand Contexte
      - Efficient
    use_cases:
      - Applications embarqu√©es et edge computing avec traitement d'images
      - Chatbots multimodaux r√©actifs n√©cessitant une faible latence
      - D√©ploiements √† grande √©chelle avec capacit√©s visuelles et textuelles
      - Applications mobiles avec analyse d'images et textes
      - Traitement de requ√™tes visuelles simples √† moyenne complexit√© avec haute performance

  - name: gemma3:1b
    editor: Google
    dsp: 31/12/2025
    location: FR üá´üá∑
    parameters: 1
    parameters_string: 1B
    context_size: 32000
    speed: 115 tokens/seconde
    energy_per_million_tokens: 0.15
    licence: Google Gemma Terms of Use
    description: Micro-mod√®le ultra-l√©ger con√ßu pour les d√©ploiements sur appareils √† tr√®s faibles ressources.
    details: Ce mod√®le ultra-compact repr√©sente la quintessence de l'efficience, permettant des d√©ploiements dans des environnements extr√™mement contraints en ressources. Malgr√© sa taille minimale, il offre des capacit√©s de base surprenantes pour des t√¢ches textuelles simples √† mod√©r√©es, avec une vitesse d'inf√©rence exceptionnelle. Il prend √©galement en charge l'int√©gration avec des outils externes via function calling.
    supports_tools: false
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Ultra-compact
      - Embarqu√©
      - Efficient
      - Rapide
    use_cases:
      - D√©ploiement sur appareils IoT et syst√®mes embarqu√©s avec int√©gration API
      - Applications n√©cessitant inf√©rence locale sur CPU avec appels √† des fonctions
      - T√¢ches textuelles basiques avec temps de r√©ponse instantan√© et function calling
      - Assistants compacts pour applications grand public avec int√©gration services externes
      - Syst√®mes de contr√¥le intelligents int√©grant plusieurs APIs/services


  - name: mistral-small3.1:24b
    editor: Mistral AI
    dsp: 31/12/2025
    location: FR üá´üá∑
    parameters: 24
    parameters_string: 24B
    context_size: 120000
    speed: 34 tokens/seconde
    energy_per_million_tokens: 3.83
    licence: Apache 2.0
    description: Mod√®le compact et r√©actif de Mistral AI, sp√©cialement con√ßu pour offrir une assistance conversationnelle fluide et pertinente avec une vitesse de r√©ponse optimale.
    details: Malgr√© sa taille mod√©r√©e, ce mod√®le affiche une performance remarquable qui rivalise avec celle de nombreux mod√®les propri√©taires bien plus volumineux. Son architecture ing√©nieusement optimis√©e facilite le d√©ploiement local sur des infrastructures vari√©es. Int√©grant des capacit√©s multimodales natives, il peut traiter √† la fois du texte et des images sans recourir √† des syst√®mes externes. Sa licence Apache 2.0 offre une flexibilit√© maximale pour les d√©ploiements commerciaux et les personnalisations, en faisant un choix id√©al pour les entreprises soucieuses d'√©quilibrer performance et contraintes l√©gales.
    supports_tools: true
    supports_vision: true
    supports_reasoning: false
    supports_security: true
    is_fast: false
    tags:
      - Vision
      - Agent
      - S√©curit√©
    use_cases:
      - Applications conversationnelles
      - Assistants virtuels combinant analyse d'images et texte (26 tokens/s)
      - Chatbots de support technique avec acc√®s √† la documentation technique
      - Outils de cr√©ation/√©dition de contenu avec r√©ponse imm√©diate (blogs, emails)
      - D√©ploiement sur infrastructures standard (24B de param√®tres)

  - name: mistral-small3.2:24b
    editor: Mistral AI
    dsp: 30/06/2026
    location: FR üá´üá∑
    parameters: 24
    parameters_string: 24B
    context_size: 128000
    speed: 56 tokens/seconde
    energy_per_million_tokens: 2.33
    licence: Apache 2.0
    description: Mise √† jour mineure de Mistral Small 3.1, am√©liorant le suivi d'instructions, la robustesse du function calling et r√©duisant les erreurs de r√©p√©tition.
    details: Cette version 3.2 conserve les forces de son pr√©d√©cesseur tout en apportant des am√©liorations cibl√©es. Elle est plus apte √† suivre des instructions pr√©cises, produit moins de g√©n√©rations infinies ou de r√©ponses r√©p√©titives, et son template pour le function calling est plus robuste. Pour les autres aspects, ses performances sont √©quivalentes ou l√©g√®rement sup√©rieures √† la version 3.1.
    supports_tools: true
    supports_vision: true
    supports_reasoning: false
    supports_security: true
    is_fast: false
    tags:
      - Vision
      - Agent
      - S√©curit√©
      - Instruction Following
    use_cases:
      - Agents conversationnels avec un suivi d'instructions am√©lior√©
      - Int√©gration robuste avec des outils externes via function calling
      - Applications n√©cessitant une grande fiabilit√© pour √©viter les r√©p√©titions
      - Cas d'usage identiques √† Mistral Small 3.1 avec des performances accrues

  - name: deepcoder:14b
    editor: Agentica x Together AI
    dsp: 30/12/2025
    location: FR üá´üá∑
    parameters: 14
    parameters_string: 14B
    context_size: 32000
    speed: 9 tokens/seconde
    energy_per_million_tokens: 3.72
    licence: Apache 2.0
    description: Mod√®le IA open source (14B) par Together AI & Agentica, alternative cr√©dible aux mod√®les propri√©taires pour la g√©n√©ration de code.
    details: Performances remarquables en g√©n√©ration de code et raisonnement algorithmique (60.6% LiveCodeBench Pass@1, 1936 Codeforces, 92.6% HumanEval+). Entra√Æn√© via RL (GRPO+) avec allongement progressif du contexte (32k -> 64k). Projet transparent (code, dataset, logs ouverts). Permet l'int√©gration de capacit√©s avanc√©es de g√©n√©ration de code sans d√©pendre de solutions propri√©taires.
    supports_tools: false
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - Programmation
      - Raisonnement
      - Open-Source
      - Math√©matiques
      - Rapide
    use_cases:
      - G√©n√©ration de code dans plus de 15 langages avec optimisation des performances
      - D√©bogage et refactoring de bases de code existantes avec analyse d'impact
      - Impl√©mentation d'algorithmes complexes (graphes, arbres, heuristiques)
      - Cr√©ation automatis√©e de tests unitaires avec couverture de code > 80%
      - Transposition de code entre langagesframeworks (par exemple Python vers JavaScript)


  - name: granite3.2-vision:2b
    editor: IBM
    dsp: 31/12/2026
    location: FR üá´üá∑
    parameters: 2
    parameters_string: 2B
    context_size: 16384
    speed: 88 tokens/seconde
    energy_per_million_tokens: 0.38
    licence: Apache 2.0
    description: Mod√®le compact r√©volutionnaire d'IBM sp√©cialis√© dans la vision par ordinateur, capable d'analyser et comprendre directement les documents visuels sans recourir √† des technologies OCR interm√©diaires.
    details: Ce mod√®le compact r√©alise l'exploit remarquable d'√©galer les performances de mod√®les bien plus volumineux sur un large √©ventail de t√¢ches de compr√©hension visuelle. Sa capacit√© √† interpr√©ter directement le contenu visuel des documents - textes, tableaux, graphiques et diagrammes - sans passer par une √©tape d'OCR traditionnelle repr√©sente une avanc√©e significative en termes d'efficacit√© et de pr√©cision. Cette approche int√©gr√©e r√©duit consid√©rablement les erreurs de reconnaissance et permet une compr√©hension plus contextuelle et plus nuanc√©e du contenu visuel.
    supports_tools: true
    supports_vision: true
    supports_reasoning: false
    supports_security: true
    is_fast: false
    tags:
      - Vision
      - S√©curit√©
      - Compact
      - Efficient
    use_cases:
      - Extraction de donn√©es structur√©es √† partir de factures et formulaires sans OCR
      - Analyse directe de tableaux et graphiques avec interpr√©tation des tendances
      - Lecture et interpr√©tation de diagrammes techniques (√©lectriques, m√©caniques)
      - Traitement de documents manuscrits avec taux de reconnaissance √©lev√©
      - Vision par ordinateur l√©g√®re (2B param√®tres) avec vitesse √©lev√©e (50 tokens/s)

  - name: granite3.3:8b
    editor: IBM
    dsp: 31/12/2025
    location: FR üá´üá∑
    parameters: 8
    parameters_string: 8B
    context_size: 60000
    speed: 39 tokens/seconde
    energy_per_million_tokens: 0.85
    licence: Apache 2.0
    description: Mod√®le Granite 8B fine-tun√© par IBM pour un raisonnement et un suivi d'instructions am√©lior√©s, avec un contexte de 128k tokens.
    details: Cette version 8B du mod√®le Granite 3.3 offre des gains significatifs sur les benchmarks g√©n√©riques (AlpacaEval-2.0, Arena-Hard) et des am√©liorations en math√©matiques, codage et suivi d'instructions. Il supporte 12 langues, le Fill-in-the-Middle (FIM) pour le code, le mode "Thinking" pour la r√©flexion structur√©e, et l'appel de fonctions. Licence Apache 2.0. Id√©al pour les t√¢ches g√©n√©rales et l'int√©gration dans des assistants IA.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: true
    is_fast: false
    tags:
      - Agent
      - Raisonnement
      - S√©curit√©
      - Efficient
    use_cases:
      - T√¢ches g√©n√©rales d'instruction-following (classification, extraction, Q&A)
      - Assistants IA multilingues (12 langues)
      - Traitement de documents tr√®s longs (128k tokens) pour les taches de r√©sum√©s, Q&A,...
      - G√©n√©ration/compl√©tion de code avec Fill-in-the-Middle
      - Int√©gration avec des outils externes via function calling
      - Raisonnement structur√© avec le mode "Thinking"

  - name: granite3.3:2b
    editor: IBM
    dsp: 31/12/2025
    location: FR üá´üá∑
    parameters: 2
    parameters_string: 2B
    context_size: 120000
    speed: 88 tokens/seconde
    energy_per_million_tokens: 0.38
    licence: Apache 2.0
    description: Mod√®le Granite 2B fine-tun√© par IBM, optimis√© pour le raisonnement et le suivi d'instructions, avec un contexte de 128k tokens.
    details: Version compacte de Granite 3.3 (2B param√®tres) offrant les m√™mes am√©liorations en raisonnement, instruction-following, math√©matiques et codage que la version 8B. Supporte 12 langues, le Fill-in-the-Middle (FIM), le mode "Thinking", et l'appel de fonctions. Licence Apache 2.0. Excellent choix pour des d√©ploiements l√©gers n√©cessitant de longues capacit√©s contextuelles et de raisonnement.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: true
    is_fast: false
    tags:
      - Agent
      - Raisonnement
      - S√©curit√©
      - Efficient
    use_cases:
      - D√©ploiements l√©gers avec grand contexte (128k tokens)
      - T√¢ches g√©n√©rales d'instruction-following sur ressources limit√©es
      - Assistants IA multilingues compacts
      - Traitement de documents longs sur appareils moins puissants
      - G√©n√©ration/compl√©tion de code FIM sur postes de travail standards

  - name: magistral:24b
    editor: Mistral AI
    dsp: 30/03/2025
    location: FR üá´üá∑
    parameters: 24
    parameters_string: 24B
    context_size: 40000
    speed: 29 tokens/seconde
    energy_per_million_tokens: 4.59
    licence: Apache 2.0
    description: Le premier mod√®le de raisonnement de Mistral AI, excellant dans le raisonnement sp√©cifique au domaine, transparent et multilingue.
    details: Id√©al pour une utilisation g√©n√©rale n√©cessitant un traitement de pens√©e plus long et une meilleure pr√©cision. Utile pour la recherche juridique, la pr√©vision financi√®re, le d√©veloppement de logiciels et la narration cr√©ative. R√©sout les d√©fis en plusieurs √©tapes o√π la transparence et la pr√©cision sont essentielles.
    supports_tools: false
    supports_vision: false
    supports_reasoning: true
    supports_security: true
    is_fast: false
    tags:
      - Raisonnement
      - Multilingue
    use_cases:
      - Strat√©gie et op√©rations commerciales (mod√©lisation des risques)
      - Industries r√©glement√©es (juridique, finance) avec raisonnement tra√ßable
      - Ing√©nierie logicielle (planification de projet, architecture)
      - Cr√©ation de contenu et communication (r√©daction cr√©ative, narration)

  - name: cogito:32b
    editor: Deep Cogito
    dsp: 30/06/2026
    location: FR üá´üá∑
    parameters: 32
    parameters_string: 32B
    context_size: 32000
    speed: 37 tokens/seconde
    energy_per_million_tokens: 7.13
    licence: LLAMA 3.2 Community Licence
    description: Version avanc√©e du mod√®le Cogito offrant des capacit√©s de raisonnement et d'analyse consid√©rablement amplifi√©es, con√ßue pour les applications les plus exigeantes en mati√®re d'intelligence artificielle analytique.
    details: Cette version √©tendue du mod√®le Cogito pousse encore plus loin les capacit√©s de raisonnement et de compr√©hension, offrant une profondeur d'analyse in√©gal√©e pour les applications les plus complexes. Sa conception architecturale sophistiqu√©e lui permet d'aborder des raisonnements multi-√©tapes avec rigueur et pr√©cision, tout en maintenant une coh√©rence globale remarquable. Id√©al pour les applications critiques n√©cessitant une intelligence artificielle capable d'un raisonnement nuanc√© et d'une compr√©hension contextuelle approfondie comparable aux analyses d'experts humains dans des domaines sp√©cialis√©s.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Agent
      - Raisonnement
      - Compr√©hension
      - Analyse
    use_cases:
      - Analyse de sc√©narios multi-factoriels avec √©valuation probabiliste des r√©sultats
      - R√©solution de probl√®mes scientifiques avec d√©monstration formelle des √©tapes
      - Applications √† haute criticit√© n√©cessitant pr√©cision et v√©rifiabilit√© des r√©sultats
      - Syst√®mes experts dans des domaines sp√©cialis√©s (juridique, m√©dical, technique)
      - Analyse avec raisonnement multi-√©tapes et explicabilit√© compl√®te des conclusions

  - name: qwen3:32b
    editor: Qwen Team
    dsp: 31/12/2025
    location: FR üá´üá∑
    parameters: 32
    parameters_string: 32B
    context_size: 40000
    speed: 21 tokens/seconde
    energy_per_million_tokens: 6.35
    licence: Apache 2.0
    description: Mod√®le puissant de la nouvelle g√©n√©ration Qwen3, offrant des capacit√©s avanc√©es en raisonnement, code, et agentique, avec un contexte √©tendu.
    details: Fait partie de la s√©rie Qwen3, entra√Æn√© sur un vaste corpus de donn√©es. Ce mod√®le de 32 milliards de param√®tres est con√ßu pour exceller dans les t√¢ches complexes, supporter plus de 100 langues et int√©grer des modes de pens√©e hybrides pour une meilleure performance.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Agent
      - Raisonnement
      - Multilingue
      - Grand Contexte
    use_cases:
      - Agents conversationnels avanc√©s avec grand contexte et int√©gration d'outils (MCP)
      - R√©solution de probl√®mes complexes (maths, code) avec mode "Thinking"
      - Analyse et g√©n√©ration de documents volumineux
      - Applications multilingues (>100 langues) n√©cessitant une compr√©hension profonde

  - name: qwq:32b
    editor: Qwen Team
    dsp: 31/12/2025
    location: FR üá´üá∑
    parameters: 32
    parameters_string: 32B
    context_size: 32000
    speed: 11 tokens/seconde
    energy_per_million_tokens: 23.99
    licence: Apache 2.0
    description: Mod√®le de 32 milliards de param√®tres am√©lior√© par apprentissage par renforcement (RL) pour exceller dans le raisonnement, le codage, les math√©matiques et les t√¢ches d'agent.
    details: Ce mod√®le utilise une approche RL innovante avec des r√©compenses bas√©es sur les r√©sultats (v√©rificateurs de pr√©cision pour les maths, ex√©cution de code pour le codage) et un entra√Ænement multi-√©tapes pour am√©liorer les capacit√©s g√©n√©rales sans d√©grader les performances sp√©cialis√©es. Il int√®gre des capacit√©s d'agent pour utiliser des outils et adapter son raisonnement. Licence Apache 2.0.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Agent
      - Raisonnement
      - Codage
      - Math√©matiques
    use_cases:
      - R√©solution de probl√®mes complexes n√©cessitant raisonnement et utilisation d'outils
      - G√©n√©ration et ex√©cution de code avec v√©rification des r√©sultats
      - T√¢ches math√©matiques avanc√©es avec v√©rification de l'exactitude
      - Applications d'agent capables d'interagir avec l'environnement
      - Instruction following am√©lior√© et alignement avec les pr√©f√©rences humaines

  - name: deepseek-r1:14b
    editor: DeepSeek AI
    dsp: 31/12/2025
    location: FR üá´üá∑
    parameters: 14
    parameters_string: 14B
    context_size: 32000
    speed: 23 tokens/seconde
    energy_per_million_tokens: 1.45
    licence: MIT licence
    description: Version compacte et efficiente du mod√®le DeepSeek-R1, offrant un excellent compromis entre performance et l√©g√®ret√© pour les d√©ploiements n√©cessitant flexibilit√© et r√©activit√©.
    details: Repr√©sentant un √©quilibre optimal entre performance et efficacit√©, cette version compacte du mod√®le DeepSeek-R1 conserve les principales qualit√©s de raisonnement et d'analyse de son homologue plus volumineux, tout en permettant un d√©ploiement plus l√©ger et plus flexible. Sa conception soigneusement optimis√©e assure des r√©sultats de qualit√© sur un large √©ventail de t√¢ches, tout en minimisant les exigences en ressources computationnelles. Cette combinaison en fait le choix id√©al pour les applications n√©cessitant un d√©ploiement agile sans compromis majeur sur les capacit√©s fondamentales.
    supports_tools: false
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - Raisonnement
      - Compact
      - Polyvalent
      - Rapide
    use_cases:
      - Applications g√©n√©ralistes avec besoins d'inf√©rence rapide (44 tokens/s)
      - D√©ploiements sur serveurs standard sans GPU sp√©cialis√© (14B param√®tres)
      - Traitement de texte avec analyse contextuelle et temps de r√©ponse rapides
      - D√©ploiement sur edge computing avec inf√©rence locale optimis√©e
      - Prototypage rapide d'applications IA avec temps d'it√©ration court

  - name: deepseek-r1:32b
    editor: DeepSeek AI
    dsp: 31/12/2025
    location: FR üá´üá∑
    parameters: 32
    parameters_string: 32B
    context_size: 32000
    speed: 20 tokens/seconde
    energy_per_million_tokens: 13.18
    licence: MIT licence
    description: Version interm√©diaire du mod√®le DeepSeek-R1 offrant un √©quilibre strat√©gique entre les capacit√©s avanc√©es de la version 70B et l'efficience de la version 14B, pour une polyvalence et performance optimales.
    details: Cette version interm√©diaire du mod√®le DeepSeek-R1 combine intelligemment puissance et efficacit√©, proposant des performances significativamente am√©lior√©es par rapport √† la version 14B tout en maintenant une empreinte plus l√©g√®re que la version 70B. Cette position strat√©gique dans la gamme en fait une option particuli√®rement int√©ressante pour les d√©ploiements n√©cessitant des capacit√©s de raisonnement avanc√©es sans les exigences mat√©rielles des plus grands mod√®les. Sa polyvalence lui permet d'exceller sur un large √©ventail de t√¢ches, de l'analyse de texte √† la g√©n√©ration de contenu structur√©.
    supports_tools: false
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Raisonnement
      - Polyvalent
    use_cases:
      - Applications n√©cessitant un bon √©quilibre puissance/co√ªt (32B param√®tres)
      - Traitement de texte professionnel avec analyse des subtilit√©s s√©mantiques
      - G√©n√©ration automatis√©e de rapports structur√©s √† partir de donn√©es brutes
      - Applications combinant analyse de donn√©es et g√©n√©ration de contenus
      - Assistants sp√©cialis√©s pour secteurs techniques (juridique, m√©dical, technique)

  - name: cogito:3b
    editor: Deep Cogito
    dsp: 30/06/2025
    location: FR üá´üá∑
    parameters: 3
    parameters_string: 3B
    context_size: 32000
    speed: 78 tokens/seconde
    energy_per_million_tokens: 0.43
    licence: LLAMA 3.2 Community Licence
    description: Version compacte du mod√®le Cogito, optimis√©e pour le raisonnement sur des appareils √† ressources limit√©es.
    details: Offre les capacit√©s de raisonnement de la famille Cogito dans un format tr√®s l√©ger (3 milliards de param√®tres), id√©al pour les d√©ploiements embarqu√©s ou les environnements CPU.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - Raisonnement
      - Compact
      - Embarqu√©
      - Efficient
      - Rapide

  - name: granite-embedding:278m
    editor: IBM
    dsp: 31/12/2026
    location: FR üá´üá∑
    parameters: 0.278
    parameters_string: 278M
    context_size: 512
    licence: Apache 2.0
    description: Mod√®le d'embedding ultra-l√©ger d'IBM pour la recherche s√©mantique et la classification.
    details: Con√ßu pour g√©n√©rer des repr√©sentations vectorielles denses de texte, ce mod√®le est optimis√© pour l'efficacit√© et la performance dans les t√¢ches de similarit√© s√©mantique, de clustering et de classification. Sa taille r√©duite le rend id√©al pour les d√©ploiements √† grande √©chelle.
    supports_tools: false
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: false
    tags:
      - Embedding
      - Compact
      - S√©mantique
      - Efficient

  - name: granite3-guardian:2b
    editor: IBM
    dsp: 31/12/2026
    location: FR üá´üá∑
    parameters: 2
    parameters_string: 2B
    context_size: 8192
    licence: Apache 2.0
    description: Mod√®le compact d'IBM sp√©cialis√© dans la s√©curit√© et la conformit√©, d√©tectant les risques et les contenus inappropri√©s.
    details: Version l√©g√®re de la famille Guardian, entra√Æn√©e pour identifier et filtrer les contenus nuisibles, les biais et les risques de s√©curit√© dans les interactions textuelles. Offre une protection robuste avec une faible empreinte computationnelle. Contexte limit√© √† 8k tokens.
    supports_tools: false
    supports_vision: false
    supports_reasoning: false
    supports_security: true
    is_fast: false
    tags:
      - S√©curit√©
      - Conformit√©
      - Compact
      - Filtrage
      - Efficient

  - name: granite3-guardian:8b
    editor: IBM
    dsp: 31/12/2026
    location: FR üá´üá∑
    parameters: 8
    parameters_string: 8B
    context_size: 32000
    licence: Apache 2.0
    description: Mod√®le d'IBM sp√©cialis√© dans la s√©curit√© et la conformit√©, offrant des capacit√©s avanc√©es de d√©tection des risques.
    details: Mod√®le de taille interm√©diaire de la famille Guardian, fournissant une analyse de s√©curit√© plus approfondie que la version 2B. Id√©al pour les applications n√©cessitant une surveillance rigoureuse du contenu et une conformit√© stricte.
    supports_tools: false
    supports_vision: false
    supports_reasoning: false
    supports_security: true
    is_fast: false
    tags:
      - S√©curit√©
      - Conformit√©
      - Filtrage

  - name: qwen3:0.6b
    editor: Qwen Team
    dsp: 31/12/2025
    location: FR üá´üá∑
    parameters: 0.6
    parameters_string: 0.6B
    context_size: 32000
    speed: 28 tokens/seconde
    energy_per_million_tokens: 0.60
    licence: Apache 2.0
    description: Mod√®le compact et efficace de la famille Qwen3, adapt√© aux t√¢ches g√©n√©rales sur ressources limit√©es.
    details: Offre un bon compromis entre les capacit√©s des mod√®les ultra-compacts et les mod√®les plus grands. Id√©al pour les applications n√©cessitant une bonne compr√©hension g√©n√©rale dans un format l√©ger et rapide.
    supports_tools: true
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Compact
      - Rapide
      - Polyvalent
      - Efficient

  - name: qwen3:1.7b
    editor: Qwen Team
    dsp: 31/12/2025
    location: FR üá´üá∑
    parameters: 1.7
    parameters_string: 1.7B
    context_size: 32000
    speed: 46 tokens/seconde
    energy_per_million_tokens: 0.73
    licence: Apache 2.0
    description: Mod√®le tr√®s compact de la famille Qwen3, offrant un bon √©quilibre performance/taille pour les d√©ploiements l√©gers.
    details: Mod√®le l√©g√®rement plus grand que la version 0.6B, offrant des capacit√©s am√©lior√©es tout en restant tr√®s efficace. Convient aux applications mobiles ou embarqu√©es n√©cessitant un peu plus de puissance.
    supports_tools: true
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Compact
      - Rapide
      - Embarqu√©
      - Efficient

  - name: qwen3:4b
    editor: Qwen Team
    dsp: 31/12/2026
    location: FR üá´üá∑
    parameters: 4
    parameters_string: 4B
    context_size: 32000
    speed: 29 tokens/seconde
    energy_per_million_tokens: 1.15
    licence: Apache 2.0
    description: Mod√®le compact de la famille Qwen3 offrant d'excellentes performances dans un format l√©ger et √©conomique.
    details: Cette version compacte du mod√®le Qwen3 est optimis√©e pour les d√©ploiements avec contraintes de ressources tout en maintenant des performances remarquables pour sa taille. Son architecture efficiente permet une inf√©rence rapide sur du mat√©riel standard.
    supports_tools: true
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: false
    tags:
      - Compact
      - Efficient

  - name: qwen3-2507-think:4b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 4
    parameters_string: 4B
    context_size: 250000
    speed: 77 tokens/seconde
    energy_per_million_tokens: 1.73
    licence: Apache 2.0
    description: Mod√®le Qwen3-4B optimis√© pour le raisonnement, avec des performances am√©lior√©es sur les t√¢ches logiques, les math√©matiques, la science et le code, et un contexte √©tendu √† 250K tokens.
    details: Cette version "Thinking" dispose d'une longueur de pens√©e accrue, la rendant id√©ale pour les t√¢ches de raisonnement tr√®s complexes. Elle offre √©galement des am√©liorations g√©n√©rales en suivi d'instructions, utilisation d'outils et g√©n√©ration de texte.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - Agent
      - Raisonnement
      - Grand Contexte
      - Compact
      - Rapide
    use_cases:
      - T√¢ches de raisonnement tr√®s complexes (logique, maths, science, code).
      - Agents conversationnels avec un historique de conversation tr√®s √©tendu (256k tokens).
      - Analyse de documents tr√®s volumineux avec raisonnement profond.
      - Int√©gration avec des outils externes via function calling sur de tr√®s grands contextes.

  - name: qwen3-2507:4b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 4
    parameters_string: 4B
    context_size: 250000
    speed: 69 tokens/seconde
    energy_per_million_tokens: 1.93
    licence: Apache 2.0
    description: Version mise √† jour du mode non-pens√©e de Qwen3-4B, avec des am√©liorations significatives des capacit√©s g√©n√©rales, une couverture de connaissances √©tendue et un meilleur alignement avec les pr√©f√©rences des utilisateurs.
    details: Am√©liorations notables du suivi d'instructions, du raisonnement logique, de la compr√©hension de texte, des math√©matiques, du codage et de l'utilisation d'outils. Contexte natif de 250k tokens.
    supports_tools: true
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Agent
      - Grand Contexte
      - Compact
      - Rapide
      - Multilingue
    use_cases:
      - T√¢ches g√©n√©rales n√©cessitant un suivi d'instructions pr√©cis et un raisonnement logique.
      - Applications multilingues avec une large couverture de connaissances.
      - G√©n√©ration de texte de haute qualit√© pour des t√¢ches ouvertes et subjectives.
      - Analyse de documents tr√®s volumineux gr√¢ce au contexte de 256k tokens.

  - name: qwen3:8b
    editor: Qwen Team
    dsp: 31/12/2026
    location: FR üá´üá∑
    parameters: 8
    parameters_string: 8B
    context_size: 32000
    speed: 18 tokens/seconde
    energy_per_million_tokens: 1.85
    licence: Apache 2.0
    description: Mod√®le Qwen3 8B offrant un bon √©quilibre entre performance et efficacit√© pour les t√¢ches g√©n√©rales.
    details: Version 8B de Qwen3, offrant des capacit√©s am√©lior√©es en raisonnement, code, maths et agent. Supporte plus de 100 langues et les modes de pens√©e hybrides.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Raisonnement
      - Agent
      - Multilingue
      - Efficient

  - name: qwen2.5vl:3b
    editor: Qwen Team
    dsp: 31/12/2025
    location: FR üá´üá∑
    parameters: 3.8
    parameters_string: 3.8B
    context_size: 128000
    speed: 73 tokens/seconde
    energy_per_million_tokens: 0.45
    licence: Apache 2.0
    description: Mod√®le Vision-Langage compact, solution performante pour l'IA en p√©riph√©rie (edge AI).
    details: Qwen2.5-VL est le nouveau mod√®le phare vision-langage de Qwen, marquant une avanc√©e significative par rapport √† Qwen2-VL. Caract√©ristiques cl√©s - Compr√©hension visuelle (objets communs, textes, graphiques, ic√¥nes, mises en page). Capacit√©s d'agent visuel (raisonnement, direction dynamique d'outils pour utilisation d'ordinateur/t√©l√©phone). Localisation visuelle pr√©cise (bo√Ætes englobantes, points, sorties JSON stables). G√©n√©ration de sorties structur√©es (factures, formulaires, tableaux). Le Qwen2.5-VL-3B surpasse m√™me la version 7B de Qwen2-VL.
    supports_tools: true
    supports_vision: true
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - Vision
      - Agent
      - Raisonnement
      - Rapide
      - Efficient
      - OCR
      - Localisation Visuelle
      - Edge AI

  - name: qwen2.5vl:7b
    editor: Qwen Team
    dsp: 31/12/2025
    location: FR üá´üá∑
    parameters: 8.3
    parameters_string: 7B (8.3B)
    context_size: 128000
    speed: 48 tokens/seconde
    energy_per_million_tokens: 0.69
    licence: Apache 2.0
    description: Mod√®le Vision-Langage performant, surpassant GPT-4o-mini sur certaines t√¢ches.
    details: Qwen2.5-VL est le nouveau mod√®le phare vision-langage de Qwen, marquant une avanc√©e significative par rapport √† Qwen2-VL. Caract√©ristiques cl√©s - Compr√©hension visuelle (objets communs, textes, graphiques, ic√¥nes, mises en page). Capacit√©s d'agent visuel (raisonnement, direction dynamique d'outils pour utilisation d'ordinateur/t√©l√©phone). Localisation visuelle pr√©cise (bo√Ætes englobantes, points, sorties JSON stables). G√©n√©ration de sorties structur√©es (factures, formulaires, tableaux). Le Qwen2.5-VL-7B-Instruct surpasse GPT-4o-mini dans plusieurs t√¢ches et est particuli√®rement performant pour la compr√©hension de documents et de diagrammes.
    supports_tools: true
    supports_vision: true
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Vision
      - Agent
      - Raisonnement
      - Efficient
      - OCR
      - Localisation Visuelle

  - name: devstral:24b
    editor: Mistral AI & All Hands AI
    dsp: 30/03/2025
    location: FR üá´üá∑
    parameters: 24
    parameters_string: 24B
    context_size: 100000
    speed: 50 tokens/seconde
    energy_per_million_tokens: 5.27
    licence: Apache 2.0
    description: Devstral est un LLM agentique pour les t√¢ches d'ing√©nierie logicielle.
    details: Devstral est un LLM agentique pour les t√¢ches d'ing√©nierie logicielle. Il excelle dans l'utilisation d'outils pour explorer les bases de code, modifier plusieurs fichiers et alimenter les agents d'ing√©nierie logicielle. Il est affin√© √† partir de Mistral Small 3.1, disposant ainsi d'une longue fen√™tre contextuelle allant jusqu'√† 128k tokens. 
    supports_tools: true
    supports_vision: false
    supports_reasoning: false
    supports_security: true
    is_fast: false
    tags:
      - Agent
      - Programmation
      - Open-Source
      - Grand Contexte
    use_cases:
      - Exploration et modification de bases de code
      - Agentic
      - Europ√©en

  - name: cogito:8b
    editor: Deep Cogito
    dsp: 30/06/2025
    location: FR üá´üá∑
    parameters: 8
    parameters_string: 8B
    context_size: 32000
    speed: 43 tokens/seconde
    energy_per_million_tokens: 0.77
    licence: LLAMA 3.2 Community Licence
    description: Mod√®le de taille interm√©diaire de la famille Cogito, offrant un bon √©quilibre entre les capacit√©s de raisonnement et l'efficacit√©.
    details: Cette version 8B se positionne entre les mod√®les compacts et les mod√®les plus larges, offrant des capacit√©s de raisonnement robustes pour une large gamme d'applications analytiques sans n√©cessiter les ressources des mod√®les plus grands.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Agent
      - Raisonnement
      - Polyvalent
      - Efficient

  - name: granite4-small-h:32b
    editor: IBM
    location: FR üá´üá∑
    parameters: 32
    parameters_string: 32B (9B actifs)
    context_size: 128000
    speed: 28 tokens/seconde
    energy_per_million_tokens: 1.19
    licence: Apache 2.0
    description: Mod√®le MoE (Mixture-of-Experts) d'IBM, con√ßu comme un "cheval de bataille" pour les t√¢ches d'entreprise quotidiennes, avec une excellente efficacit√© pour les longs contextes.
    details: Ce mod√®le hybride (Transformer + Mamba-2) de 32 milliards de param√®tres (9B actifs) est optimis√© pour les workflows d'entreprise comme les agents multi-outils et l'automatisation du support client. Son architecture innovante r√©duit de plus de 70% l'utilisation de la RAM pour les longs contextes et les lots multiples.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: true
    is_fast: false
    tags:
      - Agent
      - Raisonnement
      - S√©curit√©
      - MoE
      - Grand Contexte
      - Efficient
    use_cases:
      - Agents conversationnels pour le support client avec acc√®s √† des bases de connaissances √©tendues.
      - Automatisation de workflows d'entreprise n√©cessitant l'utilisation de plusieurs outils.
      - Analyse de documents longs avec une consommation de ressources optimis√©e.
      - D√©ploiements sur des infrastructures de taille moyenne gr√¢ce √† son efficacit√©.

  - name: granite4-tiny-h:7b
    editor: IBM
    location: FR üá´üá∑
    parameters: 7
    parameters_string: 7B (1B actif)
    context_size: 128000
    speed: 77 tokens/seconde
    energy_per_million_tokens: 0.43
    licence: Apache 2.0
    description: Mod√®le MoE hybride ultra-efficace d'IBM, con√ßu pour la faible latence, les applications "edge" et locales, et comme brique de base pour les workflows agentiques.
    details: Ce mod√®le de 7 milliards de param√®tres (1B actifs) combine des couches Transformer et Mamba-2 pour une efficacit√© maximale. Il r√©duit l'utilisation de la RAM de plus de 70% pour les longs contextes, le rendant id√©al pour les appareils √† ressources limit√©es et les t√¢ches rapides comme le "function calling".
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: true
    is_fast: true
    tags:
      - Agent
      - Raisonnement
      - S√©curit√©
      - MoE
      - Grand Contexte
      - Efficient
      - Rapide
      - Compact
    use_cases:
      - Applications embarqu√©es et "edge" n√©cessitant une faible latence.
      - T√¢ches rapides au sein de workflows agentiques plus larges (ex: function calling).
      - Analyse de documents sur du mat√©riel grand public.
      - D√©ploiements n√©cessitant une empreinte m√©moire minimale.

  - name: deepseek-ocr
    editor: DeepSeek AI
    location: FR üá´üá∑
    parameters: 3
    parameters_string: 3B
    context_size: 8192
    speed: 120 tokens/seconde
    energy_per_million_tokens: 0.16
    licence: MIT licence
    description: Mod√®le OCR sp√©cialis√© de DeepSeek, con√ßu pour une extraction de texte haute pr√©cision avec pr√©servation de la mise en forme.
    details: Syst√®me OCR en deux √©tapes (encodeur visuel + d√©codeur MoE 3B) optimis√© pour la conversion de documents en Markdown structur√© (tableaux, formules). N√©cessite un pr√©-traitement sp√©cifique (Logits Processor) pour des performances optimales.
    supports_tools: false
    supports_vision: true
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Vision
      - OCR
      - Efficient
    use_cases:
      - Extraction de texte structur√© (Markdown/latex) depuis des images/PDF
      - Num√©risation de documents avec tableaux et formules complexes

# Cas d'usage recommand√©s
use_cases:
  - name: Dialogue multilingue
    description: Chatbots et assistants capables de communiquer dans plusieurs langues avec d√©tection automatique, maintien du contexte sur l'ensemble de la conversation et compr√©hension des sp√©cificit√©s linguistiques
    recommended_models:
      - Llama 3.3
      - Mistral Small 3.2
      - Qwen 3
      - Openai OSS 
      - Granite 4 

  - name: Analyse de documents longs
    description: Traitement de documents volumineux (>100 pages) avec maintien du contexte sur l'ensemble du texte, extraction d'informations cl√©s, g√©n√©ration de r√©sum√©s pertinents et r√©ponse √† des questions sp√©cifiques sur le contenu
    recommended_models:
      - Gemma 3
      - Qwen next
      - Qwen 3 
      - Granite 4  # Mis √† jour

  - name: Programmation et d√©veloppement
    description: G√©n√©ration et optimisation de code dans multiples langages, d√©bogage, refactoring, d√©veloppement de fonctionnalit√©s compl√®tes, compr√©hension des impl√©mentations algorithmiques complexes et cr√©ation de tests unitaires
    recommended_models:
      - DeepCoder
      - Qwen3 coder 
      - Granite 4
      - Devstral

  - name: Analyse visuelle
    description: Traitement direct d'images et documents visuels sans pr√©-traitement OCR, interpr√©tation de diagrammes techniques, graphiques, tableaux, dessins et photos avec g√©n√©ration d'explications textuelles d√©taill√©es du contenu visuel
    recommended_models:
      - deepseek-OCR
      - Mistral Small 3.2
      - Gemma 3
      - Qwen2.5-VL
    
  - name: S√©curit√© et conformit√©
    description: Applications n√©cessitant des capacit√©s sp√©cifiques en mati√®re de s√©curit√© ; filtrage de contenu sensible, tra√ßabilit√© des raisonnements, v√©rification RGPD/HDS, minimisation des risques, analyse des vuln√©rabilit√©s et respect des r√©glementations sectorielles
    recommended_models:
      - Granite Guardian
      - Granite 4
      - Devstral
      - Mistral Small 3.2
      - Magistral 24b

  - name: D√©ploiements l√©gers et embarqu√©s
    description: Applications n√©cessitant une empreinte minimale en ressources, d√©ploiement sur appareils √† capacit√© limit√©e, inf√©rence en temps r√©el sur CPU standard et int√©gration dans des syst√®mes embarqu√©s ou IoT
    recommended_models:
      - Gemma 3
      - Granite Guardian
      - Granite 4 tiny
      - DeepSeek-OCR
