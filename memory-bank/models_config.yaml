# Configuration des mod√®les Cloud Temple MaaS
# Ce fichier d√©crit tous les mod√®les disponibles dans l'offre LLM as a Service

# Statistiques globales
stats:
  total_models: 51 # Mis √† jour
  min_context: 8192 # Granite Guardian 2B
  max_context: 262144 # Qwen3 4B
  pricing_input: 0.9
  pricing_output: 4
  pricing_reasoning: 21
  pricing_audio: 0.01 # Par minutes
  secnumcloud: true
  hds: true
  sovereign: true

# Mod√®les de grande taille
large_models:
  - name: gpt-oss:120b
    editor: OpenAI
    location: FR üá´üá∑
    parameters: 120
    parameters_string: 120B
    context_size: 120000
    speed: 38 tokens/seconde
    energy_per_million_tokens: 3.51 # (480W / 38 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le de langage open-weight de pointe d'OpenAI, offrant de solides performances avec une licence flexible Apache 2.0.
    details: Un mod√®le Mixture-of-Experts (MoE) de 120 milliards de param√®tres avec environ 5.1 milliards de param√®tres actifs. Il offre un effort de raisonnement configurable et un acc√®s complet √† la cha√Æne de pens√©e.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - MoE
      - Agent
      - Raisonnement
      - Open-Source
      - Tr√®s Large
    use_cases:
      - Agents conversationnels avanc√©s avec raisonnement complexe et int√©gration d'outils.
      - Applications n√©cessitant une transparence totale du processus de raisonnement (chain-of-thought).
      - Sc√©narios commerciaux n√©cessitant une licence permissive (Apache 2.0).
      - Fine-tuning pour des t√¢ches sp√©cialis√©es n√©cessitant un mod√®le de base puissant.

  - name: llama3.3:70b
    editor: Meta
    location: FR üá´üá∑
    parameters: 70
    parameters_string: 70B
    context_size: 120000
    speed: 15 tokens/seconde
    energy_per_million_tokens: 8.89 # (480W / 15 t/s) / 3.6
    licence: LLAMA 3.3 Community Licence
    description: Mod√®le multilingue de pointe d√©velopp√© par Meta, con√ßu pour exceller dans le dialogue naturel, le raisonnement complexe et la compr√©hension nuanc√©e des instructions.
    details: Combinant une efficacit√© remarquable avec des ressources computationnelles r√©duites, ce mod√®le offre des capacit√©s multilingues √©tendues couvrant 8 langues majeures (anglais, fran√ßais, allemand, espagnol, italien, portugais, hindi et tha√Ø). Sa fen√™tre contextuelle de 120 000 tokens permet l'analyse approfondie de documents complexes et de conversations longues, tout en maintenant une coh√©rence globale exceptionnelle. Optimis√© pour minimiser les biais et les r√©ponses probl√©matiques.
    supports_tools: true
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: false
    tags:
      - Agent
      - Dialogue
      - Multilingue
    use_cases:
      - Chatbots multilingues prenant en charge 8 langues simultan√©ment
      - Ex√©cution d'instructions complexes encha√Æn√©es (prompt chaining)
      - Traitement d'une fen√™tre de dialogue de 60K tokens pour historique conversationnel
      - Analyse de documents juridiques ou techniques volumineux (>100 pages)
      - G√©n√©ration de textes structur√©s avec fid√©lit√© aux consignes stylistiques

  - name: qwen3:235b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 235
    parameters_string: 235B
    context_size: 60000
    speed: 17 tokens/seconde
    energy_per_million_tokens: 7.84 # (480W / 17 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le tr√®s volumineux de la nouvelle g√©n√©ration Qwen3, offrant des capacit√©s √©tendues pour les t√¢ches les plus complexes.
    details: Fait partie de la s√©rie Qwen3. Ce mod√®le de 235 milliards de param√®tres est con√ßu pour exceller dans les t√¢ches de raisonnement profond, de g√©n√©ration de code complexe, et de compr√©hension nuanc√©e sur de vastes contextes. Supporte plus de 100 langues et int√®gre des modes de pens√©e hybrides.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - Agent
      - Raisonnement
      - Multilingue
      - Tr√®s Large
    use_cases:
      - Agents conversationnels tr√®s avanc√©s avec grand contexte et int√©gration d'outils (MCP)
      - R√©solution de probl√®mes extr√™mement complexes (maths, code)
      - Analyse et g√©n√©ration de documents tr√®s volumineux et techniques
      - Applications multilingues (>100 langues) n√©cessitant une compr√©hension et une g√©n√©ration de tr√®s haute fid√©lit√©

  - name: deepseek-r1:671b
    editor: DeepSeek AI
    location: FR üá´üá∑
    parameters: 671
    parameters_string: 671B
    context_size: 16000
    speed: 12 tokens/seconde
    energy_per_million_tokens: 11.11 # (480W / 12 t/s) / 3.6
    licence: MIT Licence
    description: Mod√®le extr√™mement volumineux de DeepSeek AI, con√ßu pour le summum du raisonnement et de la g√©n√©ration.
    details: DeepSeek-R1 671B repr√©sente l'un des plus grands mod√®les ouverts, destin√© aux t√¢ches de raisonnement les plus ardues et √† la g√©n√©ration de texte d'une qualit√© exceptionnelle.
    supports_tools: false
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Raisonnement
      - Extr√™mement Large
    use_cases:
      - T√¢ches de raisonnement de pointe
      - G√©n√©ration de texte de qualit√© sup√©rieure
      - Recherche et d√©veloppement en IA

  - name: gemma3:27b
    editor: Google
    location: FR üá´üá∑
    parameters: 27
    parameters_string: 27B
    context_size: 120000
    speed: 20 tokens/seconde
    energy_per_million_tokens: 6.67 # (480W / 20 t/s) / 3.6
    licence: Google Gemma Terms of Use
    description: Mod√®le r√©volutionnaire de Google offrant un √©quilibre optimal entre puissance et efficacit√©, avec un rapport performance/co√ªt exceptionnel pour les applications professionnelles exigeantes.
    details: Dot√© d'une efficacit√© mat√©rielle in√©gal√©e, ce mod√®le int√®gre des capacit√©s multimodales natives et excelle dans la performance multilingue sur plus de 140 langues. Sa fen√™tre contextuelle impressionnante de 120 000 tokens en fait le choix id√©al pour l'analyse de documents tr√®s volumineux, la recherche documentaire, et toute application n√©cessitant la compr√©hension de contextes √©tendus. Son architecture optimis√©e permet un d√©ploiement flexible sans compromettre la qualit√© des r√©sultats.
    supports_tools: true
    supports_vision: true
    supports_reasoning: false
    supports_security: false
    is_fast: false
    tags:
      - Vision
      - Agent
      - Grand contexte
    use_cases:
      - Analyse de documents avec contexte √©tendu jusqu'√† 120K tokens (environ 400 pages)
      - Indexation et recherche s√©mantique dans des bases documentaires volumineuses
      - Traitement d'images et texte en simultan√© gr√¢ce aux capacit√©s multimodales
      - Extraction structur√©e de donn√©es √† partir de PDF et documents scann√©s
      - Int√©gration avec des outils externes via l'API function calling

  - name: qwen3-coder:30b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 30
    parameters_string: 30B
    context_size: 250000
    speed: 80 tokens/seconde
    energy_per_million_tokens: 3.30 # (950W / 80 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le MoE optimis√© pour les t√¢ches d'ing√©nierie logicielle, avec un contexte tr√®s long.
    details: Capacit√©s agentiques avanc√©es pour les t√¢ches de g√©nie logiciel, support natif d'un contexte de 250K tokens, pr√©-entra√Æn√© sur 7.5T tokens avec un fort ratio de code, et optimis√© par apprentissage par renforcement pour am√©liorer les taux d'ex√©cution de code.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - Agent
      - Programmation
      - Grand Contexte
      - MoE
    use_cases:
      - Agents d'ing√©nierie logicielle pour explorer et modifier des bases de code
      - G√©n√©ration de code complexe avec compr√©hension √† l'√©chelle du d√©p√¥t (repository-scale)
      - T√¢ches de raisonnement sur des contextes √©tendus
      - Am√©lioration de code via apprentissage par renforcement

  - name: qwen3-2507-think:30b-a3b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 30
    parameters_string: 30B
    context_size: 120000
    speed: 80 tokens/seconde
    energy_per_million_tokens: 3.30 # (950W / 80 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le avanc√© de la famille Qwen3, optimis√© pour le raisonnement profond et les contextes √©tendus.
    details: Le mod√®le Qwen3-30B-A3B-Thinking-2507 offre des performances significativement am√©lior√©es sur les t√¢ches de raisonnement, le suivi d'instructions et l'utilisation d'outils. Il supporte nativement une fen√™tre de contexte de 256k tokens.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - Agent
      - Raisonnement
      - Grand Contexte
    use_cases:
      - Analyse de documents tr√®s volumineux avec raisonnement complexe.
      - Agents conversationnels avec un historique de conversation √©tendu.
      - T√¢ches de Q&A sur de larges corpus de texte.
      - Int√©gration avec des outils externes via function calling sur de grands contextes.

  - name: qwen3-2507:30b-a3b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 30
    parameters_string: 30B
    context_size: 250000
    speed: 90 tokens/seconde
    energy_per_million_tokens: 2.16 # (700W / 90 t/s) / 3.6
    licence: Apache 2.0
    description: Version am√©lior√©e du mode non-pens√©e de Qwen3-30B, avec des capacit√©s g√©n√©rales, une couverture de connaissances et un alignement utilisateur am√©lior√©s.
    details: Am√©liorations significatives du suivi d'instructions, du raisonnement, de la compr√©hension de texte, des math√©matiques, du codage et de l'utilisation d'outils. Contexte natif de 250k tokens. 
    supports_tools: true
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Agent
      - Grand Contexte
      - MoE
      - Multilingue
    use_cases:
      - T√¢ches complexes n√©cessitant un suivi d'instructions pr√©cis et un raisonnement logique.
      - Applications multilingues avec une large couverture de connaissances.
      - G√©n√©ration de texte de haute qualit√© pour des t√¢ches ouvertes et subjectives.
      - Analyse de documents tr√®s volumineux gr√¢ce au contexte de 250k tokens.

  - name: qwen3:30b-a3b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 30
    parameters_string: 30B
    context_size: 32000
    speed: 50 tokens/seconde
    energy_per_million_tokens: 3.89 # (700W / 50 t/s) / 3.6
    licence: Apache 2.0
    description: Derni√®re g√©n√©ration des mod√®les Qwen, offrant des am√©liorations significatives en termes de donn√©es d'entra√Ænement, d'architecture et d'optimisation.
    details: Pr√©-entra√Æn√© sur 36T de tokens dans 119 langues. Mod√®le MoE (Mixture-of-Experts) avec 128 experts dont 8 activ√©s par token. 
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Agent
      - Programmation
      - Multilingue
      - MoE
    use_cases:
      - T√¢ches de raisonnement complexes et g√©n√©ration de code.
      - Applications multilingues n√©cessitant une large couverture linguistique.
      - Sc√©narios n√©cessitant un bon √©quilibre entre performance et efficacit√© des ressources gr√¢ce √† l'architecture MoE.

  - name: deepseek-r1:70b
    editor: DeepSeek AI
    location: FR üá´üá∑
    parameters: 70
    parameters_string: 70B
    context_size: 32000
    speed: 21 tokens/seconde
    energy_per_million_tokens: 12.56 # (950W / 21 t/s) / 3.6
    licence: MIT Licence
    description: Mod√®le 70B de DeepSeek AI
    details: DeepSeek-R1 70B est con√ßu pour des t√¢ches complexes de raisonnement et de g√©n√©ration.
    supports_tools: false
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Raisonnement
      - Large
    use_cases:
      - T√¢ches de raisonnement de pointe
      - G√©n√©ration de texte de qualit√© sup√©rieure
      - Recherche et d√©veloppement en IA

  - name: qwen2.5vl:32b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 32
    parameters_string: 32B
    context_size: 120000
    speed: 18 tokens/seconde
    energy_per_million_tokens: 7.41 # (480W / 18 t/s) / 3.6
    licence: Apache 2.0
    description: Version la plus puissante de la s√©rie Qwen2.5-VL, offrant des capacit√©s de compr√©hension visuelle et d'agentique de pointe.
    details: Ce mod√®le vision-langage de 32 milliards de param√®tres est con√ßu pour les t√¢ches les plus exigeantes, combinant une compr√©hension visuelle profonde avec des capacit√©s de raisonnement avanc√©es pour interagir avec des interfaces graphiques et analyser des documents complexes.
    supports_tools: true
    supports_vision: true
    supports_reasoning: false
    supports_security: false
    is_fast: false
    tags:
      - Vision
      - Agent
      - Raisonnement
      - OCR
      - Localisation Visuelle
      - Large
    use_cases:
      - Analyse de documents et de diagrammes tr√®s complexes
      - Agents visuels autonomes pour la navigation et l'interaction avec des GUI
      - T√¢ches de localisation d'objets et de reconnaissance de texte de haute pr√©cision
      - G√©n√©ration de descriptions riches et d√©taill√©es √† partir d'images complexes

  - name: qwen2.5vl:72b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 72
    parameters_string: 72B
    context_size: 128000
    speed: 15 tokens/seconde
    energy_per_million_tokens: 8.89 # (480W / 15 t/s) / 3.6 (estimation)
    licence: Apache 2.0
    description: Version la plus puissante de la s√©rie Qwen2.5-VL, offrant des capacit√©s de compr√©hension visuelle et d'agentique de pointe pour les t√¢ches les plus exigeantes.
    details: Ce mod√®le vision-langage de 72 milliards de param√®tres est con√ßu pour les t√¢ches les plus exigeantes, combinant une compr√©hension visuelle profonde avec des capacit√©s de raisonnement avanc√©es pour interagir avec des interfaces graphiques et analyser des documents complexes.
    supports_tools: true
    supports_vision: true
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Vision
      - Agent
      - Raisonnement
      - OCR
      - Localisation Visuelle
      - Tr√®s Large
    use_cases:
      - Analyse de documents et de diagrammes tr√®s complexes
      - Agents visuels autonomes pour la navigation et l'interaction avec des GUI
      - T√¢ches de localisation d'objets et de reconnaissance de texte de tr√®s haute pr√©cision
      - G√©n√©ration de descriptions riches et d√©taill√©es √† partir d'images tr√®s complexes

# Mod√®les sp√©cialis√©s
specialized_models:
  - name: embeddinggemma:300m
    editor: Google
    location: FR üá´üá∑
    parameters: 0.3
    parameters_string: 300M
    context_size: 2048
    licence: Google Gemma Terms of Use
    description: Mod√®le d'embedding de pointe de Google, optimis√© pour sa taille, id√©al pour les t√¢ches de recherche et de r√©cup√©ration s√©mantique.
    details: Construit sur Gemma 3, ce mod√®le produit des repr√©sentations vectorielles de texte pour la classification, le clustering et la recherche de similarit√©. Entra√Æn√© sur plus de 100 langues, sa petite taille le rend parfait pour les environnements √† ressources limit√©es.
    supports_tools: false
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Embedding
      - Compact
      - S√©mantique
      - Efficient
      - Multilingue
    use_cases:
      - Recherche et r√©cup√©ration d'informations (Retrieval)
      - Classification et clustering de documents
      - Recherche de similarit√© s√©mantique
      - D√©ploiement sur des appareils √† ressources limit√©es (mobile, laptop)

  - name: gpt-oss:20b
    editor: OpenAI
    location: FR üá´üá∑
    parameters: 20
    parameters_string: 20B
    context_size: 120000
    speed: 57 tokens/seconde
    energy_per_million_tokens: 2.34 # (480W / 57 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le de langage open-weight d'OpenAI, optimis√© pour l'efficacit√© et le d√©ploiement sur du mat√©riel grand public.
    details: Un mod√®le Mixture-of-Experts (MoE) de 21 milliards de param√®tres avec 3.6 milliards de param√®tres actifs. Il offre un effort de raisonnement configurable et des capacit√©s d'agent.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - MoE
      - Agent
      - Raisonnement
      - Open-Source
      - Compact
      - Rapide
    use_cases:
      - D√©ploiements sur des appareils √† ressources limit√©es (edge devices) ou des serveurs √† faible co√ªt.
      - Applications n√©cessitant une inf√©rence rapide avec de bonnes capacit√©s de raisonnement.
      - Cas d'usage agentiques avec appel de fonctions, navigation web et ex√©cution de code.
      - Fine-tuning pour des t√¢ches sp√©cialis√©es sur du mat√©riel grand public.

  - name: qwen3:14b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 14
    parameters_string: 14B
    context_size: 32000
    speed: 40 tokens/seconde
    energy_per_million_tokens: 3.33 # (480W / 40 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le dense nouvelle g√©n√©ration Qwen3 (14B), offrant des performances √©quivalentes √† Qwen2.5 32B avec une meilleure efficacit√©.
    details: Fait partie de la s√©rie Qwen3, entra√Æn√© sur ~36T tokens. Capacit√©s am√©lior√©es en raisonnement, code, maths et agent (outils/MCP). Supporte plus de 100 langues et les modes de pens√©e hybrides.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - Agent
      - Raisonnement
      - Rapide
      - Multilingue
    use_cases:
      - T√¢ches g√©n√©rales n√©cessitant performance et grand contexte
      - G√©n√©ration de contenu cr√©atif et technique
      - Analyse de donn√©es et raisonnement complexe
      - Int√©gration avec des outils externes via function calling

  - name: gemma3:12b
    editor: Google
    location: FR üá´üá∑
    parameters: 12
    parameters_string: 12B
    context_size: 120000
    speed: 56 tokens/seconde
    energy_per_million_tokens: 4.71 # (950W / 56 t/s) / 3.6
    licence: Google Gemma Terms of Use
    description: Version interm√©diaire du mod√®le Gemma 3 offrant un excellent √©quilibre entre performance et efficacit√©.
    details: Ce mod√®le de taille moyenne combine performances de haute qualit√© et efficacit√© op√©rationnelle, offrant une grande partie des capacit√©s de son grand fr√®re de 27B param√®tres dans un format plus l√©ger. Id√©al pour les d√©ploiements n√©cessitant qualit√© et rapidit√© sans les ressources computationnelles des plus grands mod√®les.
    supports_tools: false
    supports_vision: true
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Vision
      - Rapide
      - Grand Contexte
    use_cases:
      - Applications multimodales avec contraintes de ressources mod√©r√©es
      - Traitement de documents avec contexte standard (jusqu'√† 100 pages)
      - G√©n√©ration de contenu textuel et analyse d'images combin√©es
      - D√©ploiements sur GPU standard sans infrastructure sp√©cialis√©e
      - Chatbots avanc√©s avec capacit√©s visuelles et textuelles int√©gr√©es

  - name: gemma3:4b
    editor: Google
    location: FR üá´üá∑
    parameters: 4
    parameters_string: 4B
    context_size: 120000
    speed: 57 tokens/seconde
    energy_per_million_tokens: 0.58 # (120W / 57 t/s) / 3.6
    licence: Google Gemma Terms of Use
    description: Mod√®le compact de Google offrant d'excellentes performances dans un format l√©ger et √©conomique.
    details: Cette version compacte du mod√®le Gemma 3 est optimis√©e pour les d√©ploiements avec contraintes de ressources tout en maintenant des performances remarquables pour sa taille. Son architecture efficiente permet une inf√©rence rapide sur du mat√©riel standard, id√©ale pour les applications n√©cessitant r√©activit√© et d√©ploiement √† grande √©chelle. Malgr√© sa taille r√©duite, il maintient des capacit√©s multimodales pour traiter √† la fois texte et images.
    supports_tools: false
    supports_vision: true
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Vision
      - Rapide
      - Compact
      - Grand Contexte
      - Efficient
    use_cases:
      - Applications embarqu√©es et edge computing avec traitement d'images
      - Chatbots multimodaux r√©actifs n√©cessitant une faible latence
      - D√©ploiements √† grande √©chelle avec capacit√©s visuelles et textuelles
      - Applications mobiles avec analyse d'images et textes
      - Traitement de requ√™tes visuelles simples √† moyenne complexit√© avec haute performance

  - name: gemma3:1b
    editor: Google
    location: FR üá´üá∑
    parameters: 1
    parameters_string: 1B
    context_size: 32000
    speed: 112 tokens/seconde
    energy_per_million_tokens: 0.15 # (60W / 112 t/s) / 3.6
    licence: Google Gemma Terms of Use
    description: Micro-mod√®le ultra-l√©ger con√ßu pour les d√©ploiements sur appareils √† tr√®s faibles ressources.
    details: Ce mod√®le ultra-compact repr√©sente la quintessence de l'efficience, permettant des d√©ploiements dans des environnements extr√™mement contraints en ressources. Malgr√© sa taille minimale, il offre des capacit√©s de base surprenantes pour des t√¢ches textuelles simples √† mod√©r√©es, avec une vitesse d'inf√©rence exceptionnelle. Il prend √©galement en charge l'int√©gration avec des outils externes via function calling.
    supports_tools: false
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Ultra-compact
      - Embarqu√©
      - Efficient
      - Rapide
    use_cases:
      - D√©ploiement sur appareils IoT et syst√®mes embarqu√©s avec int√©gration API
      - Applications n√©cessitant inf√©rence locale sur CPU avec appels √† des fonctions
      - T√¢ches textuelles basiques avec temps de r√©ponse instantan√© et function calling
      - Assistants compacts pour applications grand public avec int√©gration services externes
      - Syst√®mes de contr√¥le intelligents int√©grant plusieurs APIs/services

  - name: lucie-instruct:7b
    editor: OpenLLM-France
    location: FR üá´üá∑
    parameters: 7
    parameters_string: 7B
    context_size: 32000
    speed: 4 tokens/seconde
    energy_per_million_tokens: 8.33 # (120W / 4 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le causal multilingue open-source (7B), fine-tun√© depuis Lucie-7B. Optimis√© pour le fran√ßais.
    details: Fine-tun√© sur instructions synth√©tiques (ChatGPT, Gemma) et prompts customis√©s. Non optimis√© pour code/maths. Entra√Æn√© sur contexte 4k mais conserve la capacit√© du mod√®le de base pour 32k. Mod√®le en d√©veloppement.
    supports_tools: false
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: false
    tags:
      - Fran√ßais
      - Open-Source
      - Efficient

  - name: mistral-small3.1:24b
    editor: Mistral AI
    location: FR üá´üá∑
    parameters: 24
    parameters_string: 24B
    context_size: 120000
    speed: 35 tokens/seconde
    energy_per_million_tokens: 3.72 # (480W / 35 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le compact et r√©actif de Mistral AI, sp√©cialement con√ßu pour offrir une assistance conversationnelle fluide et pertinente avec une vitesse de r√©ponse optimale.
    details: Malgr√© sa taille mod√©r√©e, ce mod√®le affiche une performance remarquable qui rivalise avec celle de nombreux mod√®les propri√©taires bien plus volumineux. Son architecture ing√©nieusement optimis√©e facilite le d√©ploiement local sur des infrastructures vari√©es. Int√©grant des capacit√©s multimodales natives, il peut traiter √† la fois du texte et des images sans recourir √† des syst√®mes externes. Sa licence Apache 2.0 offre une flexibilit√© maximale pour les d√©ploiements commerciaux et les personnalisations, en faisant un choix id√©al pour les entreprises soucieuses d'√©quilibrer performance et contraintes l√©gales.
    supports_tools: true
    supports_vision: true
    supports_reasoning: false
    supports_security: true
    is_fast: false
    tags:
      - Vision
      - Agent
      - S√©curit√©
    use_cases:
      - Applications conversationnelles
      - Assistants virtuels combinant analyse d'images et texte (26 tokens/s)
      - Chatbots de support technique avec acc√®s √† la documentation technique
      - Outils de cr√©ation/√©dition de contenu avec r√©ponse imm√©diate (blogs, emails)
      - D√©ploiement sur infrastructures standard (24B de param√®tres)

  - name: mistral-small3.2:24b
    editor: Mistral AI
    location: FR üá´üá∑
    parameters: 24
    parameters_string: 24B
    context_size: 120000
    speed: 35 tokens/seconde
    energy_per_million_tokens: 3.72 # (480W / 35 t/s) / 3.6
    licence: Apache 2.0
    description: Mise √† jour mineure de Mistral Small 3.1, am√©liorant le suivi d'instructions, la robustesse du function calling et r√©duisant les erreurs de r√©p√©tition.
    details: Cette version 3.2 conserve les forces de son pr√©d√©cesseur tout en apportant des am√©liorations cibl√©es. Elle est plus apte √† suivre des instructions pr√©cises, produit moins de g√©n√©rations infinies ou de r√©ponses r√©p√©titives, et son template pour le function calling est plus robuste. Pour les autres aspects, ses performances sont √©quivalentes ou l√©g√®rement sup√©rieures √† la version 3.1.
    supports_tools: true
    supports_vision: true
    supports_reasoning: false
    supports_security: true
    is_fast: false
    tags:
      - Vision
      - Agent
      - S√©curit√©
      - Instruction Following
    use_cases:
      - Agents conversationnels avec un suivi d'instructions am√©lior√©
      - Int√©gration robuste avec des outils externes via function calling
      - Applications n√©cessitant une grande fiabilit√© pour √©viter les r√©p√©titions
      - Cas d'usage identiques √† Mistral Small 3.1 avec des performances accrues

  - name: deepcoder:14b
    editor: Agentica x Together AI
    location: FR üá´üá∑
    parameters: 14
    parameters_string: 14B
    context_size: 32000
    speed: 64 tokens/seconde
    energy_per_million_tokens: 4.12 # (950W / 64 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le IA open source (14B) par Together AI & Agentica, alternative cr√©dible aux mod√®les propri√©taires pour la g√©n√©ration de code.
    details: Performances remarquables en g√©n√©ration de code et raisonnement algorithmique (60.6% LiveCodeBench Pass@1, 1936 Codeforces, 92.6% HumanEval+). Entra√Æn√© via RL (GRPO+) avec allongement progressif du contexte (32k -> 64k). Projet transparent (code, dataset, logs ouverts). Permet l'int√©gration de capacit√©s avanc√©es de g√©n√©ration de code sans d√©pendre de solutions propri√©taires.
    supports_tools: false
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - Programmation
      - Raisonnement
      - Open-Source
      - Math√©matiques
      - Rapide
    use_cases:
      - G√©n√©ration de code dans plus de 15 langages avec optimisation des performances
      - D√©bogage et refactoring de bases de code existantes avec analyse d'impact
      - Impl√©mentation d'algorithmes complexes (graphes, arbres, heuristiques)
      - Cr√©ation automatis√©e de tests unitaires avec couverture de code > 80%
      - Transposition de code entre langagesframeworks (par exemple Python vers JavaScript)


  - name: granite3.2-vision:2b
    editor: IBM
    location: FR üá´üá∑
    parameters: 2
    parameters_string: 2B
    context_size: 16384
    speed: 48 tokens/seconde
    energy_per_million_tokens: 0.69 # (120W / 48 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le compact r√©volutionnaire d'IBM sp√©cialis√© dans la vision par ordinateur, capable d'analyser et comprendre directement les documents visuels sans recourir √† des technologies OCR interm√©diaires.
    details: Ce mod√®le compact r√©alise l'exploit remarquable d'√©galer les performances de mod√®les bien plus volumineux sur un large √©ventail de t√¢ches de compr√©hension visuelle. Sa capacit√© √† interpr√©ter directement le contenu visuel des documents - textes, tableaux, graphiques et diagrammes - sans passer par une √©tape d'OCR traditionnelle repr√©sente une avanc√©e significative en termes d'efficacit√© et de pr√©cision. Cette approche int√©gr√©e r√©duit consid√©rablement les erreurs de reconnaissance et permet une compr√©hension plus contextuelle et plus nuanc√©e du contenu visuel.
    supports_tools: true
    supports_vision: true
    supports_reasoning: false
    supports_security: true
    is_fast: false
    tags:
      - Vision
      - S√©curit√©
      - Compact
      - Efficient
    use_cases:
      - Extraction de donn√©es structur√©es √† partir de factures et formulaires sans OCR
      - Analyse directe de tableaux et graphiques avec interpr√©tation des tendances
      - Lecture et interpr√©tation de diagrammes techniques (√©lectriques, m√©caniques)
      - Traitement de documents manuscrits avec taux de reconnaissance √©lev√©
      - Vision par ordinateur l√©g√®re (2B param√®tres) avec vitesse √©lev√©e (50 tokens/s)

  - name: granite3.3:8b
    editor: IBM
    location: FR üá´üá∑
    parameters: 8
    parameters_string: 8B
    context_size: 60000
    speed: 30 tokens/seconde
    energy_per_million_tokens: 1.11 # (120W / 30 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le Granite 8B fine-tun√© par IBM pour un raisonnement et un suivi d'instructions am√©lior√©s, avec un contexte de 128k tokens.
    details: Cette version 8B du mod√®le Granite 3.3 offre des gains significatifs sur les benchmarks g√©n√©riques (AlpacaEval-2.0, Arena-Hard) et des am√©liorations en math√©matiques, codage et suivi d'instructions. Il supporte 12 langues, le Fill-in-the-Middle (FIM) pour le code, le mode "Thinking" pour la r√©flexion structur√©e, et l'appel de fonctions. Licence Apache 2.0. Id√©al pour les t√¢ches g√©n√©rales et l'int√©gration dans des assistants IA.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: true
    is_fast: false
    tags:
      - Agent
      - Raisonnement
      - S√©curit√©
      - Efficient
    use_cases:
      - T√¢ches g√©n√©rales d'instruction-following (classification, extraction, Q&A)
      - Assistants IA multilingues (12 langues)
      - Traitement de documents tr√®s longs (128k tokens) pour les taches de r√©sum√©s, Q&A,...
      - G√©n√©ration/compl√©tion de code avec Fill-in-the-Middle
      - Int√©gration avec des outils externes via function calling
      - Raisonnement structur√© avec le mode "Thinking"

  - name: granite3.3:2b
    editor: IBM
    location: FR üá´üá∑
    parameters: 2
    parameters_string: 2B
    context_size: 120000
    speed: 45 tokens/seconde
    energy_per_million_tokens: 0.74 # (120W / 45 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le Granite 2B fine-tun√© par IBM, optimis√© pour le raisonnement et le suivi d'instructions, avec un contexte de 128k tokens.
    details: Version compacte de Granite 3.3 (2B param√®tres) offrant les m√™mes am√©liorations en raisonnement, instruction-following, math√©matiques et codage que la version 8B. Supporte 12 langues, le Fill-in-the-Middle (FIM), le mode "Thinking", et l'appel de fonctions. Licence Apache 2.0. Excellent choix pour des d√©ploiements l√©gers n√©cessitant de longues capacit√©s contextuelles et de raisonnement.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: true
    is_fast: false
    tags:
      - Agent
      - Raisonnement
      - S√©curit√©
      - Efficient
    use_cases:
      - D√©ploiements l√©gers avec grand contexte (128k tokens)
      - T√¢ches g√©n√©rales d'instruction-following sur ressources limit√©es
      - Assistants IA multilingues compacts
      - Traitement de documents longs sur appareils moins puissants
      - G√©n√©ration/compl√©tion de code FIM sur postes de travail standards

  - name: magistral:24b
    editor: Mistral AI
    location: FR üá´üá∑
    parameters: 24
    parameters_string: 24B
    context_size: 40000
    speed: 25 tokens/seconde
    energy_per_million_tokens: 5.33 # (480W / 25 t/s) / 3.6
    licence: Apache 2.0
    description: Le premier mod√®le de raisonnement de Mistral AI, excellant dans le raisonnement sp√©cifique au domaine, transparent et multilingue.
    details: Id√©al pour une utilisation g√©n√©rale n√©cessitant un traitement de pens√©e plus long et une meilleure pr√©cision. Utile pour la recherche juridique, la pr√©vision financi√®re, le d√©veloppement de logiciels et la narration cr√©ative. R√©sout les d√©fis en plusieurs √©tapes o√π la transparence et la pr√©cision sont essentielles.
    supports_tools: false
    supports_vision: false
    supports_reasoning: true
    supports_security: true
    is_fast: false
    tags:
      - Raisonnement
      - Multilingue
    use_cases:
      - Strat√©gie et op√©rations commerciales (mod√©lisation des risques)
      - Industries r√©glement√©es (juridique, finance) avec raisonnement tra√ßable
      - Ing√©nierie logicielle (planification de projet, architecture)
      - Cr√©ation de contenu et communication (r√©daction cr√©ative, narration)

  - name: granite3.1-moe:3b
    editor: IBM
    location: FR üá´üá∑
    parameters: 3
    parameters_string: 3B
    context_size: 32000
    speed: 74 tokens/seconde
    energy_per_million_tokens: 0.45 # (120W / 74 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le innovant d'IBM utilisant l'architecture Mixture-of-Experts (MoE) pour offrir des performances exceptionnelles tout en optimisant drastiquement l'utilisation des ressources computationnelles.
    details: L'architecture MoE (Mixture-of-Experts) de ce mod√®le constitue une avanc√©e significative dans l'optimisation des mod√®les de langage, permettant d'atteindre des performances comparables √† celles de mod√®les bien plus volumineux tout en maintenant une empreinte m√©moire consid√©rablement r√©duite. Cette approche innovante active dynamiquement uniquement les parties pertinentes du r√©seau pour chaque t√¢che sp√©cifique, assurant ainsi une efficacit√© √©nerg√©tique et computationnelle remarquable sans compromis sur la qualit√© des r√©sultats.
    supports_tools: true
    supports_vision: false
    supports_reasoning: false
    supports_security: true
    is_fast: true
    tags:
      - Agent
      - S√©curit√©
      - Rapide
      - MoE
      - Efficacit√©
      - Efficient
    use_cases:
      - Applications g√©n√©ralistes avec co√ªt d'inf√©rence optimis√© (42 tokens/seconde)
      - Traitement de documents dans des environnements CPU avec utilisation RAM limit√©e
      - Analyses sp√©cialis√©es avec activation dynamique des parties pertinentes du mod√®le
      - D√©ploiements haute densit√© avec faible consommation √©nerg√©tique par inf√©rence
      - Traitement parall√®le de plusieurs types de requ√™tes avec sp√©cialisation MoE

  - name: cogito:14b
    editor: Deep Cogito
    location: FR üá´üá∑
    parameters: 14
    parameters_string: 14B
    context_size: 32000
    speed: 60 tokens/seconde
    energy_per_million_tokens: 4.40 # (950W / 60 t/s) / 3.6
    licence: LLAMA 3.2 Community Licence
    description: Mod√®le de Deep Cogito sp√©cialement con√ßu pour exceller dans les t√¢ches de raisonnement profond et de compr√©hension contextuelle nuanc√©e, id√©al pour les applications analytiques sophistiqu√©es.
    details: Dot√© d'excellentes capacit√©s de raisonnement logique et de compr√©hension s√©mantique approfondie, ce mod√®le se distingue par sa capacit√© √† saisir les subtilit√©s et les implications dans des textes complexes. Sa conception privil√©gie la coh√©rence du raisonnement et la pr√©cision analytique, le rendant particuli√®rement adapt√© aux applications n√©cessitant une analyse minutieuse et contextuelle des informations. Sa taille mod√©r√©e permet un d√©ploiement flexible tout en maintenant des performances de haute qualit√© sur un large √©ventail de t√¢ches analytiques exigeantes.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - Agent
      - Raisonnement
      - Compr√©hension
      - Analyse
      - Rapide
    use_cases:
      - Analyse s√©mantique de textes avec identification des implications non explicites
      - Raisonnement causal structur√© avec identification des relations cause-effet
      - Synth√®se de documents complexes avec extraction des informations cl√©s
      - Syst√®mes de question-r√©ponse pr√©cis sur corpus documentaires sp√©cialis√©s
      - Analyse argumentative avec √©valuation de la solidit√© des raisonnements

  - name: cogito:32b
    editor: Deep Cogito
    location: FR üá´üá∑
    parameters: 32
    parameters_string: 32B
    context_size: 32000
    speed: 32 tokens/seconde
    energy_per_million_tokens: 8.25 # (950W / 32 t/s) / 3.6
    licence: LLAMA 3.2 Community Licence
    description: Version avanc√©e du mod√®le Cogito offrant des capacit√©s de raisonnement et d'analyse consid√©rablement amplifi√©es, con√ßue pour les applications les plus exigeantes en mati√®re d'intelligence artificielle analytique.
    details: Cette version √©tendue du mod√®le Cogito pousse encore plus loin les capacit√©s de raisonnement et de compr√©hension, offrant une profondeur d'analyse in√©gal√©e pour les applications les plus complexes. Sa conception architecturale sophistiqu√©e lui permet d'aborder des raisonnements multi-√©tapes avec rigueur et pr√©cision, tout en maintenant une coh√©rence globale remarquable. Id√©al pour les applications critiques n√©cessitant une intelligence artificielle capable d'un raisonnement nuanc√© et d'une compr√©hension contextuelle approfondie comparable aux analyses d'experts humains dans des domaines sp√©cialis√©s.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Agent
      - Raisonnement
      - Compr√©hension
      - Analyse
    use_cases:
      - Analyse de sc√©narios multi-factoriels avec √©valuation probabiliste des r√©sultats
      - R√©solution de probl√®mes scientifiques avec d√©monstration formelle des √©tapes
      - Applications √† haute criticit√© n√©cessitant pr√©cision et v√©rifiabilit√© des r√©sultats
      - Syst√®mes experts dans des domaines sp√©cialis√©s (juridique, m√©dical, technique)
      - Analyse avec raisonnement multi-√©tapes et explicabilit√© compl√®te des conclusions

  - name: qwen3:32b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 32
    parameters_string: 32B
    context_size: 40000
    speed: 18 tokens/seconde
    energy_per_million_tokens: 7.41 # (480W / 18 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le puissant de la nouvelle g√©n√©ration Qwen3, offrant des capacit√©s avanc√©es en raisonnement, code, et agentique, avec un contexte √©tendu.
    details: Fait partie de la s√©rie Qwen3, entra√Æn√© sur un vaste corpus de donn√©es. Ce mod√®le de 32 milliards de param√®tres est con√ßu pour exceller dans les t√¢ches complexes, supporter plus de 100 langues et int√©grer des modes de pens√©e hybrides pour une meilleure performance.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Agent
      - Raisonnement
      - Multilingue
      - Grand Contexte
    use_cases:
      - Agents conversationnels avanc√©s avec grand contexte et int√©gration d'outils (MCP)
      - R√©solution de probl√®mes complexes (maths, code) avec mode "Thinking"
      - Analyse et g√©n√©ration de documents volumineux
      - Applications multilingues (>100 langues) n√©cessitant une compr√©hension profonde

  - name: qwq:32b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 32
    parameters_string: 32B
    context_size: 32000
    speed: 35 tokens/seconde
    energy_per_million_tokens: 7.54 # (950W / 35 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le de 32 milliards de param√®tres am√©lior√© par apprentissage par renforcement (RL) pour exceller dans le raisonnement, le codage, les math√©matiques et les t√¢ches d'agent.
    details: Ce mod√®le utilise une approche RL innovante avec des r√©compenses bas√©es sur les r√©sultats (v√©rificateurs de pr√©cision pour les maths, ex√©cution de code pour le codage) et un entra√Ænement multi-√©tapes pour am√©liorer les capacit√©s g√©n√©rales sans d√©grader les performances sp√©cialis√©es. Il int√®gre des capacit√©s d'agent pour utiliser des outils et adapter son raisonnement. Licence Apache 2.0.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Agent
      - Raisonnement
      - Codage
      - Math√©matiques
    use_cases:
      - R√©solution de probl√®mes complexes n√©cessitant raisonnement et utilisation d'outils
      - G√©n√©ration et ex√©cution de code avec v√©rification des r√©sultats
      - T√¢ches math√©matiques avanc√©es avec v√©rification de l'exactitude
      - Applications d'agent capables d'interagir avec l'environnement
      - Instruction following am√©lior√© et alignement avec les pr√©f√©rences humaines

  - name: deepseek-r1:14b
    editor: DeepSeek AI
    location: FR üá´üá∑
    parameters: 14
    parameters_string: 14B
    context_size: 32000
    speed: 62 tokens/seconde
    energy_per_million_tokens: 4.26 # (950W / 62 t/s) / 3.6
    licence: MIT licence
    description: Version compacte et efficiente du mod√®le DeepSeek-R1, offrant un excellent compromis entre performance et l√©g√®ret√© pour les d√©ploiements n√©cessitant flexibilit√© et r√©activit√©.
    details: Repr√©sentant un √©quilibre optimal entre performance et efficacit√©, cette version compacte du mod√®le DeepSeek-R1 conserve les principales qualit√©s de raisonnement et d'analyse de son homologue plus volumineux, tout en permettant un d√©ploiement plus l√©ger et plus flexible. Sa conception soigneusement optimis√©e assure des r√©sultats de qualit√© sur un large √©ventail de t√¢ches, tout en minimisant les exigences en ressources computationnelles. Cette combinaison en fait le choix id√©al pour les applications n√©cessitant un d√©ploiement agile sans compromis majeur sur les capacit√©s fondamentales.
    supports_tools: false
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - Raisonnement
      - Compact
      - Polyvalent
      - Rapide
    use_cases:
      - Applications g√©n√©ralistes avec besoins d'inf√©rence rapide (44 tokens/s)
      - D√©ploiements sur serveurs standard sans GPU sp√©cialis√© (14B param√®tres)
      - Traitement de texte avec analyse contextuelle et temps de r√©ponse rapides
      - D√©ploiement sur edge computing avec inf√©rence locale optimis√©e
      - Prototypage rapide d'applications IA avec temps d'it√©ration court

  - name: deepseek-r1:32b
    editor: DeepSeek AI
    location: FR üá´üá∑
    parameters: 32
    parameters_string: 32B
    context_size: 32000
    speed: 33 tokens/seconde
    energy_per_million_tokens: 7.99 # (950W / 33 t/s) / 3.6
    licence: MIT licence
    description: Version interm√©diaire du mod√®le DeepSeek-R1 offrant un √©quilibre strat√©gique entre les capacit√©s avanc√©es de la version 70B et l'efficience de la version 14B, pour une polyvalence et performance optimales.
    details: Cette version interm√©diaire du mod√®le DeepSeek-R1 combine intelligemment puissance et efficacit√©, proposant des performances significativamente am√©lior√©es par rapport √† la version 14B tout en maintenant une empreinte plus l√©g√®re que la version 70B. Cette position strat√©gique dans la gamme en fait une option particuli√®rement int√©ressante pour les d√©ploiements n√©cessitant des capacit√©s de raisonnement avanc√©es sans les exigences mat√©rielles des plus grands mod√®les. Sa polyvalence lui permet d'exceller sur un large √©ventail de t√¢ches, de l'analyse de texte √† la g√©n√©ration de contenu structur√©.
    supports_tools: false
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Raisonnement
      - Polyvalent
    use_cases:
      - Applications n√©cessitant un bon √©quilibre puissance/co√ªt (32B param√®tres)
      - Traitement de texte professionnel avec analyse des subtilit√©s s√©mantiques
      - G√©n√©ration automatis√©e de rapports structur√©s √† partir de donn√©es brutes
      - Applications combinant analyse de donn√©es et g√©n√©ration de contenus
      - Assistants sp√©cialis√©s pour secteurs techniques (juridique, m√©dical, technique)

  - name: cogito:3b
    editor: Deep Cogito
    location: FR üá´üá∑
    parameters: 3
    parameters_string: 3B
    context_size: 32000
    speed: 55 tokens/seconde
    energy_per_million_tokens: 0.61 # (120W / 55 t/s) / 3.6
    licence: LLAMA 3.2 Community Licence
    description: Version compacte du mod√®le Cogito, optimis√©e pour le raisonnement sur des appareils √† ressources limit√©es.
    details: Offre les capacit√©s de raisonnement de la famille Cogito dans un format tr√®s l√©ger (3 milliards de param√®tres), id√©al pour les d√©ploiements embarqu√©s ou les environnements CPU.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - Raisonnement
      - Compact
      - Embarqu√©
      - Efficient
      - Rapide

  - name: granite-embedding:278m
    editor: IBM
    location: FR üá´üá∑
    parameters: 0.278
    parameters_string: 278M
    context_size: 512
    licence: Apache 2.0
    description: Mod√®le d'embedding ultra-l√©ger d'IBM pour la recherche s√©mantique et la classification.
    details: Con√ßu pour g√©n√©rer des repr√©sentations vectorielles denses de texte, ce mod√®le est optimis√© pour l'efficacit√© et la performance dans les t√¢ches de similarit√© s√©mantique, de clustering et de classification. Sa taille r√©duite le rend id√©al pour les d√©ploiements √† grande √©chelle.
    supports_tools: false
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: false
    tags:
      - Embedding
      - Compact
      - S√©mantique
      - Efficient

  - name: granite3-guardian:2b
    editor: IBM
    location: FR üá´üá∑
    parameters: 2
    parameters_string: 2B
    context_size: 8192
    licence: Apache 2.0
    description: Mod√®le compact d'IBM sp√©cialis√© dans la s√©curit√© et la conformit√©, d√©tectant les risques et les contenus inappropri√©s.
    details: Version l√©g√®re de la famille Guardian, entra√Æn√©e pour identifier et filtrer les contenus nuisibles, les biais et les risques de s√©curit√© dans les interactions textuelles. Offre une protection robuste avec une faible empreinte computationnelle. Contexte limit√© √† 8k tokens.
    supports_tools: false
    supports_vision: false
    supports_reasoning: false
    supports_security: true
    is_fast: false
    tags:
      - S√©curit√©
      - Conformit√©
      - Compact
      - Filtrage
      - Efficient

  - name: granite3-guardian:8b
    editor: IBM
    location: FR üá´üá∑
    parameters: 8
    parameters_string: 8B
    context_size: 32000
    licence: Apache 2.0
    description: Mod√®le d'IBM sp√©cialis√© dans la s√©curit√© et la conformit√©, offrant des capacit√©s avanc√©es de d√©tection des risques.
    details: Mod√®le de taille interm√©diaire de la famille Guardian, fournissant une analyse de s√©curit√© plus approfondie que la version 2B. Id√©al pour les applications n√©cessitant une surveillance rigoureuse du contenu et une conformit√© stricte.
    supports_tools: false
    supports_vision: false
    supports_reasoning: false
    supports_security: true
    is_fast: false
    tags:
      - S√©curit√©
      - Conformit√©
      - Filtrage

  - name: qwen2.5:0.5b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 0.5
    parameters_string: 0.5B
    context_size: 32000
    speed: 162 tokens/seconde
    energy_per_million_tokens: 0.10 # (60W / 162 t/s) / 3.6
    licence: MIT licence
    description: Micro-mod√®le ultra-l√©ger de la famille Qwen 2.5, con√ßu pour une efficacit√© maximale sur appareils contraints.
    details: Le plus petit mod√®le de la s√©rie Qwen 2.5, offrant des capacit√©s de base en traitement de langage avec une empreinte minimale. Id√©al pour les t√¢ches tr√®s simples sur des appareils IoT ou mobiles.
    supports_tools: true
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Ultra-compact
      - Rapide
      - Embarqu√©
      - Efficient

  - name: qwen2.5:1.5b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 1.5
    parameters_string: 1.5B
    context_size: 32000
    speed: 102 tokens/seconde
    energy_per_million_tokens: 0.33 # (120W / 102 t/s) / 3.6
    licence: MIT licence
    description: Mod√®le tr√®s compact de la famille Qwen 2.5, offrant un bon √©quilibre performance/taille pour les d√©ploiements l√©gers.
    details: Mod√®le l√©g√®rement plus grand que la version 0.5B, offrant des capacit√©s am√©lior√©es tout en restant tr√®s efficace. Convient aux applications mobiles ou embarqu√©es n√©cessitant un peu plus de puissance.
    supports_tools: true
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Compact
      - Rapide
      - Embarqu√©
      - Efficient

  - name: qwen2.5:14b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 14
    parameters_string: 14B
    context_size: 32000
    speed: 61 tokens/seconde
    energy_per_million_tokens: 4.33 # (950W / 61 t/s) / 3.6
    licence: MIT licence
    description: Mod√®le polyvalent de taille moyenne de la famille Qwen 2.5, bon √©quilibre performance/ressources.
    details: Offre de solides capacit√©s multilingues et de compr√©hension g√©n√©rale dans un format 14B. Convient √† une large gamme d'applications n√©cessitant un mod√®le fiable sans les exigences des tr√®s grands mod√®les.
    supports_tools: true
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Polyvalent
      - Multilingue
      - Rapide

  - name: qwen2.5:32b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 32
    parameters_string: 32B
    context_size: 32000
    speed: 31 tokens/seconde
    energy_per_million_tokens: 8.51 # (950W / 31 t/s) / 3.6
    licence: MIT licence
    description: Mod√®le puissant de la famille Qwen 2.5, offrant des capacit√©s avanc√©es en compr√©hension et g√©n√©ration.
    details: Version 32B de Qwen 2.5, fournissant des performances accrues par rapport √† la version 14B, notamment en raisonnement et en suivi d'instructions complexes, tout en restant plus l√©ger que le mod√®le 72B.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Polyvalent
      - Multilingue
      - Raisonnement

  - name: qwen2.5:3b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 3
    parameters_string: 3B
    context_size: 32000
    speed: 64 tokens/seconde
    energy_per_million_tokens: 0.52 # (120W / 64 t/s) / 3.6
    licence: MIT licence
    description: Mod√®le compact et efficace de la famille Qwen 2.5, adapt√© aux t√¢ches g√©n√©rales sur ressources limit√©es.
    details: Offre un bon compromis entre les capacit√©s des mod√®les 1.5B et 14B. Id√©al pour les applications n√©cessitant une bonne compr√©hension g√©n√©rale dans un format l√©ger et rapide.
    supports_tools: true
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Compact
      - Rapide
      - Polyvalent
      - Efficient

  - name: qwen3:0.6b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 0.6
    parameters_string: 0.6B
    context_size: 32000
    speed: 112 tokens/seconde
    energy_per_million_tokens: 0.15 # (60W / 112 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le compact et efficace de la famille Qwen3, adapt√© aux t√¢ches g√©n√©rales sur ressources limit√©es.
    details: Offre un bon compromis entre les capacit√©s des mod√®les ultra-compacts et les mod√®les plus grands. Id√©al pour les applications n√©cessitant une bonne compr√©hension g√©n√©rale dans un format l√©ger et rapide.
    supports_tools: true
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Compact
      - Rapide
      - Polyvalent
      - Efficient

  - name: qwen3:1.7b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 1.7
    parameters_string: 1.7B
    context_size: 32000
    speed: 88 tokens/seconde
    energy_per_million_tokens: 0.38 # (120W / 88 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le tr√®s compact de la famille Qwen3, offrant un bon √©quilibre performance/taille pour les d√©ploiements l√©gers.
    details: Mod√®le l√©g√®rement plus grand que la version 0.6B, offrant des capacit√©s am√©lior√©es tout en restant tr√®s efficace. Convient aux applications mobiles ou embarqu√©es n√©cessitant un peu plus de puissance.
    supports_tools: true
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Compact
      - Rapide
      - Embarqu√©
      - Efficient

  - name: qwen3:4b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 4
    parameters_string: 4B
    context_size: 32000
    speed: 49 tokens/seconde
    energy_per_million_tokens: 0.68 # (120W / 49 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le compact de la famille Qwen3 offrant d'excellentes performances dans un format l√©ger et √©conomique.
    details: Cette version compacte du mod√®le Qwen3 est optimis√©e pour les d√©ploiements avec contraintes de ressources tout en maintenant des performances remarquables pour sa taille. Son architecture efficiente permet une inf√©rence rapide sur du mat√©riel standard.
    supports_tools: true
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: false
    tags:
      - Compact
      - Efficient

  - name: qwen3-2507-think:4b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 4
    parameters_string: 4B
    context_size: 250000
    speed: 70 tokens/seconde
    energy_per_million_tokens: 1.90 # (480W / 70 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le Qwen3-4B optimis√© pour le raisonnement, avec des performances am√©lior√©es sur les t√¢ches logiques, les math√©matiques, la science et le code, et un contexte √©tendu √† 250K tokens.
    details: Cette version "Thinking" dispose d'une longueur de pens√©e accrue, la rendant id√©ale pour les t√¢ches de raisonnement tr√®s complexes. Elle offre √©galement des am√©liorations g√©n√©rales en suivi d'instructions, utilisation d'outils et g√©n√©ration de texte.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - Agent
      - Raisonnement
      - Grand Contexte
      - Compact
      - Rapide
    use_cases:
      - T√¢ches de raisonnement tr√®s complexes (logique, maths, science, code).
      - Agents conversationnels avec un historique de conversation tr√®s √©tendu (256k tokens).
      - Analyse de documents tr√®s volumineux avec raisonnement profond.
      - Int√©gration avec des outils externes via function calling sur de tr√®s grands contextes.

  - name: qwen3-2507:4b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 4
    parameters_string: 4B
    context_size: 250000
    speed: 70 tokens/seconde
    energy_per_million_tokens: 1.90 # (480W / 70 t/s) / 3.6
    licence: Apache 2.0
    description: Version mise √† jour du mode non-pens√©e de Qwen3-4B, avec des am√©liorations significatives des capacit√©s g√©n√©rales, une couverture de connaissances √©tendue et un meilleur alignement avec les pr√©f√©rences des utilisateurs.
    details: Am√©liorations notables du suivi d'instructions, du raisonnement logique, de la compr√©hension de texte, des math√©matiques, du codage et de l'utilisation d'outils. Contexte natif de 250k tokens.
    supports_tools: true
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: true
    tags:
      - Agent
      - Grand Contexte
      - Compact
      - Rapide
      - Multilingue
    use_cases:
      - T√¢ches g√©n√©rales n√©cessitant un suivi d'instructions pr√©cis et un raisonnement logique.
      - Applications multilingues avec une large couverture de connaissances.
      - G√©n√©ration de texte de haute qualit√© pour des t√¢ches ouvertes et subjectives.
      - Analyse de documents tr√®s volumineux gr√¢ce au contexte de 256k tokens.

  - name: qwen3:8b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 8
    parameters_string: 8B
    context_size: 32000
    speed: 33 tokens/seconde
    energy_per_million_tokens: 1.01 # (120W / 33 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le Qwen3 8B offrant un bon √©quilibre entre performance et efficacit√© pour les t√¢ches g√©n√©rales.
    details: Version 8B de Qwen3, offrant des capacit√©s am√©lior√©es en raisonnement, code, maths et agent. Supporte plus de 100 langues et les modes de pens√©e hybrides.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Raisonnement
      - Agent
      - Multilingue
      - Efficient

  - name: qwen2.5vl:3b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 3.8
    parameters_string: 3.8B
    context_size: 128000
    speed: 65 tokens/seconde
    energy_per_million_tokens: 0.51 # (120W / 65 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le Vision-Langage compact, solution performante pour l'IA en p√©riph√©rie (edge AI).
    details: Qwen2.5-VL est le nouveau mod√®le phare vision-langage de Qwen, marquant une avanc√©e significative par rapport √† Qwen2-VL. Caract√©ristiques cl√©s - Compr√©hension visuelle (objets communs, textes, graphiques, ic√¥nes, mises en page). Capacit√©s d'agent visuel (raisonnement, direction dynamique d'outils pour utilisation d'ordinateur/t√©l√©phone). Localisation visuelle pr√©cise (bo√Ætes englobantes, points, sorties JSON stables). G√©n√©ration de sorties structur√©es (factures, formulaires, tableaux). Le Qwen2.5-VL-3B surpasse m√™me la version 7B de Qwen2-VL.
    supports_tools: true
    supports_vision: true
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - Vision
      - Agent
      - Raisonnement
      - Rapide
      - Efficient
      - OCR
      - Localisation Visuelle
      - Edge AI

  - name: qwen2.5vl:7b
    editor: Qwen Team
    location: FR üá´üá∑
    parameters: 8.3
    parameters_string: 7B (8.3B)
    context_size: 128000
    speed: 35 tokens/seconde
    energy_per_million_tokens: 0.95 # (120W / 35 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le Vision-Langage performant, surpassant GPT-4o-mini sur certaines t√¢ches.
    details: Qwen2.5-VL est le nouveau mod√®le phare vision-langage de Qwen, marquant une avanc√©e significative par rapport √† Qwen2-VL. Caract√©ristiques cl√©s - Compr√©hension visuelle (objets communs, textes, graphiques, ic√¥nes, mises en page). Capacit√©s d'agent visuel (raisonnement, direction dynamique d'outils pour utilisation d'ordinateur/t√©l√©phone). Localisation visuelle pr√©cise (bo√Ætes englobantes, points, sorties JSON stables). G√©n√©ration de sorties structur√©es (factures, formulaires, tableaux). Le Qwen2.5-VL-7B-Instruct surpasse GPT-4o-mini dans plusieurs t√¢ches et est particuli√®rement performant pour la compr√©hension de documents et de diagrammes.
    supports_tools: true
    supports_vision: true
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Vision
      - Agent
      - Raisonnement
      - Efficient
      - OCR
      - Localisation Visuelle

  - name: hf.co/roadus/Foundation-Sec-8B-Q4_K_M-GGUF:Q4_K_M
    editor: Foundation AI ‚Äî Cisco
    location: FR üá´üá∑
    parameters: 8
    parameters_string: 8B
    context_size: 16384
    speed: 21 tokens/seconde
    energy_per_million_tokens: 1.59 # (120W / 21 t/s) / 3.6
    licence: Apache 2.0
    description: Mod√®le de langage sp√©cialis√© pour la cybers√©curit√©, optimis√© pour l'efficacit√©.
    details: Mod√®le Foundation-Sec-8B (Llama-3.1-FoundationAI-SecurityLLM-base-8B) bas√© sur Llama-3.1-8B, pr√©-entra√Æn√© sur un corpus cybers√©curit√©. Con√ßu pour la d√©tection de menaces, l'√©valuation de vuln√©rabilit√©s, l'automatisation de la s√©curit√©, etc. Optimis√© pour le d√©ploiement local. Contexte de 16k tokens.
    supports_tools: false
    supports_vision: false
    supports_reasoning: true
    supports_security: true
    is_fast: false
    tags:
      - S√©curit√©
      - Compact

  - name: devstral:24b
    editor: Mistral AI & All Hands AI
    location: FR üá´üá∑
    parameters: 24
    parameters_string: 24B
    context_size: 120000
    speed: 45 tokens/seconde
    energy_per_million_tokens: 5.86 # (950W / 45 t/s) / 3.6
    licence: Apache 2.0
    description: Devstral est un LLM agentique pour les t√¢ches d'ing√©nierie logicielle.
    details: Devstral est un LLM agentique pour les t√¢ches d'ing√©nierie logicielle. Il excelle dans l'utilisation d'outils pour explorer les bases de code, modifier plusieurs fichiers et alimenter les agents d'ing√©nierie logicielle. Il est affin√© √† partir de Mistral Small 3.1, disposant ainsi d'une longue fen√™tre contextuelle allant jusqu'√† 128k tokens. 
    supports_tools: true
    supports_vision: false
    supports_reasoning: false
    supports_security: true
    is_fast: false
    tags:
      - Agent
      - Programmation
      - Open-Source
      - Grand Contexte
    use_cases:
      - Exploration et modification de bases de code
      - Agentic
      - Europ√©en

  - name: cogito:8b
    editor: Deep Cogito
    location: FR üá´üá∑
    parameters: 8
    parameters_string: 8B
    context_size: 32000
    speed: 30 tokens/seconde
    energy_per_million_tokens: 1.11 # (120W / 30 t/s) / 3.6
    licence: LLAMA 3.2 Community Licence
    description: Mod√®le de taille interm√©diaire de la famille Cogito, offrant un bon √©quilibre entre les capacit√©s de raisonnement et l'efficacit√©.
    details: Cette version 8B se positionne entre les mod√®les compacts et les mod√®les plus larges, offrant des capacit√©s de raisonnement robustes pour une large gamme d'applications analytiques sans n√©cessiter les ressources des mod√®les plus grands.
    supports_tools: true
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: false
    tags:
      - Agent
      - Raisonnement
      - Polyvalent
      - Efficient

  - name: llama3.1:8b
    editor: Meta
    location: FR üá´üá∑
    parameters: 8
    parameters_string: 8B
    context_size: 32000
    speed: 31 tokens/seconde
    energy_per_million_tokens: 1.08 # (120W / 31 t/s) / 3.6
    licence: LLAMA 3.1 Community Licence
    description: Mod√®le de base de la famille Llama 3.1, offrant des performances solides pour sa taille.
    details: Bas√© sur l'architecture Llama 3.1, ce mod√®le 8B est un excellent point de d√©part pour des t√¢ches g√©n√©rales, offrant une bonne qualit√© de g√©n√©ration et de compr√©hension dans un format efficace.
    supports_tools: false
    supports_vision: false
    supports_reasoning: false
    supports_security: false
    is_fast: false
    tags:
      - Polyvalent
      - Efficient

  - name: phi4-reasoning:14b
    editor: Microsoft
    location: FR üá´üá∑
    parameters: 14
    parameters_string: 14B
    context_size: 32000
    speed: 71 tokens/seconde
    energy_per_million_tokens: 3.71 # (950W / 71 t/s) / 3.6
    licence: MIT Licence
    description: Mod√®le de la famille Phi de Microsoft, sp√©cialis√© dans le raisonnement complexe et les math√©matiques.
    details: Ce mod√®le est sp√©cifiquement entra√Æn√© pour exceller dans les t√¢ches qui n√©cessitent un raisonnement logique en plusieurs √©tapes, ce qui le rend particuli√®rement performant pour les probl√®mes de math√©matiques, de logique et de codage.
    supports_tools: false
    supports_vision: false
    supports_reasoning: true
    supports_security: false
    is_fast: true
    tags:
      - Raisonnement
      - Math√©matiques
      - Programmation
      - Rapide

# Cas d'usage recommand√©s
use_cases:
  - name: Dialogue multilingue
    description: Chatbots et assistants capables de communiquer dans plusieurs langues avec d√©tection automatique, maintien du contexte sur l'ensemble de la conversation et compr√©hension des sp√©cificit√©s linguistiques
    recommended_models:
      - Llama 3.3
      - Mistral Small 3.2
      - Qwen 3 
      - Granite 3.3 

  - name: Analyse de documents longs
    description: Traitement de documents volumineux (>100 pages) avec maintien du contexte sur l'ensemble du texte, extraction d'informations cl√©s, g√©n√©ration de r√©sum√©s pertinents et r√©ponse √† des questions sp√©cifiques sur le contenu
    recommended_models:
      - Gemma 3 
      - Qwen3 
      - Granite 3.3  # Mis √† jour

  - name: Programmation et d√©veloppement
    description: G√©n√©ration et optimisation de code dans multiples langages, d√©bogage, refactoring, d√©veloppement de fonctionnalit√©s compl√®tes, compr√©hension des impl√©mentations algorithmiques complexes et cr√©ation de tests unitaires
    recommended_models:
      - DeepCoder
      - QwQ
      - Qwen3 coder 
      - Granite 3.3 # Ajout√© (FIM)
      - Devstral

  - name: Analyse visuelle
    description: Traitement direct d'images et documents visuels sans pr√©-traitement OCR, interpr√©tation de diagrammes techniques, graphiques, tableaux, dessins et photos avec g√©n√©ration d'explications textuelles d√©taill√©es du contenu visuel
    recommended_models:
      - Granite 3.2 Vision
      - Mistral Small 3.2
      - Gemma 3
      - Qwen2.5-VL
    
  - name: S√©curit√© et conformit√©
    description: Applications n√©cessitant des capacit√©s sp√©cifiques en mati√®re de s√©curit√© ; filtrage de contenu sensible, tra√ßabilit√© des raisonnements, v√©rification RGPD/HDS, minimisation des risques, analyse des vuln√©rabilit√©s et respect des r√©glementations sectorielles
    recommended_models:
      - Granite Guardian
      - Granite 3.3
      - Devstral
      - Mistral Small 3.1
      - Magistral 24b
      - Foundation-Sec-8B

  - name: D√©ploiements l√©gers et embarqu√©s
    description: Applications n√©cessitant une empreinte minimale en ressources, d√©ploiement sur appareils √† capacit√© limit√©e, inf√©rence en temps r√©el sur CPU standard et int√©gration dans des syst√®mes embarqu√©s ou IoT
    recommended_models:
      - Gemma 3
      - Granite 3.1 MoE
      - Granite Guardian
      - Granite 3.3